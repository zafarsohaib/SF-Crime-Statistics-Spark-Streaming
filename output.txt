2020-05-19 05:24:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-19 05:24:15 INFO  SparkContext:54 - Running Spark version 2.3.4
2020-05-19 05:24:15 INFO  SparkContext:54 - Submitted application: KafkaSparkStructuredStreaming
2020-05-19 05:24:15 INFO  SecurityManager:54 - Changing view acls to: root
2020-05-19 05:24:15 INFO  SecurityManager:54 - Changing modify acls to: root
2020-05-19 05:24:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-05-19 05:24:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-05-19 05:24:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2020-05-19 05:24:16 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40389.
2020-05-19 05:24:16 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-05-19 05:24:16 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-05-19 05:24:16 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-05-19 05:24:16 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-05-19 05:24:16 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-9e753217-e040-47f7-8cc1-9882f7b3066f
2020-05-19 05:24:16 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2020-05-19 05:24:16 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-05-19 05:24:16 INFO  log:192 - Logging initialized @9001ms
2020-05-19 05:24:17 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-05-19 05:24:17 INFO  Server:419 - Started @9318ms
2020-05-19 05:24:17 WARN  Utils:66 - Service 'SparkUI' could not bind on port 3000. Attempting port 3001.
2020-05-19 05:24:17 WARN  Utils:66 - Service 'SparkUI' could not bind on port 3001. Attempting port 3002.
2020-05-19 05:24:17 INFO  AbstractConnector:278 - Started ServerConnector@4552eb46{HTTP/1.1,[http/1.1]}{0.0.0.0:3002}
2020-05-19 05:24:17 INFO  Utils:54 - Successfully started service 'SparkUI' on port 3002.
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6373aac{/jobs,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e417223{/jobs/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65dac41a{/jobs/job,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c8b0567{/jobs/job/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59eeb2bf{/stages,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a27478c{/stages/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67dd99c2{/stages/stage,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f5510a7{/stages/stage/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24cd8f06{/stages/pool,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3fdc81ec{/stages/pool/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31d35c23{/storage,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3684b296{/storage/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef9beff{/storage/rdd,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2571932d{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@e68f1e4{/environment,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d6bf2bd{/environment/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e56a9a9{/executors,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@797afb5{/executors/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4eb98972{/executors/threadDump,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c856402{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17858fda{/static,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12fbbccf{/,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f4cc03{/api,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d2a2e4f{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26ce726{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-05-19 05:24:17 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://234cbc3ca30b:3002
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar at spark://234cbc3ca30b:40389/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar with timestamp 1589865858014
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar at spark://234cbc3ca30b:40389/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar with timestamp 1589865858015
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://234cbc3ca30b:40389/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1589865858015
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar at spark://234cbc3ca30b:40389/jars/net.jpountz.lz4_lz4-1.3.0.jar with timestamp 1589865858017
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar at spark://234cbc3ca30b:40389/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar with timestamp 1589865858018
2020-05-19 05:24:18 INFO  SparkContext:54 - Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://234cbc3ca30b:40389/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1589865858018
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:/home/workspace/data_stream.py at file:/home/workspace/data_stream.py with timestamp 1589865858098
2020-05-19 05:24:18 INFO  Utils:54 - Copying /home/workspace/data_stream.py to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/data_stream.py
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar with timestamp 1589865858147
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar with timestamp 1589865858168
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.kafka_kafka-clients-0.10.0.1.jar
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1589865858188
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.spark-project.spark_unused-1.0.0.jar
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar at file:///root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar with timestamp 1589865858208
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/net.jpountz.lz4_lz4-1.3.0.jar
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar with timestamp 1589865858222
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.xerial.snappy_snappy-java-1.1.2.6.jar
2020-05-19 05:24:18 INFO  SparkContext:54 - Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1589865858255
2020-05-19 05:24:18 INFO  Utils:54 - Copying /root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.slf4j_slf4j-api-1.7.16.jar
2020-05-19 05:24:18 INFO  Executor:54 - Starting executor ID driver on host localhost
2020-05-19 05:24:18 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38543.
2020-05-19 05:24:18 INFO  NettyBlockTransferService:54 - Server created on 234cbc3ca30b:38543
2020-05-19 05:24:18 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-05-19 05:24:18 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 234cbc3ca30b, 38543, None)
2020-05-19 05:24:18 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 234cbc3ca30b:38543 with 366.3 MB RAM, BlockManagerId(driver, 234cbc3ca30b, 38543, None)
2020-05-19 05:24:18 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 234cbc3ca30b, 38543, None)
2020-05-19 05:24:18 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 234cbc3ca30b, 38543, None)
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a3c7378{/metrics/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:19 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/workspace/spark-warehouse/').
2020-05-19 05:24:19 INFO  SharedState:54 - Warehouse path is 'file:/home/workspace/spark-warehouse/'.
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@ada0207{/SQL,null,AVAILABLE,@Spark}
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d573ebf{/SQL/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@130377aa{/SQL/execution,null,AVAILABLE,@Spark}
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12c8b7b4{/SQL/execution/json,null,AVAILABLE,@Spark}
2020-05-19 05:24:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64494b39{/static/sql,null,AVAILABLE,@Spark}
2020-05-19 05:24:21 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2020-05-19 05:24:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 1
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-5a51fd12-c138-4027-9569-ff9d80a0d7d5--2130216036-driver-0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

2020-05-19 05:24:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 1
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-5a51fd12-c138-4027-9569-ff9d80a0d7d5--2130216036-driver-0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

2020-05-19 05:24:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2020-05-19 05:24:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
root
 |-- key: binary (nullable = true)
 |-- value: binary (nullable = true)
 |-- topic: string (nullable = true)
 |-- partition: integer (nullable = true)
 |-- offset: long (nullable = true)
 |-- timestamp: timestamp (nullable = true)
 |-- timestampType: integer (nullable = true)

root
 |-- crime_id: string (nullable = true)
 |-- original_crime_type_name: string (nullable = true)
 |-- report_date: string (nullable = true)
 |-- call_date: string (nullable = true)
 |-- offense_date: string (nullable = true)
 |-- call_time: string (nullable = true)
 |-- call_date_time: timestamp (nullable = true)
 |-- disposition: string (nullable = true)
 |-- address: string (nullable = true)
 |-- city: string (nullable = true)
 |-- state: string (nullable = true)
 |-- agency_id: string (nullable = true)
 |-- address_type: string (nullable = true)
 |-- common_location: string (nullable = true)

root
 |-- window: struct (nullable = false)
 |    |-- start: timestamp (nullable = true)
 |    |-- end: timestamp (nullable = true)
 |-- original_crime_type_name: string (nullable = true)
 |-- count: long (nullable = false)

2020-05-19 05:24:29 INFO  MicroBatchExecution:54 - Starting aggregates [id = 5bb46ce7-e507-4d4a-b04e-67d0babbd47c, runId = aa5811b7-4964-4f8f-81cc-092a1da056a8]. Use file:///tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b to store the query checkpoint.
2020-05-19 05:24:29 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 1
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

2020-05-19 05:24:29 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 1
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

2020-05-19 05:24:29 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2020-05-19 05:24:29 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2020-05-19 05:24:29 INFO  MicroBatchExecution:54 - Starting new streaming query.
2020-05-19 05:24:30 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147483647 rack: null) for group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0.
2020-05-19 05:24:30 INFO  ConsumerCoordinator:292 - Revoking previously assigned partitions [] for group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0
2020-05-19 05:24:30 INFO  AbstractCoordinator:326 - (Re-)joining group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0
2020-05-19 05:24:33 INFO  AbstractCoordinator:434 - Successfully joined group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0 with generation 1
2020-05-19 05:24:33 INFO  ConsumerCoordinator:231 - Setting newly assigned partitions [department.police.service.call-0, department.police.service.call-1] for group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-driver-0
2020-05-19 05:24:33 INFO  KafkaSource:54 - Initial offsets: {"department.police.service.call":{"1":0,"0":0}}
2020-05-19 05:24:33 INFO  MicroBatchExecution:54 - Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1589865873421,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:33 INFO  KafkaSource:54 - GetBatch called with start = None, end = {"department.police.service.call":{"1":3207,"0":3107}}
2020-05-19 05:24:33 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:34 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,0,3107,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,0,3207,None)
2020-05-19 05:24:36 INFO  CodeGenerator:54 - Code generated in 884.69722 ms
2020-05-19 05:24:37 INFO  CodeGenerator:54 - Code generated in 260.732892 ms
2020-05-19 05:24:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:37 INFO  CodeGenerator:54 - Code generated in 143.809323 ms
2020-05-19 05:24:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:37 INFO  CodeGenerator:54 - Code generated in 118.62809 ms
2020-05-19 05:24:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:37 INFO  ContextCleaner:54 - Cleaned accumulator 1
2020-05-19 05:24:37 INFO  ContextCleaner:54 - Cleaned accumulator 3
2020-05-19 05:24:37 INFO  CodeGenerator:54 - Code generated in 140.978313 ms
2020-05-19 05:24:38 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 281.8 KB, free 366.0 MB)
2020-05-19 05:24:39 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.1 KB, free 366.0 MB)
2020-05-19 05:24:39 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.3 MB)
2020-05-19 05:24:39 INFO  SparkContext:54 - Created broadcast 0 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:39 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 281.8 KB, free 365.7 MB)
2020-05-19 05:24:39 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.7 MB)
2020-05-19 05:24:39 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.3 MB)
2020-05-19 05:24:39 INFO  SparkContext:54 - Created broadcast 1 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:39 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@49472724. The input RDD has 10 partitions.
2020-05-19 05:24:39 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Registering RDD 6 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Got job 0 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:39 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 39.1 KB, free 365.7 MB)
2020-05-19 05:24:39 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 15.7 KB, free 365.6 MB)
2020-05-19 05:24:39 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 234cbc3ca30b:38543 (size: 15.7 KB, free: 366.2 MB)
2020-05-19 05:24:39 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:39 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2020-05-19 05:24:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:39 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2020-05-19 05:24:39 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2020-05-19 05:24:39 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar with timestamp 1589865858208
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/net.jpountz.lz4_lz4-1.3.0.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/net.jpountz.lz4_lz4-1.3.0.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar with timestamp 1589865858222
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.xerial.snappy_snappy-java-1.1.2.6.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1589865858255
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.slf4j_slf4j-api-1.7.16.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1589865858188
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.spark-project.spark_unused-1.0.0.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar with timestamp 1589865858168
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.kafka_kafka-clients-0.10.0.1.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:/home/workspace/data_stream.py with timestamp 1589865858098
2020-05-19 05:24:40 INFO  Utils:54 - /home/workspace/data_stream.py has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/data_stream.py
2020-05-19 05:24:40 INFO  Executor:54 - Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar with timestamp 1589865858147
2020-05-19 05:24:40 INFO  Utils:54 - /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar with timestamp 1589865858018
2020-05-19 05:24:40 INFO  TransportClientFactory:267 - Successfully created connection to 234cbc3ca30b/172.18.0.2:40389 after 122 ms (0 ms spent in bootstraps)
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/org.xerial.snappy_snappy-java-1.1.2.6.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp8418155887086594972.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp8418155887086594972.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.xerial.snappy_snappy-java-1.1.2.6.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.xerial.snappy_snappy-java-1.1.2.6.jar to class loader
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar with timestamp 1589865858015
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/org.apache.kafka_kafka-clients-0.10.0.1.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp1969911969028085366.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp1969911969028085366.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.kafka_kafka-clients-0.10.0.1.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.kafka_kafka-clients-0.10.0.1.jar to class loader
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1589865858015
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp4489344049396548028.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp4489344049396548028.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.spark-project.spark_unused-1.0.0.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.spark-project.spark_unused-1.0.0.jar to class loader
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar with timestamp 1589865858014
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp832563812955532661.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp832563812955532661.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.apache.spark_spark-sql-kafka-0-10_2.11-2.3.4.jar to class loader
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1589865858018
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp1443222200417365182.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp1443222200417365182.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.slf4j_slf4j-api-1.7.16.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/org.slf4j_slf4j-api-1.7.16.jar to class loader
2020-05-19 05:24:40 INFO  Executor:54 - Fetching spark://234cbc3ca30b:40389/jars/net.jpountz.lz4_lz4-1.3.0.jar with timestamp 1589865858017
2020-05-19 05:24:40 INFO  Utils:54 - Fetching spark://234cbc3ca30b:40389/jars/net.jpountz.lz4_lz4-1.3.0.jar to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp6265377931849020897.tmp
2020-05-19 05:24:40 INFO  Utils:54 - /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/fetchFileTemp6265377931849020897.tmp has been previously copied to /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/net.jpountz.lz4_lz4-1.3.0.jar
2020-05-19 05:24:40 INFO  Executor:54 - Adding file:/tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/userFiles-60c5ea04-cf8c-4428-b579-77cb74973588/net.jpountz.lz4_lz4-1.3.0.jar to class loader
2020-05-19 05:24:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

2020-05-19 05:24:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

2020-05-19 05:24:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2020-05-19 05:24:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2020-05-19 05:24:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

2020-05-19 05:24:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

2020-05-19 05:24:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2020-05-19 05:24:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 78.200319 ms
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 31.587477 ms
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 39.97128 ms
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 15.700026 ms
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 41.848522 ms
2020-05-19 05:24:41 INFO  CodeGenerator:54 - Code generated in 34.207977 ms
2020-05-19 05:24:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147483647 rack: null) for group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor.
2020-05-19 05:24:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147483647 rack: null) for group spark-kafka-source-7bb78d34-5b5d-42bd-a672-feffdd62bf21--1996019038-executor.
2020-05-19 05:24:43 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2289 bytes result sent to driver
2020-05-19 05:24:43 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 2289 bytes result sent to driver
2020-05-19 05:24:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 3488 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:43 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 3472 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-05-19 05:24:43 INFO  DAGScheduler:54 - ShuffleMapStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 3.658 s
2020-05-19 05:24:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:43 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2020-05-19 05:24:43 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:43 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 54.1 KB, free 365.6 MB)
2020-05-19 05:24:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 19.1 KB, free 365.6 MB)
2020-05-19 05:24:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:43 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:43 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:43 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 10 tasks
2020-05-19 05:24:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7754 bytes)
2020-05-19 05:24:43 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7754 bytes)
2020-05-19 05:24:43 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 2)
2020-05-19 05:24:43 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 3)
2020-05-19 05:24:43 INFO  StateStore:54 - State Store maintenance task started
2020-05-19 05:24:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c5ef8d5
2020-05-19 05:24:43 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43dcb8bd
2020-05-19 05:24:43 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65e839c7
2020-05-19 05:24:43 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61800d28
2020-05-19 05:24:43 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2020-05-19 05:24:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2020-05-19 05:24:43 INFO  CodeGenerator:54 - Code generated in 50.307163 ms
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/1.delta
2020-05-19 05:24:43 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/1.delta
2020-05-19 05:24:44 INFO  CodeGenerator:54 - Code generated in 37.443304 ms
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:44 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 2). 33947 bytes result sent to driver
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 4, localhost, executor driver, partition 2, ANY, 7754 bytes)
2020-05-19 05:24:44 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 4)
2020-05-19 05:24:44 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 3). 32962 bytes result sent to driver
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 5, localhost, executor driver, partition 3, ANY, 7754 bytes)
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 2) in 781 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:44 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 5)
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655f5a77
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c456e6f
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 3) in 812 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18d3dca8
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32cbd25f
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/1.delta
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/1.delta
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:44 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 5). 35692 bytes result sent to driver
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Starting task 4.0 in stage 1.0 (TID 6, localhost, executor driver, partition 4, ANY, 7754 bytes)
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 5) in 331 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:44 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 4). 34621 bytes result sent to driver
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Starting task 5.0 in stage 1.0 (TID 7, localhost, executor driver, partition 5, ANY, 7754 bytes)
2020-05-19 05:24:44 INFO  Executor:54 - Running task 5.0 in stage 1.0 (TID 7)
2020-05-19 05:24:44 INFO  Executor:54 - Running task 4.0 in stage 1.0 (TID 6)
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 4) in 406 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@624bafa3
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66742732
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cc0a03c
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55ebadb
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/1.delta
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/1.delta
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:44 INFO  Executor:54 - Finished task 5.0 in stage 1.0 (TID 7). 37735 bytes result sent to driver
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Starting task 6.0 in stage 1.0 (TID 8, localhost, executor driver, partition 6, ANY, 7754 bytes)
2020-05-19 05:24:44 INFO  Executor:54 - Running task 6.0 in stage 1.0 (TID 8)
2020-05-19 05:24:44 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:44 INFO  TaskSetManager:54 - Finished task 5.0 in stage 1.0 (TID 7) in 280 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c52f5e4
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cd9f9a7
2020-05-19 05:24:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:45 INFO  Executor:54 - Finished task 4.0 in stage 1.0 (TID 6). 35731 bytes result sent to driver
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Starting task 7.0 in stage 1.0 (TID 9, localhost, executor driver, partition 7, ANY, 7754 bytes)
2020-05-19 05:24:45 INFO  Executor:54 - Running task 7.0 in stage 1.0 (TID 9)
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Finished task 4.0 in stage 1.0 (TID 6) in 376 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@622a4536
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d5fda8
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/1.delta
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/1.delta
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:45 INFO  Executor:54 - Finished task 6.0 in stage 1.0 (TID 8). 38294 bytes result sent to driver
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Starting task 8.0 in stage 1.0 (TID 10, localhost, executor driver, partition 8, ANY, 7754 bytes)
2020-05-19 05:24:45 INFO  Executor:54 - Running task 8.0 in stage 1.0 (TID 10)
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Finished task 6.0 in stage 1.0 (TID 8) in 315 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3173923d
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ae26eef
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 8 ms
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:45 INFO  Executor:54 - Finished task 7.0 in stage 1.0 (TID 9). 36104 bytes result sent to driver
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Starting task 9.0 in stage 1.0 (TID 11, localhost, executor driver, partition 9, ANY, 7754 bytes)
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Finished task 7.0 in stage 1.0 (TID 9) in 351 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:45 INFO  Executor:54 - Running task 9.0 in stage 1.0 (TID 11)
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/1.delta
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d08240f
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6241a860
2020-05-19 05:24:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:45 INFO  Executor:54 - Finished task 8.0 in stage 1.0 (TID 10). 35051 bytes result sent to driver
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Finished task 8.0 in stage 1.0 (TID 10) in 254 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/1.delta
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:45 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:45 INFO  Executor:54 - Finished task 9.0 in stage 1.0 (TID 11). 34595 bytes result sent to driver
2020-05-19 05:24:45 INFO  TaskSetManager:54 - Finished task 9.0 in stage 1.0 (TID 11) in 272 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:45 INFO  DAGScheduler:54 - ResultStage 1 (start at NativeMethodAccessorImpl.java:0) finished in 2.162 s
2020-05-19 05:24:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-05-19 05:24:45 INFO  DAGScheduler:54 - Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 6.041620 s
2020-05-19 05:24:45 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@49472724 is committing.
-------------------------------------------
Batch: 0
-------------------------------------------
2020-05-19 05:24:46 INFO  CodeGenerator:54 - Code generated in 26.323331 ms
2020-05-19 05:24:46 INFO  CodeGenerator:54 - Code generated in 80.488122 ms
2020-05-19 05:24:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 16:00:00, 2018-12-29 17:00:00]|Audible Alarm           |2    |
|[2018-12-30 06:00:00, 2018-12-30 07:00:00]|Suspicious Person       |2    |
|[2018-12-31 05:00:00, 2018-12-31 06:00:00]|Assault / Battery       |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-31 19:00:00, 2018-12-31 20:00:00]|Suspicious Person       |1    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 08:00:00, 2018-12-31 09:00:00]|7.2.46                  |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-29 23:00:00, 2018-12-30 00:00:00]|Casers                  |1    |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 20:00:00, 2018-12-31 21:00:00]|Well Being Check        |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-29 03:00:00, 2018-12-29 04:00:00]|Casing                  |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:46 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@49472724 committed.
2020-05-19 05:24:46 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:46 INFO  DAGScheduler:54 - Job 1 finished: start at NativeMethodAccessorImpl.java:0, took 0.000066 s
2020-05-19 05:24:46 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:29.821Z",
  "batchId" : 0,
  "numInputRows" : 6314,
  "processedRowsPerSecond" : 377.0903010033445,
  "durationMs" : {
    "addBatch" : 11502,
    "getBatch" : 773,
    "getOffset" : 3585,
    "queryPlanning" : 767,
    "triggerExecution" : 16743,
    "walCommit" : 68
  },
  "eventTime" : {
    "avg" : "2018-12-30T09:22:31.244Z",
    "max" : "2018-12-31T23:57:00.000Z",
    "min" : "2018-12-28T17:25:00.000Z",
    "watermark" : "1970-01-01T00:00:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2800,
    "numRowsUpdated" : 2800,
    "memoryUsedBytes" : 758149
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : null,
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3207,
        "0" : 3107
      }
    },
    "numInputRows" : 6314,
    "processedRowsPerSecond" : 377.0903010033445
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:46 INFO  MicroBatchExecution:54 - Updating eventTime watermark to: 1546297020000 ms
2020-05-19 05:24:46 INFO  MicroBatchExecution:54 - Committed offsets for batch 1. Metadata OffsetSeqMetadata(1546297020000,1589865886827,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:46 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3207,"0":3107}}), end = {"department.police.service.call":{"1":3213,"0":3114}}
2020-05-19 05:24:46 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:47 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3107,3114,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3207,3213,None)
2020-05-19 05:24:47 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:47 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:47 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:24:47 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:47 INFO  SparkContext:54 - Created broadcast 4 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:24:47 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:47 INFO  SparkContext:54 - Created broadcast 5 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:47 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3e910cd4. The input RDD has 10 partitions.
2020-05-19 05:24:47 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Registering RDD 21 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Got job 2 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:24:47 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:47 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:47 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 2 tasks
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:47 INFO  Executor:54 - Running task 1.0 in stage 2.0 (TID 13)
2020-05-19 05:24:47 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 12)
2020-05-19 05:24:47 INFO  Executor:54 - Finished task 1.0 in stage 2.0 (TID 13). 2203 bytes result sent to driver
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 13) in 73 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:47 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 12). 2203 bytes result sent to driver
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 12) in 89 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-05-19 05:24:47 INFO  DAGScheduler:54 - ShuffleMapStage 2 (start at NativeMethodAccessorImpl.java:0) finished in 0.108 s
2020-05-19 05:24:47 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:47 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2020-05-19 05:24:47 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:24:47 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:24:47 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:47 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:47 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 3 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:47 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 10 tasks
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:47 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:47 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 14)
2020-05-19 05:24:47 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 15)
2020-05-19 05:24:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c473b30
2020-05-19 05:24:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@664e40e6
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@689ae93
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@686c040e
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/2.delta
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 14). 34047 bytes result sent to driver
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 16)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 14) in 228 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72a065b6
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b295630
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 15). 32962 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 17)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 15) in 287 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@328ffaca
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59562378
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/2.delta
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 16). 34719 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 18, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 18)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 16) in 219 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31d3cf55
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a28ede0
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 17). 35692 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 19, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 17) in 199 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 19)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f8e7c9c
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19a497cd
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 18). 35829 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 20, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 20)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 18) in 227 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27087329
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@101633db
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 19). 37837 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 21, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 21)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 19) in 223 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63a3aec5
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4040db90
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 21). 36104 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 22, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 21) in 128 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 22)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e1ecdd6
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b89bb62
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 20). 38389 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 23, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 20) in 225 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:48 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 23)
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@199d1dbf
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62964f75
2020-05-19 05:24:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/2.delta
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/2.delta
2020-05-19 05:24:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:48 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 22). 35051 bytes result sent to driver
2020-05-19 05:24:48 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 22) in 179 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:48 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:49 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:49 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 23). 34604 bytes result sent to driver
2020-05-19 05:24:49 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 23) in 191 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020-05-19 05:24:49 INFO  DAGScheduler:54 - ResultStage 3 (start at NativeMethodAccessorImpl.java:0) finished in 1.082 s
2020-05-19 05:24:49 INFO  DAGScheduler:54 - Job 2 finished: start at NativeMethodAccessorImpl.java:0, took 1.209285 s
2020-05-19 05:24:49 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3e910cd4 is committing.
-------------------------------------------
Batch: 1
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:49 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3e910cd4 committed.
2020-05-19 05:24:49 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:49 INFO  DAGScheduler:54 - Job 3 finished: start at NativeMethodAccessorImpl.java:0, took 0.000050 s
2020-05-19 05:24:49 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:46.811Z",
  "batchId" : 1,
  "numInputRows" : 13,
  "inputRowsPerSecond" : 0.7651559741024132,
  "processedRowsPerSecond" : 4.786450662739322,
  "durationMs" : {
    "addBatch" : 2249,
    "getBatch" : 22,
    "getOffset" : 12,
    "queryPlanning" : 248,
    "triggerExecution" : 2706,
    "walCommit" : 163
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:21:00.000Z",
    "max" : "2018-12-28T17:24:00.000Z",
    "min" : "2018-12-28T17:19:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2805,
    "numRowsUpdated" : 11,
    "memoryUsedBytes" : 702005
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3207,
        "0" : 3107
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3213,
        "0" : 3114
      }
    },
    "numInputRows" : 13,
    "inputRowsPerSecond" : 0.7651559741024132,
    "processedRowsPerSecond" : 4.786450662739322
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:49 INFO  MicroBatchExecution:54 - Committed offsets for batch 2. Metadata OffsetSeqMetadata(1546297020000,1589865889623,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:49 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3213,"0":3114}}), end = {"department.police.service.call":{"1":3215,"0":3115}}
2020-05-19 05:24:49 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:49 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3114,3115,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3213,3215,None)
2020-05-19 05:24:50 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:50 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:50 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 146
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 120
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 124
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 96
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 135
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 98
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 172
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 166
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 104
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 108
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 115
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 92
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 95
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 139
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 102
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 150
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 93
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 140
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 134
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 154
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 110
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 145
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 123
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 176
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 133
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 148
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 121
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 153
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 125
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 94
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 147
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 167
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 157
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 165
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 118
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 122
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 101
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 143
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 91
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 128
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 177
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 90
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 127
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 144
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 89
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 106
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 142
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 137
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 149
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 158
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 173
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 160
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 113
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 178
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 107
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 117
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 105
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 114
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 103
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 141
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 164
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 169
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 130
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 181
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 155
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 99
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 175
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 112
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 159
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.3 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 132
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 162
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 156
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 136
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 126
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 152
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 138
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 170
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 174
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 131
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 171
2020-05-19 05:24:50 INFO  SparkContext:54 - Created broadcast 8 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned shuffle 1
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 163
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 119
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 129
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 111
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 116
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 168
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 179
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 97
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 161
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 100
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 151
2020-05-19 05:24:50 INFO  ContextCleaner:54 - Cleaned accumulator 109
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  SparkContext:54 - Created broadcast 9 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:50 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@582b1c7b. The input RDD has 10 partitions.
2020-05-19 05:24:50 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Registering RDD 36 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Got job 4 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[36] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[36] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:50 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 2 tasks
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 25)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 24)
2020-05-19 05:24:50 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 24). 2203 bytes result sent to driver
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 24) in 77 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:50 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 25). 2203 bytes result sent to driver
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 25) in 83 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2020-05-19 05:24:50 INFO  DAGScheduler:54 - ShuffleMapStage 4 (start at NativeMethodAccessorImpl.java:0) finished in 0.104 s
2020-05-19 05:24:50 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:50 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:50 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2020-05-19 05:24:50 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[42] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:24:50 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:24:50 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:50 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:50 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 5 (MapPartitionsRDD[42] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:50 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 10 tasks
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 1.0 in stage 5.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 1.0 in stage 5.0 (TID 27)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 26)
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25447d54
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ba2e0fa
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@628711f0
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6364a701
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/3.delta
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/3.delta
2020-05-19 05:24:50 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:50 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:50 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:50 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:50 INFO  Executor:54 - Finished task 1.0 in stage 5.0 (TID 27). 32962 bytes result sent to driver
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 2.0 in stage 5.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 2.0 in stage 5.0 (TID 28)
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:50 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 26). 34047 bytes result sent to driver
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Starting task 3.0 in stage 5.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Finished task 1.0 in stage 5.0 (TID 27) in 195 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:50 INFO  Executor:54 - Running task 3.0 in stage 5.0 (TID 29)
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 26) in 202 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4699b528
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@765d9b50
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1536b8cd
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@82b0b58
2020-05-19 05:24:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/3.delta
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/3.delta
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 3.0 in stage 5.0 (TID 29). 35692 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 4.0 in stage 5.0 (TID 30, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 4.0 in stage 5.0 (TID 30)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 3.0 in stage 5.0 (TID 29) in 201 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 2.0 in stage 5.0 (TID 28). 34820 bytes result sent to driver
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36db0b01
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 5.0 in stage 5.0 (TID 31, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 5.0 in stage 5.0 (TID 31)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 2.0 in stage 5.0 (TID 28) in 229 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@241954d5
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ccd7250
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 8 ms
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6632369
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/3.delta
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/3.delta
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 4.0 in stage 5.0 (TID 30). 35829 bytes result sent to driver
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 6.0 in stage 5.0 (TID 32, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 6.0 in stage 5.0 (TID 32)
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 5.0 in stage 5.0 (TID 31). 37837 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 7.0 in stage 5.0 (TID 33, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 5.0 in stage 5.0 (TID 31) in 206 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 4.0 in stage 5.0 (TID 30) in 223 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 7.0 in stage 5.0 (TID 33)
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39c216f0
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@137f1ee5
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cd398e8
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3390bc26
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/3.delta
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/3.delta
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 6.0 in stage 5.0 (TID 32). 38389 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 8.0 in stage 5.0 (TID 34, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 8.0 in stage 5.0 (TID 34)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 6.0 in stage 5.0 (TID 32) in 199 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b443081
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a5469e2
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 7.0 in stage 5.0 (TID 33). 36104 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Starting task 9.0 in stage 5.0 (TID 35, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 7.0 in stage 5.0 (TID 33) in 240 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:51 INFO  Executor:54 - Running task 9.0 in stage 5.0 (TID 35)
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cc53fc9
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@671119ed
2020-05-19 05:24:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/3.delta
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 3 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/3.delta
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:51 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 8.0 in stage 5.0 (TID 34). 35051 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 8.0 in stage 5.0 (TID 34) in 210 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 3 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:51 INFO  Executor:54 - Finished task 9.0 in stage 5.0 (TID 35). 34604 bytes result sent to driver
2020-05-19 05:24:51 INFO  TaskSetManager:54 - Finished task 9.0 in stage 5.0 (TID 35) in 172 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2020-05-19 05:24:51 INFO  DAGScheduler:54 - ResultStage 5 (start at NativeMethodAccessorImpl.java:0) finished in 1.043 s
2020-05-19 05:24:51 INFO  DAGScheduler:54 - Job 4 finished: start at NativeMethodAccessorImpl.java:0, took 1.177587 s
2020-05-19 05:24:51 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@582b1c7b is committing.
-------------------------------------------
Batch: 2
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:52 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@582b1c7b committed.
2020-05-19 05:24:52 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:52 INFO  DAGScheduler:54 - Job 5 finished: start at NativeMethodAccessorImpl.java:0, took 0.000046 s
2020-05-19 05:24:52 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:49.619Z",
  "batchId" : 2,
  "numInputRows" : 3,
  "inputRowsPerSecond" : 1.0683760683760684,
  "processedRowsPerSecond" : 1.1655011655011656,
  "durationMs" : {
    "addBatch" : 2259,
    "getBatch" : 9,
    "getOffset" : 3,
    "queryPlanning" : 187,
    "triggerExecution" : 2574,
    "walCommit" : 114
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:18:20.000Z",
    "max" : "2018-12-28T17:19:00.000Z",
    "min" : "2018-12-28T17:18:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2806,
    "numRowsUpdated" : 3,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3213,
        "0" : 3114
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3215,
        "0" : 3115
      }
    },
    "numInputRows" : 3,
    "inputRowsPerSecond" : 1.0683760683760684,
    "processedRowsPerSecond" : 1.1655011655011656
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:52 INFO  MicroBatchExecution:54 - Committed offsets for batch 3. Metadata OffsetSeqMetadata(1546297020000,1589865892286,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:52 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3215,"0":3115}}), end = {"department.police.service.call":{"1":3217,"0":3116}}
2020-05-19 05:24:52 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:52 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3115,3116,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3215,3217,None)
2020-05-19 05:24:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:52 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:24:52 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:24:52 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:52 INFO  SparkContext:54 - Created broadcast 12 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  SparkContext:54 - Created broadcast 13 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:53 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@126c96cf. The input RDD has 10 partitions.
2020-05-19 05:24:53 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Registering RDD 51 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Got job 6 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:53 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 2 tasks
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 36)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 37)
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 37). 2246 bytes result sent to driver
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 36). 2203 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 37) in 65 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 36) in 67 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2020-05-19 05:24:53 INFO  DAGScheduler:54 - ShuffleMapStage 6 (start at NativeMethodAccessorImpl.java:0) finished in 0.082 s
2020-05-19 05:24:53 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:53 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2020-05-19 05:24:53 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Submitting ResultStage 7 (MapPartitionsRDD[57] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:24:53 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:53 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[57] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:53 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 10 tasks
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 7.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 38)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 1.0 in stage 7.0 (TID 39)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77498417
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b1f25d
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bb03eab
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ea831da
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 9 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/4.delta
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/4.delta
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 1.0 in stage 7.0 (TID 39). 32962 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 2.0 in stage 7.0 (TID 40, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 2.0 in stage 7.0 (TID 40)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 7.0 (TID 39) in 249 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 253
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 258
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 204
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 254
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 247
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 265
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 232
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 250
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 191
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 210
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 270
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 193
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 212
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 215
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 206
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 209
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 200
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 207
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 255
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 228
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 245
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 195
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 190
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 230
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aabddbd
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 183
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 188
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 208
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 192
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 182
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 259
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34376772
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned shuffle 2
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 226
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 187
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 241
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 268
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 234
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 197
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 243
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 260
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 267
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 235
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 38). 34090 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 3.0 in stage 7.0 (TID 41, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 3.0 in stage 7.0 (TID 41)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 38) in 320 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 242
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 202
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 224
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 252
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 198
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 194
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 248
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 201
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 229
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 199
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 221
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 216
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 261
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 266
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 218
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 217
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 184
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 256
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 233
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 186
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 205
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 257
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 189
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 219
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 222
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 227
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 236
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 185
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 240
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 237
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 196
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 213
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 220
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@325a294c
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 223
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 244
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 246
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 262
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 249
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 238
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 231
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 263
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 251
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 214
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 225
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fe50bfa
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:53 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 180
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 203
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 264
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 211
2020-05-19 05:24:53 INFO  ContextCleaner:54 - Cleaned accumulator 239
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/4.delta
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/4.delta
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 2.0 in stage 7.0 (TID 40). 34863 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 4.0 in stage 7.0 (TID 42, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 4.0 in stage 7.0 (TID 42)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 2.0 in stage 7.0 (TID 40) in 194 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b3a57d4
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fc28bec
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/4.delta
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 3.0 in stage 7.0 (TID 41). 35692 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 5.0 in stage 7.0 (TID 43, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 5.0 in stage 7.0 (TID 43)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 3.0 in stage 7.0 (TID 41) in 202 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a4db472
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bd97ec7
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 4.0 in stage 7.0 (TID 42). 35829 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 6.0 in stage 7.0 (TID 44, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 6.0 in stage 7.0 (TID 44)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 4.0 in stage 7.0 (TID 42) in 127 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e73b799
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c094de9
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/4.delta
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/4.delta
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 5.0 in stage 7.0 (TID 43). 37837 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 7.0 in stage 7.0 (TID 45, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 7.0 in stage 7.0 (TID 45)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 5.0 in stage 7.0 (TID 43) in 169 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8a23da
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ddf435a
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:53 INFO  Executor:54 - Finished task 6.0 in stage 7.0 (TID 44). 38389 bytes result sent to driver
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Starting task 8.0 in stage 7.0 (TID 46, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:53 INFO  Executor:54 - Running task 8.0 in stage 7.0 (TID 46)
2020-05-19 05:24:53 INFO  TaskSetManager:54 - Finished task 6.0 in stage 7.0 (TID 44) in 151 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@704835c
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668f7803
2020-05-19 05:24:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/4.delta
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:53 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/4.delta
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:54 INFO  Executor:54 - Finished task 7.0 in stage 7.0 (TID 45). 36104 bytes result sent to driver
2020-05-19 05:24:54 INFO  TaskSetManager:54 - Starting task 9.0 in stage 7.0 (TID 47, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:54 INFO  Executor:54 - Running task 9.0 in stage 7.0 (TID 47)
2020-05-19 05:24:54 INFO  TaskSetManager:54 - Finished task 7.0 in stage 7.0 (TID 45) in 150 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a5a1b7
2020-05-19 05:24:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668e2bdd
2020-05-19 05:24:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 3 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:54 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:54 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 4 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/4.delta
2020-05-19 05:24:54 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:54 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:54 INFO  Executor:54 - Finished task 8.0 in stage 7.0 (TID 46). 35051 bytes result sent to driver
2020-05-19 05:24:54 INFO  TaskSetManager:54 - Finished task 8.0 in stage 7.0 (TID 46) in 209 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 4 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:54 INFO  Executor:54 - Finished task 9.0 in stage 7.0 (TID 47). 34604 bytes result sent to driver
2020-05-19 05:24:54 INFO  TaskSetManager:54 - Finished task 9.0 in stage 7.0 (TID 47) in 106 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:54 INFO  DAGScheduler:54 - ResultStage 7 (start at NativeMethodAccessorImpl.java:0) finished in 0.964 s
2020-05-19 05:24:54 INFO  DAGScheduler:54 - Job 6 finished: start at NativeMethodAccessorImpl.java:0, took 1.060500 s
2020-05-19 05:24:54 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@126c96cf is committing.
-------------------------------------------
Batch: 3
-------------------------------------------
2020-05-19 05:24:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:54 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@126c96cf committed.
2020-05-19 05:24:54 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:54 INFO  DAGScheduler:54 - Job 7 finished: start at NativeMethodAccessorImpl.java:0, took 0.000054 s
2020-05-19 05:24:54 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:52.279Z",
  "batchId" : 3,
  "numInputRows" : 3,
  "inputRowsPerSecond" : 1.1278195488721805,
  "processedRowsPerSecond" : 1.4177693761814745,
  "durationMs" : {
    "addBatch" : 1806,
    "getBatch" : 9,
    "getOffset" : 7,
    "queryPlanning" : 187,
    "triggerExecution" : 2116,
    "walCommit" : 105
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:17:40.000Z",
    "max" : "2018-12-28T17:18:00.000Z",
    "min" : "2018-12-28T17:17:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2806,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3215,
        "0" : 3115
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3217,
        "0" : 3116
      }
    },
    "numInputRows" : 3,
    "inputRowsPerSecond" : 1.1278195488721805,
    "processedRowsPerSecond" : 1.4177693761814745
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:54 INFO  MicroBatchExecution:54 - Committed offsets for batch 4. Metadata OffsetSeqMetadata(1546297020000,1589865894511,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:54 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3217,"0":3116}}), end = {"department.police.service.call":{"1":3218,"0":3117}}
2020-05-19 05:24:54 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:54 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3116,3117,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3217,3218,None)
2020-05-19 05:24:54 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:54 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:54 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:24:55 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:55 INFO  SparkContext:54 - Created broadcast 16 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:24:55 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:55 INFO  SparkContext:54 - Created broadcast 17 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:55 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4f2e923a. The input RDD has 10 partitions.
2020-05-19 05:24:55 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Registering RDD 66 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Got job 8 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 8)
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 8 (MapPartitionsRDD[66] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:24:55 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:24:55 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[66] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:55 INFO  TaskSchedulerImpl:54 - Adding task set 8.0 with 2 tasks
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 1.0 in stage 8.0 (TID 49, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 0.0 in stage 8.0 (TID 48)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 1.0 in stage 8.0 (TID 49)
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 0.0 in stage 8.0 (TID 48). 2203 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 48) in 51 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 1.0 in stage 8.0 (TID 49). 2203 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 8.0 (TID 49) in 58 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:55 INFO  TaskSchedulerImpl:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2020-05-19 05:24:55 INFO  DAGScheduler:54 - ShuffleMapStage 8 (start at NativeMethodAccessorImpl.java:0) finished in 0.070 s
2020-05-19 05:24:55 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:55 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:55 INFO  DAGScheduler:54 - waiting: Set(ResultStage 9)
2020-05-19 05:24:55 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Submitting ResultStage 9 (MapPartitionsRDD[72] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:24:55 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:24:55 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:24:55 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:55 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 9 (MapPartitionsRDD[72] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:55 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 10 tasks
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 1.0 in stage 9.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 50)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 1.0 in stage 9.0 (TID 51)
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b2d4427
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@224317bb
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f28a0d1
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2af4f647
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/5.delta
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/5.delta
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 1.0 in stage 9.0 (TID 51). 32962 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 2.0 in stage 9.0 (TID 52, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 9.0 (TID 51) in 177 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 2.0 in stage 9.0 (TID 52)
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d59b340
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d6fac98
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 50). 34047 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 3.0 in stage 9.0 (TID 53, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 3.0 in stage 9.0 (TID 53)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 50) in 205 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cdd282b
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17dc3be1
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/5.delta
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/5.delta
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 2.0 in stage 9.0 (TID 52). 34820 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 4.0 in stage 9.0 (TID 54, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 4.0 in stage 9.0 (TID 54)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 2.0 in stage 9.0 (TID 52) in 221 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f94958
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62b65e8f
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:55 INFO  Executor:54 - Finished task 3.0 in stage 9.0 (TID 53). 35804 bytes result sent to driver
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Starting task 5.0 in stage 9.0 (TID 55, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:55 INFO  TaskSetManager:54 - Finished task 3.0 in stage 9.0 (TID 53) in 230 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:55 INFO  Executor:54 - Running task 5.0 in stage 9.0 (TID 55)
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@289838d7
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40cf55d1
2020-05-19 05:24:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/5.delta
2020-05-19 05:24:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/5.delta
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:55 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 5.0 in stage 9.0 (TID 55). 37837 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Starting task 6.0 in stage 9.0 (TID 56, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:56 INFO  Executor:54 - Running task 6.0 in stage 9.0 (TID 56)
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 5.0 in stage 9.0 (TID 55) in 162 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bb5bebf
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57c3d1c4
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 4.0 in stage 9.0 (TID 54). 35829 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Starting task 7.0 in stage 9.0 (TID 57, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:56 INFO  Executor:54 - Running task 7.0 in stage 9.0 (TID 57)
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 4.0 in stage 9.0 (TID 54) in 227 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 6 ms
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ddd4d2e
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72d7d192
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/5.delta
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/5.delta
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 7.0 in stage 9.0 (TID 57). 36104 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Starting task 8.0 in stage 9.0 (TID 58, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 7.0 in stage 9.0 (TID 57) in 146 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:56 INFO  Executor:54 - Running task 8.0 in stage 9.0 (TID 58)
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70fe978e
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 6.0 in stage 9.0 (TID 56). 38389 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Starting task 9.0 in stage 9.0 (TID 59, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:56 INFO  Executor:54 - Running task 9.0 in stage 9.0 (TID 59)
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 6.0 in stage 9.0 (TID 56) in 190 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6051d448
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a283a28
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74becbc4
2020-05-19 05:24:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 4 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/5.delta
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 5 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/5.delta
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:56 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 274
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 289
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 295
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 307
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 273
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 347
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 311
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 338
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 321
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 275
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 301
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 296
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 324
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 335
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 280
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 305
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 288
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 302
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 339
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 340
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 282
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 276
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 271
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 312
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 343
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 298
2020-05-19 05:24:56 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 306
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 319
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 272
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 315
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 330
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 297
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 292
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 329
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 356
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 300
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 294
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 348
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 331
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 353
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 354
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 309
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 284
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 351
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 336
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 346
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 279
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 308
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 342
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 269
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 287
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 293
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 345
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 286
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 314
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 318
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 290
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 341
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 285
2020-05-19 05:24:56 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 316
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 344
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 357
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 349
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 350
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 322
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 325
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 299
2020-05-19 05:24:56 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 352
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 359
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 317
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 355
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 334
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 278
2020-05-19 05:24:56 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 323
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 310
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 291
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 283
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 320
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 332
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 313
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 326
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 333
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 328
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 281
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 303
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 327
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 337
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 304
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned accumulator 277
2020-05-19 05:24:56 INFO  ContextCleaner:54 - Cleaned shuffle 3
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 8.0 in stage 9.0 (TID 58). 35094 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 8.0 in stage 9.0 (TID 58) in 264 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 5 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:56 INFO  Executor:54 - Finished task 9.0 in stage 9.0 (TID 59). 34647 bytes result sent to driver
2020-05-19 05:24:56 INFO  TaskSetManager:54 - Finished task 9.0 in stage 9.0 (TID 59) in 299 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:56 INFO  DAGScheduler:54 - ResultStage 9 (start at NativeMethodAccessorImpl.java:0) finished in 1.084 s
2020-05-19 05:24:56 INFO  DAGScheduler:54 - Job 8 finished: start at NativeMethodAccessorImpl.java:0, took 1.174762 s
2020-05-19 05:24:56 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4f2e923a is committing.
-------------------------------------------
Batch: 4
-------------------------------------------
2020-05-19 05:24:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:56 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4f2e923a committed.
2020-05-19 05:24:56 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:56 INFO  DAGScheduler:54 - Job 9 finished: start at NativeMethodAccessorImpl.java:0, took 0.000055 s
2020-05-19 05:24:56 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:54.506Z",
  "batchId" : 4,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.898069151324652,
  "processedRowsPerSecond" : 0.8227067050596463,
  "durationMs" : {
    "addBatch" : 2175,
    "getBatch" : 12,
    "getOffset" : 4,
    "queryPlanning" : 131,
    "triggerExecution" : 2431,
    "walCommit" : 105
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:16:30.000Z",
    "max" : "2018-12-28T17:17:00.000Z",
    "min" : "2018-12-28T17:16:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2807,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3217,
        "0" : 3116
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3218,
        "0" : 3117
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.898069151324652,
    "processedRowsPerSecond" : 0.8227067050596463
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:57 INFO  MicroBatchExecution:54 - Committed offsets for batch 5. Metadata OffsetSeqMetadata(1546297020000,1589865897028,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:57 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3218,"0":3117}}), end = {"department.police.service.call":{"1":3220,"0":3117}}
2020-05-19 05:24:57 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:57 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3117,3117,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3218,3220,None)
2020-05-19 05:24:57 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:57 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:57 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:24:57 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:57 INFO  SparkContext:54 - Created broadcast 20 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:24:57 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:57 INFO  SparkContext:54 - Created broadcast 21 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:57 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6049846e. The input RDD has 10 partitions.
2020-05-19 05:24:57 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Registering RDD 81 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Got job 10 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 10)
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 10 (MapPartitionsRDD[81] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:24:57 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:24:57 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[81] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:24:57 INFO  TaskSchedulerImpl:54 - Adding task set 10.0 with 2 tasks
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 1.0 in stage 10.0 (TID 61, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 0.0 in stage 10.0 (TID 60)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 1.0 in stage 10.0 (TID 61)
2020-05-19 05:24:57 INFO  KafkaSourceRDD:54 - Beginning offset 3117 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:24:57 INFO  Executor:54 - Finished task 1.0 in stage 10.0 (TID 61). 2074 bytes result sent to driver
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Finished task 1.0 in stage 10.0 (TID 61) in 66 ms on localhost (executor driver) (1/2)
2020-05-19 05:24:57 INFO  Executor:54 - Finished task 0.0 in stage 10.0 (TID 60). 2203 bytes result sent to driver
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 60) in 76 ms on localhost (executor driver) (2/2)
2020-05-19 05:24:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2020-05-19 05:24:57 INFO  DAGScheduler:54 - ShuffleMapStage 10 (start at NativeMethodAccessorImpl.java:0) finished in 0.083 s
2020-05-19 05:24:57 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:24:57 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:24:57 INFO  DAGScheduler:54 - waiting: Set(ResultStage 11)
2020-05-19 05:24:57 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[87] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:24:57 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:24:57 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:24:57 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:24:57 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 11 (MapPartitionsRDD[87] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:24:57 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 10 tasks
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 1.0 in stage 11.0 (TID 63, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 1.0 in stage 11.0 (TID 63)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 62)
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66b0261
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a33fe8f
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bd11931
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@115af73f
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/6.delta
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/6.delta
2020-05-19 05:24:57 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:24:57 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:24:57 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:24:57 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:24:57 INFO  Executor:54 - Finished task 1.0 in stage 11.0 (TID 63). 32962 bytes result sent to driver
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 2.0 in stage 11.0 (TID 64, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Finished task 1.0 in stage 11.0 (TID 63) in 168 ms on localhost (executor driver) (1/10)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 2.0 in stage 11.0 (TID 64)
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:24:57 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 62). 34047 bytes result sent to driver
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Starting task 3.0 in stage 11.0 (TID 65, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:57 INFO  Executor:54 - Running task 3.0 in stage 11.0 (TID 65)
2020-05-19 05:24:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 62) in 186 ms on localhost (executor driver) (2/10)
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cffb4d5
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68e037b0
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@175a46a5
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c5ed000
2020-05-19 05:24:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/6.delta
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/6.delta
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 3.0 in stage 11.0 (TID 65). 35804 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 4.0 in stage 11.0 (TID 66, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 4.0 in stage 11.0 (TID 66)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5504730b
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@751d7bbe
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 3.0 in stage 11.0 (TID 65) in 135 ms on localhost (executor driver) (3/10)
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 2.0 in stage 11.0 (TID 64). 34820 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 5.0 in stage 11.0 (TID 67, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 5.0 in stage 11.0 (TID 67)
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 2.0 in stage 11.0 (TID 64) in 166 ms on localhost (executor driver) (4/10)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b702ac3
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@484f1821
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/6.delta
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/6.delta
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 4.0 in stage 11.0 (TID 66). 35829 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 6.0 in stage 11.0 (TID 68, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 4.0 in stage 11.0 (TID 66) in 181 ms on localhost (executor driver) (5/10)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 6.0 in stage 11.0 (TID 68)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33ba3cae
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57271f40
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 5.0 in stage 11.0 (TID 67). 37837 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 7.0 in stage 11.0 (TID 69, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 7.0 in stage 11.0 (TID 69)
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 5.0 in stage 11.0 (TID 67) in 185 ms on localhost (executor driver) (6/10)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52409b8f
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66c6387a
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 24 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/6.delta
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/6.delta
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 6.0 in stage 11.0 (TID 68). 38389 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 8.0 in stage 11.0 (TID 70, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 8.0 in stage 11.0 (TID 70)
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 6.0 in stage 11.0 (TID 68) in 178 ms on localhost (executor driver) (7/10)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f1bd217
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c076905
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 7.0 in stage 11.0 (TID 69). 36104 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Starting task 9.0 in stage 11.0 (TID 71, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:24:58 INFO  Executor:54 - Running task 9.0 in stage 11.0 (TID 71)
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 7.0 in stage 11.0 (TID 69) in 175 ms on localhost (executor driver) (8/10)
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@374a9cf3
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:24:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:24:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6484aa8a
2020-05-19 05:24:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 5 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:24:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/6.delta
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 6 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/6.delta
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:24:58 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 9.0 in stage 11.0 (TID 71). 34604 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 9.0 in stage 11.0 (TID 71) in 144 ms on localhost (executor driver) (9/10)
2020-05-19 05:24:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 6 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:24:58 INFO  Executor:54 - Finished task 8.0 in stage 11.0 (TID 70). 35149 bytes result sent to driver
2020-05-19 05:24:58 INFO  TaskSetManager:54 - Finished task 8.0 in stage 11.0 (TID 70) in 182 ms on localhost (executor driver) (10/10)
2020-05-19 05:24:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2020-05-19 05:24:58 INFO  DAGScheduler:54 - ResultStage 11 (start at NativeMethodAccessorImpl.java:0) finished in 0.850 s
2020-05-19 05:24:58 INFO  DAGScheduler:54 - Job 10 finished: start at NativeMethodAccessorImpl.java:0, took 0.952958 s
2020-05-19 05:24:58 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6049846e is committing.
-------------------------------------------
Batch: 5
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:24:58 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6049846e committed.
2020-05-19 05:24:58 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:58 INFO  DAGScheduler:54 - Job 11 finished: start at NativeMethodAccessorImpl.java:0, took 0.000057 s
2020-05-19 05:24:59 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:57.023Z",
  "batchId" : 5,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.7945967421533572,
  "processedRowsPerSecond" : 1.0126582278481011,
  "durationMs" : {
    "addBatch" : 1796,
    "getBatch" : 12,
    "getOffset" : 5,
    "queryPlanning" : 94,
    "triggerExecution" : 1975,
    "walCommit" : 66
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:16:00.000Z",
    "max" : "2018-12-28T17:16:00.000Z",
    "min" : "2018-12-28T17:16:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2808,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3218,
        "0" : 3117
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3220,
        "0" : 3117
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.7945967421533572,
    "processedRowsPerSecond" : 1.0126582278481011
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:24:59 INFO  MicroBatchExecution:54 - Committed offsets for batch 6. Metadata OffsetSeqMetadata(1546297020000,1589865899127,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:24:59 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3220,"0":3117}}), end = {"department.police.service.call":{"1":3221,"0":3118}}
2020-05-19 05:24:59 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:24:59 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3117,3118,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3220,3221,None)
2020-05-19 05:24:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 531
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 401
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 434
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 450
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 418
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 364
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 535
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 407
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 521
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 386
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 422
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 365
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 385
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 410
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 475
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 474
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 484
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 457
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 442
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 502
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 373
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 499
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 420
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 400
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 438
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 500
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 473
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 479
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 423
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 514
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 533
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 398
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 490
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 367
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 426
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 528
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 496
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 448
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 392
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 362
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 480
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 416
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 487
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 489
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 370
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 507
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:24:59 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 281.8 KB, free 364.6 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 390
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 431
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 472
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 366
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 452
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 523
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 379
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 526
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 368
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 451
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 444
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 488
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 494
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 537
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 399
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 408
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 417
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 404
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 412
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 458
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 449
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 413
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 406
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 395
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 428
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 513
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 382
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 427
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 483
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 530
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 486
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 493
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 524
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned shuffle 4
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 468
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 477
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 501
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 369
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 403
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 380
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 388
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 467
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 455
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 471
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 384
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 510
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 389
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned shuffle 5
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 391
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 402
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 516
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 409
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 440
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 394
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 372
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 439
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 506
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 534
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 481
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 461
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 411
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 519
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 504
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 525
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 466
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 363
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 482
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 381
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 430
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 358
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 470
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 527
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 374
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 405
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 518
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 376
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 387
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 492
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 437
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 465
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 462
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 532
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 503
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 522
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 436
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 512
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 469
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 425
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 485
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 432
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 375
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 441
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 361
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 497
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 456
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 393
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 498
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 445
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 414
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 515
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 495
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 396
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 463
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 371
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 517
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 454
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 529
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 508
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 459
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 505
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 397
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 443
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 478
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 446
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 435
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 419
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 447
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 378
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 360
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 509
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 476
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 491
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 511
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 421
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 453
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 377
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 424
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 433
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 429
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 520
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 383
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 460
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 464
2020-05-19 05:24:59 INFO  ContextCleaner:54 - Cleaned accumulator 415
2020-05-19 05:24:59 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:24:59 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:24:59 INFO  SparkContext:54 - Created broadcast 24 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:24:59 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:00 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:00 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:00 INFO  SparkContext:54 - Created broadcast 25 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:00 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6ca3597f. The input RDD has 10 partitions.
2020-05-19 05:25:00 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Registering RDD 96 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Got job 12 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[96] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:00 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:00 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:00 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:00 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[96] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:00 INFO  TaskSchedulerImpl:54 - Adding task set 12.0 with 2 tasks
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 12.0 (TID 73, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 0.0 in stage 12.0 (TID 72)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 1.0 in stage 12.0 (TID 73)
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 0.0 in stage 12.0 (TID 72). 2203 bytes result sent to driver
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 1.0 in stage 12.0 (TID 73). 2203 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 72) in 55 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 12.0 (TID 73) in 57 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2020-05-19 05:25:00 INFO  DAGScheduler:54 - ShuffleMapStage 12 (start at NativeMethodAccessorImpl.java:0) finished in 0.072 s
2020-05-19 05:25:00 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:00 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:00 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)
2020-05-19 05:25:00 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[102] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:00 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:00 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:00 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:00 INFO  SparkContext:54 - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 13 (MapPartitionsRDD[102] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:00 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 10 tasks
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 13.0 (TID 75, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 74)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 1.0 in stage 13.0 (TID 75)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@718e077f
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6216e02e
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@558884e8
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c5ec3c4
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/7.delta
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/7.delta
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 74). 34047 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 13.0 (TID 76, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 74) in 163 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 2.0 in stage 13.0 (TID 76)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34223a1b
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65c42013
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 1.0 in stage 13.0 (TID 75). 32962 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 3.0 in stage 13.0 (TID 77, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 3.0 in stage 13.0 (TID 77)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 13.0 (TID 75) in 213 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15747522
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a415576
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/7.delta
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/7.delta
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 2.0 in stage 13.0 (TID 76). 34820 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 4.0 in stage 13.0 (TID 78, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 4.0 in stage 13.0 (TID 78)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 13.0 (TID 76) in 185 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c9e1eb5
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27c7434e
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 3.0 in stage 13.0 (TID 77). 35804 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 5.0 in stage 13.0 (TID 79, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 5.0 in stage 13.0 (TID 79)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 3.0 in stage 13.0 (TID 77) in 149 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d82755
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@606630ad
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/7.delta
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/7.delta
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 4.0 in stage 13.0 (TID 78). 35829 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 6.0 in stage 13.0 (TID 80, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 6.0 in stage 13.0 (TID 80)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 4.0 in stage 13.0 (TID 78) in 121 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73165a75
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61f0bb0a
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 5.0 in stage 13.0 (TID 79). 37837 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 7.0 in stage 13.0 (TID 81, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 7.0 in stage 13.0 (TID 81)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 5.0 in stage 13.0 (TID 79) in 131 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a3ed46a
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8cfebbc
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/7.delta
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/7.delta
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 6.0 in stage 13.0 (TID 80). 38389 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 8.0 in stage 13.0 (TID 82, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 6.0 in stage 13.0 (TID 80) in 165 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 8.0 in stage 13.0 (TID 82)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e31020
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fca32e4
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 7.0 in stage 13.0 (TID 81). 36200 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Starting task 9.0 in stage 13.0 (TID 83, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:00 INFO  Executor:54 - Running task 9.0 in stage 13.0 (TID 83)
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 7.0 in stage 13.0 (TID 81) in 158 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@431a23fc
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437527c7
2020-05-19 05:25:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 6 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/7.delta
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 7 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/7.delta
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:00 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 8.0 in stage 13.0 (TID 82). 35149 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 8.0 in stage 13.0 (TID 82) in 181 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 7 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:00 INFO  Executor:54 - Finished task 9.0 in stage 13.0 (TID 83). 34604 bytes result sent to driver
2020-05-19 05:25:00 INFO  TaskSetManager:54 - Finished task 9.0 in stage 13.0 (TID 83) in 176 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2020-05-19 05:25:00 INFO  DAGScheduler:54 - ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 0.831 s
2020-05-19 05:25:00 INFO  DAGScheduler:54 - Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 0.911546 s
2020-05-19 05:25:00 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6ca3597f is committing.
-------------------------------------------
Batch: 6
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:01 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6ca3597f committed.
2020-05-19 05:25:01 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:01 INFO  DAGScheduler:54 - Job 13 finished: start at NativeMethodAccessorImpl.java:0, took 0.000048 s
2020-05-19 05:25:01 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:24:59.121Z",
  "batchId" : 6,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.9532888465204957,
  "processedRowsPerSecond" : 0.9170105456212746,
  "durationMs" : {
    "addBatch" : 1830,
    "getBatch" : 9,
    "getOffset" : 6,
    "queryPlanning" : 185,
    "triggerExecution" : 2181,
    "walCommit" : 150
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:14:30.000Z",
    "max" : "2018-12-28T17:15:00.000Z",
    "min" : "2018-12-28T17:14:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2809,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3220,
        "0" : 3117
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3221,
        "0" : 3118
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.9532888465204957,
    "processedRowsPerSecond" : 0.9170105456212746
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:01 INFO  MicroBatchExecution:54 - Committed offsets for batch 7. Metadata OffsetSeqMetadata(1546297020000,1589865901393,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:01 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3221,"0":3118}}), end = {"department.police.service.call":{"1":3222,"0":3120}}
2020-05-19 05:25:01 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:01 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3118,3120,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3221,3222,None)
2020-05-19 05:25:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:01 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:01 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:01 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:01 INFO  SparkContext:54 - Created broadcast 28 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  SparkContext:54 - Created broadcast 29 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:02 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25016760. The input RDD has 10 partitions.
2020-05-19 05:25:02 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Registering RDD 111 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Got job 14 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 14)
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 14)
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  SparkContext:54 - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:02 INFO  TaskSchedulerImpl:54 - Adding task set 14.0 with 2 tasks
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 14.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 0.0 in stage 14.0 (TID 84)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 1.0 in stage 14.0 (TID 85)
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 1.0 in stage 14.0 (TID 85). 2203 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 14.0 (TID 85) in 50 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 0.0 in stage 14.0 (TID 84). 2203 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 84) in 60 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2020-05-19 05:25:02 INFO  DAGScheduler:54 - ShuffleMapStage 14 (start at NativeMethodAccessorImpl.java:0) finished in 0.071 s
2020-05-19 05:25:02 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:02 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:02 INFO  DAGScheduler:54 - waiting: Set(ResultStage 15)
2020-05-19 05:25:02 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Submitting ResultStage 15 (MapPartitionsRDD[117] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:02 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  SparkContext:54 - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:02 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 15 (MapPartitionsRDD[117] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:02 INFO  TaskSchedulerImpl:54 - Adding task set 15.0 with 10 tasks
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 15.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 0.0 in stage 15.0 (TID 86)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 1.0 in stage 15.0 (TID 87)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b916153
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@515b72bd
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66828e1b
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@627fe278
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/8.delta
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/8.delta
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 561
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 590
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 589
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 624
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 551
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 582
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 557
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 576
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 592
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 574
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 610
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 598
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 544
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 569
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 552
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 559
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 608
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 550
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 549
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 619
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 545
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 575
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 595
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 564
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 560
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 609
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 615
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 573
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 577
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 623
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 614
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 548
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 558
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 586
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 578
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 540
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 594
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 553
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 601
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 542
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 581
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 596
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 612
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 617
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 603
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned shuffle 6
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 543
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 572
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 584
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 606
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 566
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 621
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 583
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 611
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 538
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 568
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 613
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 555
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 618
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 565
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 599
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 607
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 600
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 563
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 580
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 591
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 597
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 547
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 626
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 554
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 541
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 585
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 579
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 622
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 539
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 587
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 604
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 536
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 570
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 546
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 571
2020-05-19 05:25:02 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 605
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 562
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 602
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 616
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 556
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 588
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 593
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 620
2020-05-19 05:25:02 INFO  ContextCleaner:54 - Cleaned accumulator 567
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 1.0 in stage 15.0 (TID 87). 33005 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 15.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 15.0 (TID 87) in 215 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 2.0 in stage 15.0 (TID 88)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7462c771
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63bc5e6b
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 0.0 in stage 15.0 (TID 86). 34090 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 3.0 in stage 15.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 86) in 228 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 3.0 in stage 15.0 (TID 89)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68f35d85
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3864c318
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/8.delta
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/8.delta
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 2.0 in stage 15.0 (TID 88). 34820 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 4.0 in stage 15.0 (TID 90, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 15.0 (TID 88) in 157 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 4.0 in stage 15.0 (TID 90)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@268e31e0
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36b403e0
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 3.0 in stage 15.0 (TID 89). 35804 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 5.0 in stage 15.0 (TID 91, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 3.0 in stage 15.0 (TID 89) in 229 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 5.0 in stage 15.0 (TID 91)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7376de71
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51ab1174
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/8.delta
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/8.delta
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 4.0 in stage 15.0 (TID 90). 35829 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 6.0 in stage 15.0 (TID 92, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 6.0 in stage 15.0 (TID 92)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 4.0 in stage 15.0 (TID 90) in 204 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b2bcf43
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24ef292b
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 5.0 in stage 15.0 (TID 91). 37837 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 7.0 in stage 15.0 (TID 93, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 7.0 in stage 15.0 (TID 93)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 5.0 in stage 15.0 (TID 91) in 184 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60d1924e
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a3c21fc
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/8.delta
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 6.0 in stage 15.0 (TID 92). 38492 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 8.0 in stage 15.0 (TID 94, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 6.0 in stage 15.0 (TID 92) in 161 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 8.0 in stage 15.0 (TID 94)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/8.delta
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725e2400
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49144c02
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:02 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:02 INFO  Executor:54 - Finished task 7.0 in stage 15.0 (TID 93). 36299 bytes result sent to driver
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Starting task 9.0 in stage 15.0 (TID 95, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:02 INFO  TaskSetManager:54 - Finished task 7.0 in stage 15.0 (TID 93) in 150 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:02 INFO  Executor:54 - Running task 9.0 in stage 15.0 (TID 95)
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59d73f6d
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aac487
2020-05-19 05:25:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 7 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/8.delta
2020-05-19 05:25:03 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:03 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 8 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/8.delta
2020-05-19 05:25:03 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:03 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:03 INFO  Executor:54 - Finished task 8.0 in stage 15.0 (TID 94). 35149 bytes result sent to driver
2020-05-19 05:25:03 INFO  TaskSetManager:54 - Finished task 8.0 in stage 15.0 (TID 94) in 189 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 8 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:03 INFO  Executor:54 - Finished task 9.0 in stage 15.0 (TID 95). 34604 bytes result sent to driver
2020-05-19 05:25:03 INFO  TaskSetManager:54 - Finished task 9.0 in stage 15.0 (TID 95) in 146 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2020-05-19 05:25:03 INFO  DAGScheduler:54 - ResultStage 15 (start at NativeMethodAccessorImpl.java:0) finished in 0.947 s
2020-05-19 05:25:03 INFO  DAGScheduler:54 - Job 14 finished: start at NativeMethodAccessorImpl.java:0, took 1.029692 s
2020-05-19 05:25:03 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25016760 is committing.
-------------------------------------------
Batch: 7
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:03 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25016760 committed.
2020-05-19 05:25:03 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:03 INFO  DAGScheduler:54 - Job 15 finished: start at NativeMethodAccessorImpl.java:0, took 0.000057 s
2020-05-19 05:25:03 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:01.387Z",
  "batchId" : 7,
  "numInputRows" : 3,
  "inputRowsPerSecond" : 1.323918799646955,
  "processedRowsPerSecond" : 1.4381591562799618,
  "durationMs" : {
    "addBatch" : 1834,
    "getBatch" : 6,
    "getOffset" : 5,
    "queryPlanning" : 145,
    "triggerExecution" : 2086,
    "walCommit" : 95
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:13:40.000Z",
    "max" : "2018-12-28T17:14:00.000Z",
    "min" : "2018-12-28T17:13:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2811,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3221,
        "0" : 3118
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3222,
        "0" : 3120
      }
    },
    "numInputRows" : 3,
    "inputRowsPerSecond" : 1.323918799646955,
    "processedRowsPerSecond" : 1.4381591562799618
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:03 INFO  MicroBatchExecution:54 - Committed offsets for batch 8. Metadata OffsetSeqMetadata(1546297020000,1589865903588,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:03 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3222,"0":3120}}), end = {"department.police.service.call":{"1":3224,"0":3120}}
2020-05-19 05:25:03 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:03 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3120,3120,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3222,3224,None)
2020-05-19 05:25:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:03 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:03 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:03 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:03 INFO  SparkContext:54 - Created broadcast 32 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:04 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:04 INFO  SparkContext:54 - Created broadcast 33 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:04 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@346bfee9. The input RDD has 10 partitions.
2020-05-19 05:25:04 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Registering RDD 126 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Got job 16 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[126] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:04 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:04 INFO  SparkContext:54 - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[126] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:04 INFO  TaskSchedulerImpl:54 - Adding task set 16.0 with 2 tasks
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 1.0 in stage 16.0 (TID 97, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 1.0 in stage 16.0 (TID 97)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 0.0 in stage 16.0 (TID 96)
2020-05-19 05:25:04 INFO  KafkaSourceRDD:54 - Beginning offset 3120 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 1.0 in stage 16.0 (TID 97). 2074 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 1.0 in stage 16.0 (TID 97) in 23 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 0.0 in stage 16.0 (TID 96). 2203 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 96) in 54 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2020-05-19 05:25:04 INFO  DAGScheduler:54 - ShuffleMapStage 16 (start at NativeMethodAccessorImpl.java:0) finished in 0.073 s
2020-05-19 05:25:04 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:04 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:04 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)
2020-05-19 05:25:04 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:04 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:04 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:04 INFO  SparkContext:54 - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:04 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 17 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:04 INFO  TaskSchedulerImpl:54 - Adding task set 17.0 with 10 tasks
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 1.0 in stage 17.0 (TID 99, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 0.0 in stage 17.0 (TID 98)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 1.0 in stage 17.0 (TID 99)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d16d665
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61ed9e7a
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2217f4dc
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a1aab46
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/9.delta
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/9.delta
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 1.0 in stage 17.0 (TID 99). 32962 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 2.0 in stage 17.0 (TID 100, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 1.0 in stage 17.0 (TID 99) in 176 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 2.0 in stage 17.0 (TID 100)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af93e0b
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@738a6beb
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 0.0 in stage 17.0 (TID 98). 34047 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 3.0 in stage 17.0 (TID 101, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 98) in 191 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 3.0 in stage 17.0 (TID 101)
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@189f4bbb
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3047d35f
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/9.delta
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/9.delta
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 2.0 in stage 17.0 (TID 100). 34820 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 4.0 in stage 17.0 (TID 102, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 4.0 in stage 17.0 (TID 102)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 2.0 in stage 17.0 (TID 100) in 163 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ff8d2f6
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20b94db0
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 3.0 in stage 17.0 (TID 101). 35804 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 5.0 in stage 17.0 (TID 103, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 5.0 in stage 17.0 (TID 103)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 3.0 in stage 17.0 (TID 101) in 184 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43b9f9be
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43221736
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/9.delta
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/9.delta
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 4.0 in stage 17.0 (TID 102). 35829 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 6.0 in stage 17.0 (TID 104, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 6.0 in stage 17.0 (TID 104)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 4.0 in stage 17.0 (TID 102) in 168 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c1167ac
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51bd33f3
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:04 INFO  Executor:54 - Finished task 5.0 in stage 17.0 (TID 103). 37837 bytes result sent to driver
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Starting task 7.0 in stage 17.0 (TID 105, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:04 INFO  Executor:54 - Running task 7.0 in stage 17.0 (TID 105)
2020-05-19 05:25:04 INFO  TaskSetManager:54 - Finished task 5.0 in stage 17.0 (TID 103) in 164 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@793acc73
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:04 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:04 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:04 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509c4bea
2020-05-19 05:25:04 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/9.delta
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/9.delta
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:04 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:05 INFO  Executor:54 - Finished task 6.0 in stage 17.0 (TID 104). 38606 bytes result sent to driver
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Starting task 8.0 in stage 17.0 (TID 106, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:05 INFO  Executor:54 - Running task 8.0 in stage 17.0 (TID 106)
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Finished task 6.0 in stage 17.0 (TID 104) in 239 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48a37258
2020-05-19 05:25:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d9cd7d
2020-05-19 05:25:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:05 INFO  Executor:54 - Finished task 7.0 in stage 17.0 (TID 105). 36299 bytes result sent to driver
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Starting task 9.0 in stage 17.0 (TID 107, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Finished task 7.0 in stage 17.0 (TID 105) in 238 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:05 INFO  Executor:54 - Running task 9.0 in stage 17.0 (TID 107)
2020-05-19 05:25:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@433d3e69
2020-05-19 05:25:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7887fa49
2020-05-19 05:25:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 8 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/9.delta
2020-05-19 05:25:05 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:05 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 9 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/9.delta
2020-05-19 05:25:05 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:05 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 657
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 625
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 686
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 651
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 649
2020-05-19 05:25:05 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 650
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 691
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 694
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 644
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 653
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 670
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 676
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 646
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 711
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 675
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 659
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 631
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 660
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 643
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 632
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 655
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 689
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 645
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 712
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 681
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 663
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 674
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 633
2020-05-19 05:25:05 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 629
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 647
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 678
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 672
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 641
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 637
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 635
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 698
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 634
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 701
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 669
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 679
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 710
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 684
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 627
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 667
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 648
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 668
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 692
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 652
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 654
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 664
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 680
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 666
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 642
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 704
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 661
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 700
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 685
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 662
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 713
2020-05-19 05:25:05 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 683
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 628
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 671
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 699
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 665
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 677
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 697
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 705
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 658
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 638
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 709
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 693
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 690
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 639
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 640
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 656
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 706
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 673
2020-05-19 05:25:05 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 702
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 688
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 715
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 682
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 687
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 630
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 636
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned shuffle 7
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 695
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 707
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 696
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 703
2020-05-19 05:25:05 INFO  ContextCleaner:54 - Cleaned accumulator 708
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:05 INFO  Executor:54 - Finished task 8.0 in stage 17.0 (TID 106). 35192 bytes result sent to driver
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Finished task 8.0 in stage 17.0 (TID 106) in 182 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 9 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:05 INFO  Executor:54 - Finished task 9.0 in stage 17.0 (TID 107). 34647 bytes result sent to driver
2020-05-19 05:25:05 INFO  TaskSetManager:54 - Finished task 9.0 in stage 17.0 (TID 107) in 177 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2020-05-19 05:25:05 INFO  DAGScheduler:54 - ResultStage 17 (start at NativeMethodAccessorImpl.java:0) finished in 0.962 s
2020-05-19 05:25:05 INFO  DAGScheduler:54 - Job 16 finished: start at NativeMethodAccessorImpl.java:0, took 1.044130 s
2020-05-19 05:25:05 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@346bfee9 is committing.
-------------------------------------------
Batch: 8
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:05 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@346bfee9 committed.
2020-05-19 05:25:05 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:05 INFO  DAGScheduler:54 - Job 17 finished: start at NativeMethodAccessorImpl.java:0, took 0.000056 s
2020-05-19 05:25:05 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:03.583Z",
  "batchId" : 8,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.9107468123861566,
  "processedRowsPerSecond" : 1.0235414534288638,
  "durationMs" : {
    "addBatch" : 1781,
    "getBatch" : 8,
    "getOffset" : 5,
    "queryPlanning" : 88,
    "triggerExecution" : 1954,
    "walCommit" : 71
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:12:00.000Z",
    "max" : "2018-12-28T17:12:00.000Z",
    "min" : "2018-12-28T17:12:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2812,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3222,
        "0" : 3120
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3224,
        "0" : 3120
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.9107468123861566,
    "processedRowsPerSecond" : 1.0235414534288638
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:05 INFO  MicroBatchExecution:54 - Committed offsets for batch 9. Metadata OffsetSeqMetadata(1546297020000,1589865905653,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:05 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3224,"0":3120}}), end = {"department.police.service.call":{"1":3224,"0":3122}}
2020-05-19 05:25:05 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:05 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3120,3122,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3224,3224,None)
2020-05-19 05:25:05 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:05 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:05 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:06 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:06 INFO  SparkContext:54 - Created broadcast 36 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:06 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:06 INFO  SparkContext:54 - Created broadcast 37 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:06 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1213b05e. The input RDD has 10 partitions.
2020-05-19 05:25:06 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Registering RDD 141 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Got job 18 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Final stage: ResultStage 19 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 18)
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 18)
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 18 (MapPartitionsRDD[141] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:06 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:06 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[141] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:06 INFO  TaskSchedulerImpl:54 - Adding task set 18.0 with 2 tasks
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 1.0 in stage 18.0 (TID 109, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 0.0 in stage 18.0 (TID 108)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 1.0 in stage 18.0 (TID 109)
2020-05-19 05:25:06 INFO  KafkaSourceRDD:54 - Beginning offset 3224 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 0.0 in stage 18.0 (TID 108). 2074 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 108) in 39 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 1.0 in stage 18.0 (TID 109). 2203 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 1.0 in stage 18.0 (TID 109) in 57 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2020-05-19 05:25:06 INFO  DAGScheduler:54 - ShuffleMapStage 18 (start at NativeMethodAccessorImpl.java:0) finished in 0.065 s
2020-05-19 05:25:06 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:06 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:06 INFO  DAGScheduler:54 - waiting: Set(ResultStage 19)
2020-05-19 05:25:06 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Submitting ResultStage 19 (MapPartitionsRDD[147] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:06 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:06 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:06 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:06 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 19 (MapPartitionsRDD[147] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:06 INFO  TaskSchedulerImpl:54 - Adding task set 19.0 with 10 tasks
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 1.0 in stage 19.0 (TID 111, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 1.0 in stage 19.0 (TID 111)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 0.0 in stage 19.0 (TID 110)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78a19a74
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@715c357e
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7da44cfe
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55c45e8d
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 1.0 in stage 19.0 (TID 111). 32962 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 2.0 in stage 19.0 (TID 112, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 1.0 in stage 19.0 (TID 111) in 133 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 2.0 in stage 19.0 (TID 112)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69a429da
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 0.0 in stage 19.0 (TID 110). 34047 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 3.0 in stage 19.0 (TID 113, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 3.0 in stage 19.0 (TID 113)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 110) in 156 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b07cdcd
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18f1bdf9
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bed2692
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 2.0 in stage 19.0 (TID 112). 34820 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 4.0 in stage 19.0 (TID 114, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 4.0 in stage 19.0 (TID 114)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 2.0 in stage 19.0 (TID 112) in 138 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e8681b7
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e8eaa51
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 3.0 in stage 19.0 (TID 113). 35804 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 5.0 in stage 19.0 (TID 115, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 5.0 in stage 19.0 (TID 115)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 3.0 in stage 19.0 (TID 113) in 159 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bfcd108
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c09c575
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/10.delta
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 4.0 in stage 19.0 (TID 114). 35829 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 6.0 in stage 19.0 (TID 116, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 4.0 in stage 19.0 (TID 114) in 143 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 6.0 in stage 19.0 (TID 116)
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25dbcbf1
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35276b5e
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 5.0 in stage 19.0 (TID 115). 37837 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 7.0 in stage 19.0 (TID 117, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 7.0 in stage 19.0 (TID 117)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 5.0 in stage 19.0 (TID 115) in 150 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29c4b55b
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@679a2453
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/10.delta
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:06 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 6.0 in stage 19.0 (TID 116). 38615 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 8.0 in stage 19.0 (TID 118, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 8.0 in stage 19.0 (TID 118)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 6.0 in stage 19.0 (TID 116) in 144 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1082e74c
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@334755bb
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:06 INFO  Executor:54 - Finished task 7.0 in stage 19.0 (TID 117). 36299 bytes result sent to driver
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Starting task 9.0 in stage 19.0 (TID 119, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:06 INFO  Executor:54 - Running task 9.0 in stage 19.0 (TID 119)
2020-05-19 05:25:06 INFO  TaskSetManager:54 - Finished task 7.0 in stage 19.0 (TID 117) in 150 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e84d282
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fb509aa
2020-05-19 05:25:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 9 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:07 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/10.delta
2020-05-19 05:25:07 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:07 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:07 INFO  HDFSBackedStateStoreProvider:54 - Committed version 10 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/10.delta
2020-05-19 05:25:07 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:07 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:07 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:07 INFO  Executor:54 - Finished task 8.0 in stage 19.0 (TID 118). 35149 bytes result sent to driver
2020-05-19 05:25:07 INFO  TaskSetManager:54 - Finished task 8.0 in stage 19.0 (TID 118) in 206 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:07 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 10 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:07 INFO  Executor:54 - Finished task 9.0 in stage 19.0 (TID 119). 34604 bytes result sent to driver
2020-05-19 05:25:07 INFO  TaskSetManager:54 - Finished task 9.0 in stage 19.0 (TID 119) in 182 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2020-05-19 05:25:07 INFO  DAGScheduler:54 - ResultStage 19 (start at NativeMethodAccessorImpl.java:0) finished in 0.799 s
2020-05-19 05:25:07 INFO  DAGScheduler:54 - Job 18 finished: start at NativeMethodAccessorImpl.java:0, took 0.884634 s
2020-05-19 05:25:07 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1213b05e is committing.
-------------------------------------------
Batch: 9
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:07 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1213b05e committed.
2020-05-19 05:25:07 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:07 INFO  DAGScheduler:54 - Job 19 finished: start at NativeMethodAccessorImpl.java:0, took 0.000046 s
2020-05-19 05:25:07 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:05.634Z",
  "batchId" : 9,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.9751340809361286,
  "processedRowsPerSecond" : 1.027221366204417,
  "durationMs" : {
    "addBatch" : 1713,
    "getBatch" : 15,
    "getOffset" : 9,
    "queryPlanning" : 123,
    "triggerExecution" : 1947,
    "walCommit" : 75
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:12:00.000Z",
    "max" : "2018-12-28T17:12:00.000Z",
    "min" : "2018-12-28T17:12:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2812,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3224,
        "0" : 3120
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3224,
        "0" : 3122
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.9751340809361286,
    "processedRowsPerSecond" : 1.027221366204417
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:07 INFO  MicroBatchExecution:54 - Committed offsets for batch 10. Metadata OffsetSeqMetadata(1546297020000,1589865907692,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:07 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3224,"0":3122}}), end = {"department.police.service.call":{"1":3225,"0":3123}}
2020-05-19 05:25:07 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:07 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3122,3123,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3224,3225,None)
2020-05-19 05:25:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_40 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 876
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 768
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 825
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 833
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 739
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 753
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 811
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 814
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 783
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 784
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 796
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 886
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 758
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 774
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 737
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 856
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 878
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 760
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 823
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 743
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 841
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 727
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 800
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 838
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 824
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 748
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 806
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 872
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 890
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 761
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 745
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 738
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 851
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned shuffle 8
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 769
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 853
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 803
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 822
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 829
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 770
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 870
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 747
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 759
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 798
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 840
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 719
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 742
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 788
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 765
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 801
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 717
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 756
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 810
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 834
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 864
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 891
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 799
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 729
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 861
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 843
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 732
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 793
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 859
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 721
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 855
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 844
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 778
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 766
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 772
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 755
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  SparkContext:54 - Created broadcast 40 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 776
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 790
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 820
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 785
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 723
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 734
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 847
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 858
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 857
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 874
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 805
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 852
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 802
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 726
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 882
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 866
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 771
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 828
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 862
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 714
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 763
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned shuffle 9
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 730
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 757
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 807
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 865
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 817
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 812
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 893
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 885
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 835
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 797
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 831
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 883
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 880
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 724
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 754
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 792
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 877
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 786
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 826
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 815
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 884
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 777
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 720
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 860
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 854
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 764
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 875
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 863
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 722
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 839
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 888
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 845
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 804
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 741
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 848
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 749
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 773
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 809
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 842
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 789
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 736
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 735
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 775
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 818
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 731
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 868
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 779
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 832
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 718
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 869
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 780
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 867
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 887
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 846
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 716
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 795
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 821
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 850
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 881
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 794
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 813
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 827
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 830
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 744
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 808
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 787
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 819
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 836
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 725
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 751
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 762
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 767
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 746
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 752
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 871
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 873
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 750
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 782
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 733
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 816
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 837
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 791
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 879
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 889
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 728
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 849
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 740
2020-05-19 05:25:08 INFO  ContextCleaner:54 - Cleaned accumulator 781
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_41 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  SparkContext:54 - Created broadcast 41 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:08 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4279d8d4. The input RDD has 10 partitions.
2020-05-19 05:25:08 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Registering RDD 156 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Got job 20 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Final stage: ResultStage 21 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 20)
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 20)
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 20 (MapPartitionsRDD[156] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_42 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_42_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  SparkContext:54 - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[156] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:08 INFO  TaskSchedulerImpl:54 - Adding task set 20.0 with 2 tasks
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 1.0 in stage 20.0 (TID 121, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 1.0 in stage 20.0 (TID 121)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 0.0 in stage 20.0 (TID 120)
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 1.0 in stage 20.0 (TID 121). 2203 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 1.0 in stage 20.0 (TID 121) in 28 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 0.0 in stage 20.0 (TID 120). 2203 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 120) in 41 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2020-05-19 05:25:08 INFO  DAGScheduler:54 - ShuffleMapStage 20 (start at NativeMethodAccessorImpl.java:0) finished in 0.067 s
2020-05-19 05:25:08 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:08 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:08 INFO  DAGScheduler:54 - waiting: Set(ResultStage 21)
2020-05-19 05:25:08 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Submitting ResultStage 21 (MapPartitionsRDD[162] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_43 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:08 INFO  MemoryStore:54 - Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:08 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:08 INFO  SparkContext:54 - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:08 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 21 (MapPartitionsRDD[162] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:08 INFO  TaskSchedulerImpl:54 - Adding task set 21.0 with 10 tasks
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 1.0 in stage 21.0 (TID 123, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 1.0 in stage 21.0 (TID 123)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 0.0 in stage 21.0 (TID 122)
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39434967
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1178de2b
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d063336
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71e4ba6b
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/11.delta
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/11.delta
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 0.0 in stage 21.0 (TID 122). 34047 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 2.0 in stage 21.0 (TID 124, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 2.0 in stage 21.0 (TID 124)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 122) in 160 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7610e276
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 1.0 in stage 21.0 (TID 123). 32962 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 3.0 in stage 21.0 (TID 125, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 1.0 in stage 21.0 (TID 123) in 170 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c373b26
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  Executor:54 - Running task 3.0 in stage 21.0 (TID 125)
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e8d17e0
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43b3ef2
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/11.delta
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/11.delta
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 2.0 in stage 21.0 (TID 124). 34820 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 4.0 in stage 21.0 (TID 126, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 2.0 in stage 21.0 (TID 124) in 138 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 4.0 in stage 21.0 (TID 126)
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30fbe07c
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55b06279
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/11.delta
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 3.0 in stage 21.0 (TID 125). 35804 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 5.0 in stage 21.0 (TID 127, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 3.0 in stage 21.0 (TID 125) in 236 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 5.0 in stage 21.0 (TID 127)
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68a4fc9f
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:08 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a8b80c
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:08 INFO  Executor:54 - Finished task 4.0 in stage 21.0 (TID 126). 35829 bytes result sent to driver
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Starting task 6.0 in stage 21.0 (TID 128, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:08 INFO  TaskSetManager:54 - Finished task 4.0 in stage 21.0 (TID 126) in 190 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:08 INFO  Executor:54 - Running task 6.0 in stage 21.0 (TID 128)
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42ab3ee1
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/11.delta
2020-05-19 05:25:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc40fe5
2020-05-19 05:25:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/11.delta
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:09 INFO  Executor:54 - Finished task 5.0 in stage 21.0 (TID 127). 37837 bytes result sent to driver
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Starting task 7.0 in stage 21.0 (TID 129, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:09 INFO  Executor:54 - Running task 7.0 in stage 21.0 (TID 129)
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Finished task 5.0 in stage 21.0 (TID 127) in 206 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a17ccb
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9dffbab
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:09 INFO  Executor:54 - Finished task 6.0 in stage 21.0 (TID 128). 38606 bytes result sent to driver
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Starting task 8.0 in stage 21.0 (TID 130, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:09 INFO  Executor:54 - Running task 8.0 in stage 21.0 (TID 130)
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Finished task 6.0 in stage 21.0 (TID 128) in 179 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1be2fa07
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3270572a
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/11.delta
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:09 INFO  Executor:54 - Finished task 7.0 in stage 21.0 (TID 129). 36299 bytes result sent to driver
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Starting task 9.0 in stage 21.0 (TID 131, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Finished task 7.0 in stage 21.0 (TID 129) in 146 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:09 INFO  Executor:54 - Running task 9.0 in stage 21.0 (TID 131)
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fa7965b
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e501dae
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/11.delta
2020-05-19 05:25:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 10 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:09 INFO  Executor:54 - Finished task 8.0 in stage 21.0 (TID 130). 35149 bytes result sent to driver
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Finished task 8.0 in stage 21.0 (TID 130) in 168 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 11 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/11.delta
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:09 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 11 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:09 INFO  Executor:54 - Finished task 9.0 in stage 21.0 (TID 131). 34604 bytes result sent to driver
2020-05-19 05:25:09 INFO  TaskSetManager:54 - Finished task 9.0 in stage 21.0 (TID 131) in 170 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2020-05-19 05:25:09 INFO  DAGScheduler:54 - ResultStage 21 (start at NativeMethodAccessorImpl.java:0) finished in 0.931 s
2020-05-19 05:25:09 INFO  DAGScheduler:54 - Job 20 finished: start at NativeMethodAccessorImpl.java:0, took 1.007024 s
2020-05-19 05:25:09 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4279d8d4 is committing.
-------------------------------------------
Batch: 10
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:09 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4279d8d4 committed.
2020-05-19 05:25:09 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:09 INFO  DAGScheduler:54 - Job 21 finished: start at NativeMethodAccessorImpl.java:0, took 0.000048 s
2020-05-19 05:25:09 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:07.689Z",
  "batchId" : 10,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.97323600973236,
  "processedRowsPerSecond" : 0.9765625,
  "durationMs" : {
    "addBatch" : 1805,
    "getBatch" : 8,
    "getOffset" : 3,
    "queryPlanning" : 119,
    "triggerExecution" : 2048,
    "walCommit" : 111
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:11:00.000Z",
    "max" : "2018-12-28T17:11:00.000Z",
    "min" : "2018-12-28T17:11:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2812,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3224,
        "0" : 3122
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3225,
        "0" : 3123
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.97323600973236,
    "processedRowsPerSecond" : 0.9765625
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:09 INFO  MicroBatchExecution:54 - Committed offsets for batch 11. Metadata OffsetSeqMetadata(1546297020000,1589865909782,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:09 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3225,"0":3123}}), end = {"department.police.service.call":{"1":3227,"0":3123}}
2020-05-19 05:25:09 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:09 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3123,3123,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3225,3227,None)
2020-05-19 05:25:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_44 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_44_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  SparkContext:54 - Created broadcast 44 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_45 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  SparkContext:54 - Created broadcast 45 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:10 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6b2637a1. The input RDD has 10 partitions.
2020-05-19 05:25:10 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Registering RDD 171 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Got job 22 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Final stage: ResultStage 23 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 22)
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 22)
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 22 (MapPartitionsRDD[171] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_46 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_46_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  SparkContext:54 - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[171] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:10 INFO  TaskSchedulerImpl:54 - Adding task set 22.0 with 2 tasks
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 1.0 in stage 22.0 (TID 133, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 0.0 in stage 22.0 (TID 132)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 1.0 in stage 22.0 (TID 133)
2020-05-19 05:25:10 INFO  KafkaSourceRDD:54 - Beginning offset 3123 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 1.0 in stage 22.0 (TID 133). 2074 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 1.0 in stage 22.0 (TID 133) in 45 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 0.0 in stage 22.0 (TID 132). 2203 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 132) in 65 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:10 INFO  TaskSchedulerImpl:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2020-05-19 05:25:10 INFO  DAGScheduler:54 - ShuffleMapStage 22 (start at NativeMethodAccessorImpl.java:0) finished in 0.077 s
2020-05-19 05:25:10 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:10 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:10 INFO  DAGScheduler:54 - waiting: Set(ResultStage 23)
2020-05-19 05:25:10 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Submitting ResultStage 23 (MapPartitionsRDD[177] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_47 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:10 INFO  MemoryStore:54 - Block broadcast_47_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  SparkContext:54 - Created broadcast 47 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:10 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 23 (MapPartitionsRDD[177] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:10 INFO  TaskSchedulerImpl:54 - Adding task set 23.0 with 10 tasks
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 1.0 in stage 23.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 1.0 in stage 23.0 (TID 135)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 0.0 in stage 23.0 (TID 134)
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f60133
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7301b81a
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b8ba116
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25a1c089
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/12.delta
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/12.delta
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 914
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 909
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 969
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 955
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 947
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 968
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 926
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 944
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 961
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 892
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 959
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 943
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 975
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 931
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 948
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 922
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 967
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 895
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 897
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 903
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 915
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 960
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 940
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 972
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 954
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 899
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 896
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 937
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 977
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 941
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 974
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 936
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 965
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 898
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 963
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 929
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 946
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 971
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 905
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 978
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 918
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 921
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 966
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 979
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 907
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 962
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 902
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 964
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 916
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 910
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 951
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 956
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 912
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 942
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 900
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 923
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 917
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 906
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 945
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 927
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 939
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 928
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 958
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 924
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 938
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 904
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned shuffle 10
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 970
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 982
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 901
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 925
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 934
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 933
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 911
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 930
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 950
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 953
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 976
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 919
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 894
2020-05-19 05:25:10 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 932
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 980
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 952
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 935
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 913
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 949
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 908
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 920
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 973
2020-05-19 05:25:10 INFO  ContextCleaner:54 - Cleaned accumulator 957
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 0.0 in stage 23.0 (TID 134). 34090 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 2.0 in stage 23.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 134) in 189 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 2.0 in stage 23.0 (TID 136)
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@90ce1b1
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51e2552
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 1.0 in stage 23.0 (TID 135). 33005 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 3.0 in stage 23.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 3.0 in stage 23.0 (TID 137)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 1.0 in stage 23.0 (TID 135) in 212 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2308575e
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e19fa61
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/12.delta
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/12.delta
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:10 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 2.0 in stage 23.0 (TID 136). 34820 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 4.0 in stage 23.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 2.0 in stage 23.0 (TID 136) in 142 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 4.0 in stage 23.0 (TID 138)
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e3cf53e
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7272cea3
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:10 INFO  Executor:54 - Finished task 3.0 in stage 23.0 (TID 137). 35804 bytes result sent to driver
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Starting task 5.0 in stage 23.0 (TID 139, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:10 INFO  TaskSetManager:54 - Finished task 3.0 in stage 23.0 (TID 137) in 161 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:10 INFO  Executor:54 - Running task 5.0 in stage 23.0 (TID 139)
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26542af1
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62890c00
2020-05-19 05:25:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/12.delta
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/12.delta
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 5.0 in stage 23.0 (TID 139). 37837 bytes result sent to driver
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 4.0 in stage 23.0 (TID 138). 35829 bytes result sent to driver
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Starting task 6.0 in stage 23.0 (TID 140, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Starting task 7.0 in stage 23.0 (TID 141, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:11 INFO  Executor:54 - Running task 6.0 in stage 23.0 (TID 140)
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 5.0 in stage 23.0 (TID 139) in 132 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  Executor:54 - Running task 7.0 in stage 23.0 (TID 141)
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 4.0 in stage 23.0 (TID 138) in 176 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a7f6acc
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bff0eb5
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f9e20cb
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3598e5c9
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/12.delta
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/12.delta
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 6.0 in stage 23.0 (TID 140). 38606 bytes result sent to driver
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Starting task 8.0 in stage 23.0 (TID 142, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:11 INFO  Executor:54 - Running task 8.0 in stage 23.0 (TID 142)
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 6.0 in stage 23.0 (TID 140) in 133 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fead97d
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@103fbc18
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 7.0 in stage 23.0 (TID 141). 36299 bytes result sent to driver
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Starting task 9.0 in stage 23.0 (TID 143, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:11 INFO  Executor:54 - Running task 9.0 in stage 23.0 (TID 143)
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 7.0 in stage 23.0 (TID 141) in 147 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44bbb99e
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26133a6b
2020-05-19 05:25:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 11 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/12.delta
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 12 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/12.delta
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:11 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 9.0 in stage 23.0 (TID 143). 34604 bytes result sent to driver
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 9.0 in stage 23.0 (TID 143) in 135 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 12 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:11 INFO  Executor:54 - Finished task 8.0 in stage 23.0 (TID 142). 35149 bytes result sent to driver
2020-05-19 05:25:11 INFO  TaskSetManager:54 - Finished task 8.0 in stage 23.0 (TID 142) in 167 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2020-05-19 05:25:11 INFO  DAGScheduler:54 - ResultStage 23 (start at NativeMethodAccessorImpl.java:0) finished in 0.814 s
2020-05-19 05:25:11 INFO  DAGScheduler:54 - Job 22 finished: start at NativeMethodAccessorImpl.java:0, took 0.907599 s
2020-05-19 05:25:11 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6b2637a1 is committing.
-------------------------------------------
Batch: 11
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:11 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6b2637a1 committed.
2020-05-19 05:25:11 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:11 INFO  DAGScheduler:54 - Job 23 finished: start at NativeMethodAccessorImpl.java:0, took 0.000047 s
2020-05-19 05:25:11 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:09.778Z",
  "batchId" : 11,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.9573958831977023,
  "processedRowsPerSecond" : 1.0781671159029649,
  "durationMs" : {
    "addBatch" : 1585,
    "getBatch" : 11,
    "getOffset" : 4,
    "queryPlanning" : 150,
    "triggerExecution" : 1855,
    "walCommit" : 104
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:09:00.000Z",
    "max" : "2018-12-28T17:09:00.000Z",
    "min" : "2018-12-28T17:09:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2812,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3225,
        "0" : 3123
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3227,
        "0" : 3123
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.9573958831977023,
    "processedRowsPerSecond" : 1.0781671159029649
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:11 INFO  MicroBatchExecution:54 - Committed offsets for batch 12. Metadata OffsetSeqMetadata(1546297020000,1589865911752,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:11 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3227,"0":3123}}), end = {"department.police.service.call":{"1":3227,"0":3125}}
2020-05-19 05:25:11 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:11 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3123,3125,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3227,3227,None)
2020-05-19 05:25:12 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:12 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:12 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_48 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_48_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:12 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:12 INFO  SparkContext:54 - Created broadcast 48 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_49 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_49_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:12 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:12 INFO  SparkContext:54 - Created broadcast 49 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:12 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@361130b5. The input RDD has 10 partitions.
2020-05-19 05:25:12 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Registering RDD 186 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Got job 24 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Final stage: ResultStage 25 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 24)
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 24)
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 24 (MapPartitionsRDD[186] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_50 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_50_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:12 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:12 INFO  SparkContext:54 - Created broadcast 50 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[186] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:12 INFO  TaskSchedulerImpl:54 - Adding task set 24.0 with 2 tasks
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 1.0 in stage 24.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 0.0 in stage 24.0 (TID 144)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 1.0 in stage 24.0 (TID 145)
2020-05-19 05:25:12 INFO  KafkaSourceRDD:54 - Beginning offset 3227 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 1.0 in stage 24.0 (TID 145). 2203 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 1.0 in stage 24.0 (TID 145) in 22 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 0.0 in stage 24.0 (TID 144). 2074 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 144) in 31 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:12 INFO  TaskSchedulerImpl:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2020-05-19 05:25:12 INFO  DAGScheduler:54 - ShuffleMapStage 24 (start at NativeMethodAccessorImpl.java:0) finished in 0.043 s
2020-05-19 05:25:12 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:12 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:12 INFO  DAGScheduler:54 - waiting: Set(ResultStage 25)
2020-05-19 05:25:12 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Submitting ResultStage 25 (MapPartitionsRDD[192] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_51 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:12 INFO  MemoryStore:54 - Block broadcast_51_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:12 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:12 INFO  SparkContext:54 - Created broadcast 51 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:12 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 25 (MapPartitionsRDD[192] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:12 INFO  TaskSchedulerImpl:54 - Adding task set 25.0 with 10 tasks
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 0.0 in stage 25.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 1.0 in stage 25.0 (TID 147, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 0.0 in stage 25.0 (TID 146)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 1.0 in stage 25.0 (TID 147)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c6fdc2f
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54637abf
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b32e7e
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78b0533e
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/13.delta
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/13.delta
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 1.0 in stage 25.0 (TID 147). 32962 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 2.0 in stage 25.0 (TID 148, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 1.0 in stage 25.0 (TID 147) in 109 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 2.0 in stage 25.0 (TID 148)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34b4fcf7
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52760901
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 0.0 in stage 25.0 (TID 146). 34047 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 3.0 in stage 25.0 (TID 149, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 3.0 in stage 25.0 (TID 149)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 25.0 (TID 146) in 147 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43fb0ae8
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e7ff7df
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/13.delta
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/13.delta
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 2.0 in stage 25.0 (TID 148). 34820 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 4.0 in stage 25.0 (TID 150, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 2.0 in stage 25.0 (TID 148) in 117 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 4.0 in stage 25.0 (TID 150)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2da857d3
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e0441fa
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 3.0 in stage 25.0 (TID 149). 35804 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 5.0 in stage 25.0 (TID 151, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 5.0 in stage 25.0 (TID 151)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 3.0 in stage 25.0 (TID 149) in 145 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502e1d60
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@294112fe
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/13.delta
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/13.delta
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 4.0 in stage 25.0 (TID 150). 35829 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 6.0 in stage 25.0 (TID 152, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 6.0 in stage 25.0 (TID 152)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 4.0 in stage 25.0 (TID 150) in 179 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74deef62
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a7e989
2020-05-19 05:25:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:12 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/13.delta
2020-05-19 05:25:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:12 INFO  Executor:54 - Finished task 5.0 in stage 25.0 (TID 151). 37837 bytes result sent to driver
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Starting task 7.0 in stage 25.0 (TID 153, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:12 INFO  Executor:54 - Running task 7.0 in stage 25.0 (TID 153)
2020-05-19 05:25:12 INFO  TaskSetManager:54 - Finished task 5.0 in stage 25.0 (TID 151) in 176 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11cb2d42
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f104ca4
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:13 INFO  Executor:54 - Finished task 6.0 in stage 25.0 (TID 152). 38606 bytes result sent to driver
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Starting task 8.0 in stage 25.0 (TID 154, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Finished task 6.0 in stage 25.0 (TID 152) in 123 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:13 INFO  Executor:54 - Running task 8.0 in stage 25.0 (TID 154)
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69252d8a
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cff9863
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/13.delta
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/13.delta
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:13 INFO  Executor:54 - Finished task 7.0 in stage 25.0 (TID 153). 36299 bytes result sent to driver
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Starting task 9.0 in stage 25.0 (TID 155, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Finished task 7.0 in stage 25.0 (TID 153) in 139 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:13 INFO  Executor:54 - Running task 9.0 in stage 25.0 (TID 155)
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@726debbd
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25ca024
2020-05-19 05:25:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 12 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:13 INFO  Executor:54 - Finished task 8.0 in stage 25.0 (TID 154). 35149 bytes result sent to driver
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Finished task 8.0 in stage 25.0 (TID 154) in 126 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 13 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/13.delta
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:13 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 13 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:13 INFO  Executor:54 - Finished task 9.0 in stage 25.0 (TID 155). 34604 bytes result sent to driver
2020-05-19 05:25:13 INFO  TaskSetManager:54 - Finished task 9.0 in stage 25.0 (TID 155) in 91 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2020-05-19 05:25:13 INFO  DAGScheduler:54 - ResultStage 25 (start at NativeMethodAccessorImpl.java:0) finished in 0.696 s
2020-05-19 05:25:13 INFO  DAGScheduler:54 - Job 24 finished: start at NativeMethodAccessorImpl.java:0, took 0.751556 s
2020-05-19 05:25:13 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@361130b5 is committing.
-------------------------------------------
Batch: 12
-------------------------------------------
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1060
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1129
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1024
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1003
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1040
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1062
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1109
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1151
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1119
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1114
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 995
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1134
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1035
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1057
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 998
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 988
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1153
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1034
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1111
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1015
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 983
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 994
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1049
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1051
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1141
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1149
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1121
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 993
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 996
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1031
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1007
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1020
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1120
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1145
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1021
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1045
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1107
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1030
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 991
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 987
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 984
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1154
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1150
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1139
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1117
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1148
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1041
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1043
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1053
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1000
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 990
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1006
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 997
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1140
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1064
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1012
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 981
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 999
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1028
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1019
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1146
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1032
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1014
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1056
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1054
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1131
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1052
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1013
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1036
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1059
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1113
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1071
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1002
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1046
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1152
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1033
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1066
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 985
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1048
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1016
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1128
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1124
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1125
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1050
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1011
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1123
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1116
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1005
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1133
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 986
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1058
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1142
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1112
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1008
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1018
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1025
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1061
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1047
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1022
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1067
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1127
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1115
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1023
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1026
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1042
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1010
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1001
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1143
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1118
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1126
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 992
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1063
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1039
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1138
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1155
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1108
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1132
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1122
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1137
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1027
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1004
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1069
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1029
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1009
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1065
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1037
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1110
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1130
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1038
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1044
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1156
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1144
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 989
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1136
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1017
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1135
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1055
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1068
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned shuffle 11
2020-05-19 05:25:13 INFO  ContextCleaner:54 - Cleaned accumulator 1147
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:13 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@361130b5 committed.
2020-05-19 05:25:13 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:13 INFO  DAGScheduler:54 - Job 25 finished: start at NativeMethodAccessorImpl.java:0, took 0.000073 s
2020-05-19 05:25:13 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:11.745Z",
  "batchId" : 12,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0167768174885612,
  "processedRowsPerSecond" : 1.1242270938729624,
  "durationMs" : {
    "addBatch" : 1529,
    "getBatch" : 9,
    "getOffset" : 7,
    "queryPlanning" : 125,
    "triggerExecution" : 1779,
    "walCommit" : 104
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:09:00.000Z",
    "max" : "2018-12-28T17:09:00.000Z",
    "min" : "2018-12-28T17:09:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2812,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3227,
        "0" : 3123
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3227,
        "0" : 3125
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0167768174885612,
    "processedRowsPerSecond" : 1.1242270938729624
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:13 INFO  MicroBatchExecution:54 - Committed offsets for batch 13. Metadata OffsetSeqMetadata(1546297020000,1589865913630,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:13 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3227,"0":3125}}), end = {"department.police.service.call":{"1":3228,"0":3126}}
2020-05-19 05:25:13 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:13 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3125,3126,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3227,3228,None)
2020-05-19 05:25:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:13 INFO  MemoryStore:54 - Block broadcast_52 stored as values in memory (estimated size 281.8 KB, free 364.8 MB)
2020-05-19 05:25:13 INFO  MemoryStore:54 - Block broadcast_52_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.8 MB)
2020-05-19 05:25:13 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:13 INFO  SparkContext:54 - Created broadcast 52 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_53 stored as values in memory (estimated size 281.8 KB, free 364.5 MB)
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_53_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.5 MB)
2020-05-19 05:25:14 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:14 INFO  SparkContext:54 - Created broadcast 53 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:14 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@766103b6. The input RDD has 10 partitions.
2020-05-19 05:25:14 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Registering RDD 201 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Got job 26 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Final stage: ResultStage 27 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 26)
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 26)
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 26 (MapPartitionsRDD[201] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_54 stored as values in memory (estimated size 39.1 KB, free 364.4 MB)
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_54_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.4 MB)
2020-05-19 05:25:14 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:14 INFO  SparkContext:54 - Created broadcast 54 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[201] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:14 INFO  TaskSchedulerImpl:54 - Adding task set 26.0 with 2 tasks
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 26.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 26.0 (TID 157, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 0.0 in stage 26.0 (TID 156)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 1.0 in stage 26.0 (TID 157)
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 1.0 in stage 26.0 (TID 157). 2203 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 1.0 in stage 26.0 (TID 157) in 33 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 0.0 in stage 26.0 (TID 156). 2203 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 26.0 (TID 156) in 36 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2020-05-19 05:25:14 INFO  DAGScheduler:54 - ShuffleMapStage 26 (start at NativeMethodAccessorImpl.java:0) finished in 0.045 s
2020-05-19 05:25:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:14 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 27)
2020-05-19 05:25:14 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Submitting ResultStage 27 (MapPartitionsRDD[207] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_55 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:14 INFO  MemoryStore:54 - Block broadcast_55_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:14 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:14 INFO  SparkContext:54 - Created broadcast 55 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 27 (MapPartitionsRDD[207] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:14 INFO  TaskSchedulerImpl:54 - Adding task set 27.0 with 10 tasks
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 27.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 27.0 (TID 159, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 0.0 in stage 27.0 (TID 158)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 1.0 in stage 27.0 (TID 159)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2148c73e
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@746146ec
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ea6b1c1
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bc49d86
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/14.delta
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 1.0 in stage 27.0 (TID 159). 33063 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 2.0 in stage 27.0 (TID 160, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 2.0 in stage 27.0 (TID 160)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 1.0 in stage 27.0 (TID 159) in 148 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@984d0e7
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38121d27
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 0.0 in stage 27.0 (TID 158). 34047 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 3.0 in stage 27.0 (TID 161, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 27.0 (TID 158) in 160 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 3.0 in stage 27.0 (TID 161)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a5e0b84
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3efd8cd4
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 2.0 in stage 27.0 (TID 160). 34820 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 4.0 in stage 27.0 (TID 162, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 4.0 in stage 27.0 (TID 162)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 2.0 in stage 27.0 (TID 160) in 167 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2033fa7e
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4eba4541
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 3.0 in stage 27.0 (TID 161). 35804 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 5.0 in stage 27.0 (TID 163, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 5.0 in stage 27.0 (TID 163)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 3.0 in stage 27.0 (TID 161) in 168 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e61d958
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@590d3bc2
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 5.0 in stage 27.0 (TID 163). 37837 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 6.0 in stage 27.0 (TID 164, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 6.0 in stage 27.0 (TID 164)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 5.0 in stage 27.0 (TID 163) in 121 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2063e73a
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a6cf847
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 4.0 in stage 27.0 (TID 162). 35829 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 7.0 in stage 27.0 (TID 165, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 7.0 in stage 27.0 (TID 165)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 4.0 in stage 27.0 (TID 162) in 181 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f51a365
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e204f42
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 6.0 in stage 27.0 (TID 164). 38606 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 8.0 in stage 27.0 (TID 166, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 8.0 in stage 27.0 (TID 166)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 6.0 in stage 27.0 (TID 164) in 101 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c06cecc
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27efa3b
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/14.delta
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/14.delta
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 7.0 in stage 27.0 (TID 165). 36299 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Starting task 9.0 in stage 27.0 (TID 167, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:14 INFO  Executor:54 - Running task 9.0 in stage 27.0 (TID 167)
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 7.0 in stage 27.0 (TID 165) in 129 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19b36122
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@685859f9
2020-05-19 05:25:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 13 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 8.0 in stage 27.0 (TID 166). 35149 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 8.0 in stage 27.0 (TID 166) in 138 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 14 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/14.delta
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:14 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 14 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:14 INFO  Executor:54 - Finished task 9.0 in stage 27.0 (TID 167). 34604 bytes result sent to driver
2020-05-19 05:25:14 INFO  TaskSetManager:54 - Finished task 9.0 in stage 27.0 (TID 167) in 102 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2020-05-19 05:25:14 INFO  DAGScheduler:54 - ResultStage 27 (start at NativeMethodAccessorImpl.java:0) finished in 0.728 s
2020-05-19 05:25:14 INFO  DAGScheduler:54 - Job 26 finished: start at NativeMethodAccessorImpl.java:0, took 0.781890 s
2020-05-19 05:25:14 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@766103b6 is committing.
-------------------------------------------
Batch: 13
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:15 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@766103b6 committed.
2020-05-19 05:25:15 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Job 27 finished: start at NativeMethodAccessorImpl.java:0, took 0.000045 s
2020-05-19 05:25:15 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:13.619Z",
  "batchId" : 13,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0672358591248665,
  "processedRowsPerSecond" : 1.2070006035003018,
  "durationMs" : {
    "addBatch" : 1517,
    "getBatch" : 5,
    "getOffset" : 11,
    "queryPlanning" : 84,
    "triggerExecution" : 1657,
    "walCommit" : 40
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:08:00.000Z",
    "max" : "2018-12-28T17:08:00.000Z",
    "min" : "2018-12-28T17:08:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2813,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3227,
        "0" : 3125
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3126
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0672358591248665,
    "processedRowsPerSecond" : 1.2070006035003018
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:15 INFO  MicroBatchExecution:54 - Committed offsets for batch 14. Metadata OffsetSeqMetadata(1546297020000,1589865915378,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:15 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3228,"0":3126}}), end = {"department.police.service.call":{"1":3228,"0":3128}}
2020-05-19 05:25:15 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:15 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3126,3128,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3228,3228,None)
2020-05-19 05:25:15 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:15 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:15 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_56 stored as values in memory (estimated size 281.8 KB, free 364.1 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1214
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1072
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1178
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1175
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1164
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1244
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1183
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1190
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1186
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1201
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1076
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1106
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1240
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1182
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1232
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1247
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1206
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1165
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1215
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1074
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_55_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1197
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1092
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1230
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1205
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1189
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1237
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1176
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1246
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1173
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1168
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1170
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1096
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1239
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1249
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1171
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1194
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1202
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1087
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1179
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1091
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1180
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1226
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1169
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1088
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1222
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1105
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1217
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1227
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1229
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1216
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1224
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1223
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1243
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1157
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1081
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1075
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1181
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1101
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1211
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1098
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1095
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1192
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1191
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1235
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1167
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1233
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1245
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1225
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1188
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1221
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1195
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1099
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1159
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1210
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1203
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1174
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1208
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1082
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1242
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1093
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1228
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1187
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1163
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1090
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1199
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1219
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1177
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1160
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1080
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1085
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1102
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1094
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1204
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_54_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1097
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1158
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1078
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1161
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1162
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1207
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1213
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1200
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1220
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1104
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1238
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1212
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1234
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1073
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1241
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1079
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1070
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1184
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_56_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1231
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1236
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1172
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1218
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1086
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1084
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1100
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1103
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1185
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1196
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1193
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1198
2020-05-19 05:25:15 INFO  SparkContext:54 - Created broadcast 56 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned shuffle 13
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1209
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned shuffle 12
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1077
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1083
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1089
2020-05-19 05:25:15 INFO  ContextCleaner:54 - Cleaned accumulator 1166
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_57 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  SparkContext:54 - Created broadcast 57 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:15 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a8968fd. The input RDD has 10 partitions.
2020-05-19 05:25:15 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Registering RDD 216 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Got job 28 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Final stage: ResultStage 29 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 28)
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 28)
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 28 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_58 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:15 INFO  MemoryStore:54 - Block broadcast_58_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:15 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:15 INFO  SparkContext:54 - Created broadcast 58 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:15 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:15 INFO  TaskSchedulerImpl:54 - Adding task set 28.0 with 2 tasks
2020-05-19 05:25:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 28.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:15 INFO  TaskSetManager:54 - Starting task 1.0 in stage 28.0 (TID 169, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:15 INFO  Executor:54 - Running task 0.0 in stage 28.0 (TID 168)
2020-05-19 05:25:15 INFO  Executor:54 - Running task 1.0 in stage 28.0 (TID 169)
2020-05-19 05:25:15 INFO  KafkaSourceRDD:54 - Beginning offset 3228 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 1.0 in stage 28.0 (TID 169). 2074 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 1.0 in stage 28.0 (TID 169) in 24 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 0.0 in stage 28.0 (TID 168). 2203 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 28.0 (TID 168) in 30 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2020-05-19 05:25:16 INFO  DAGScheduler:54 - ShuffleMapStage 28 (start at NativeMethodAccessorImpl.java:0) finished in 0.036 s
2020-05-19 05:25:16 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:16 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:16 INFO  DAGScheduler:54 - waiting: Set(ResultStage 29)
2020-05-19 05:25:16 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:16 INFO  DAGScheduler:54 - Submitting ResultStage 29 (MapPartitionsRDD[222] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:16 INFO  MemoryStore:54 - Block broadcast_59 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:16 INFO  MemoryStore:54 - Block broadcast_59_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:16 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:16 INFO  SparkContext:54 - Created broadcast 59 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:16 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 29 (MapPartitionsRDD[222] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:16 INFO  TaskSchedulerImpl:54 - Adding task set 29.0 with 10 tasks
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 29.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 1.0 in stage 29.0 (TID 171, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 1.0 in stage 29.0 (TID 171)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 0.0 in stage 29.0 (TID 170)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fa71d64
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dcbde47
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5937f455
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6705c226
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/15.delta
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 1.0 in stage 29.0 (TID 171). 33063 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 2.0 in stage 29.0 (TID 172, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 2.0 in stage 29.0 (TID 172)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 1.0 in stage 29.0 (TID 171) in 145 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b1c9d64
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b68ba77
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 0.0 in stage 29.0 (TID 170). 34047 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 3.0 in stage 29.0 (TID 173, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 29.0 (TID 170) in 197 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 3.0 in stage 29.0 (TID 173)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9219f75
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@416d2c4e
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 2.0 in stage 29.0 (TID 172). 34820 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 4.0 in stage 29.0 (TID 174, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 2.0 in stage 29.0 (TID 172) in 140 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 4.0 in stage 29.0 (TID 174)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a66ffc4
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d8ed97
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 3.0 in stage 29.0 (TID 173). 35804 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 5.0 in stage 29.0 (TID 175, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 5.0 in stage 29.0 (TID 175)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 3.0 in stage 29.0 (TID 173) in 135 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a413d9d
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76d1c125
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 4.0 in stage 29.0 (TID 174). 35829 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 6.0 in stage 29.0 (TID 176, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 6.0 in stage 29.0 (TID 176)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 4.0 in stage 29.0 (TID 174) in 110 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@aeddf65
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@545da03a
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 6.0 in stage 29.0 (TID 176). 38615 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 7.0 in stage 29.0 (TID 177, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 6.0 in stage 29.0 (TID 176) in 83 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 7.0 in stage 29.0 (TID 177)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72605592
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38674585
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 5.0 in stage 29.0 (TID 175). 37837 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 8.0 in stage 29.0 (TID 178, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 8.0 in stage 29.0 (TID 178)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 5.0 in stage 29.0 (TID 175) in 160 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc75220
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34ad3cad
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/15.delta
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 8.0 in stage 29.0 (TID 178). 35149 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Starting task 9.0 in stage 29.0 (TID 179, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 8.0 in stage 29.0 (TID 178) in 82 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:16 INFO  Executor:54 - Running task 9.0 in stage 29.0 (TID 179)
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46671f74
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74737b1f
2020-05-19 05:25:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 14 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 7.0 in stage 29.0 (TID 177). 36299 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 7.0 in stage 29.0 (TID 177) in 157 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 15 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/15.delta
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:16 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 15 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:16 INFO  Executor:54 - Finished task 9.0 in stage 29.0 (TID 179). 34604 bytes result sent to driver
2020-05-19 05:25:16 INFO  TaskSetManager:54 - Finished task 9.0 in stage 29.0 (TID 179) in 135 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2020-05-19 05:25:16 INFO  DAGScheduler:54 - ResultStage 29 (start at NativeMethodAccessorImpl.java:0) finished in 0.709 s
2020-05-19 05:25:16 INFO  DAGScheduler:54 - Job 28 finished: start at NativeMethodAccessorImpl.java:0, took 0.752816 s
2020-05-19 05:25:16 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a8968fd is committing.
-------------------------------------------
Batch: 14
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:16 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a8968fd committed.
2020-05-19 05:25:16 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:16 INFO  DAGScheduler:54 - Job 29 finished: start at NativeMethodAccessorImpl.java:0, took 0.000049 s
2020-05-19 05:25:16 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:15.376Z",
  "batchId" : 14,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1383039271485487,
  "processedRowsPerSecond" : 1.266624445851805,
  "durationMs" : {
    "addBatch" : 1378,
    "getBatch" : 5,
    "getOffset" : 2,
    "queryPlanning" : 99,
    "triggerExecution" : 1579,
    "walCommit" : 95
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:07:30.000Z",
    "max" : "2018-12-28T17:08:00.000Z",
    "min" : "2018-12-28T17:07:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2813,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3126
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3128
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1383039271485487,
    "processedRowsPerSecond" : 1.266624445851805
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:17 INFO  MicroBatchExecution:54 - Committed offsets for batch 15. Metadata OffsetSeqMetadata(1546297020000,1589865917072,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:17 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3228,"0":3128}}), end = {"department.police.service.call":{"1":3228,"0":3129}}
2020-05-19 05:25:17 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:17 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3128,3129,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3228,3228,None)
2020-05-19 05:25:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_60 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_60_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  SparkContext:54 - Created broadcast 60 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_61 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_61_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  SparkContext:54 - Created broadcast 61 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:17 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@418951d3. The input RDD has 10 partitions.
2020-05-19 05:25:17 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Registering RDD 231 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Got job 30 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Final stage: ResultStage 31 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 30)
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 30)
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 30 (MapPartitionsRDD[231] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_62 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_62_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  SparkContext:54 - Created broadcast 62 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[231] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:17 INFO  TaskSchedulerImpl:54 - Adding task set 30.0 with 2 tasks
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 30.0 (TID 180, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 30.0 (TID 181, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 0.0 in stage 30.0 (TID 180)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 1.0 in stage 30.0 (TID 181)
2020-05-19 05:25:17 INFO  KafkaSourceRDD:54 - Beginning offset 3228 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:17 INFO  Executor:54 - Finished task 1.0 in stage 30.0 (TID 181). 2074 bytes result sent to driver
2020-05-19 05:25:17 INFO  Executor:54 - Finished task 0.0 in stage 30.0 (TID 180). 2203 bytes result sent to driver
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 30.0 (TID 181) in 27 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 30.0 (TID 180) in 33 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2020-05-19 05:25:17 INFO  DAGScheduler:54 - ShuffleMapStage 30 (start at NativeMethodAccessorImpl.java:0) finished in 0.041 s
2020-05-19 05:25:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:17 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 31)
2020-05-19 05:25:17 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Submitting ResultStage 31 (MapPartitionsRDD[237] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_63 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:17 INFO  MemoryStore:54 - Block broadcast_63_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Added broadcast_63_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  SparkContext:54 - Created broadcast 63 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:17 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 31 (MapPartitionsRDD[237] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:17 INFO  TaskSchedulerImpl:54 - Adding task set 31.0 with 10 tasks
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 31.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 31.0 (TID 183, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 1.0 in stage 31.0 (TID 183)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 0.0 in stage 31.0 (TID 182)
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5500f52c
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@770e696a
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@129dda03
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e3ebf5
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1252
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1281
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1263
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1305
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1327
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1333
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1307
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Removed broadcast_56_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1250
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1302
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1287
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1283
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1261
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Removed broadcast_59_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1266
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Removed broadcast_62_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1274
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1321
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1313
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1334
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1267
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1314
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1323
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1272
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1254
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1316
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1259
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1260
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1286
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1310
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1304
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1303
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1301
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1322
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1328
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1326
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1270
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1288
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1324
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1306
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1308
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1311
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1332
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1331
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Removed broadcast_57_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1251
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1296
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1276
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1280
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1265
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1338
2020-05-19 05:25:17 INFO  BlockManagerInfo:54 - Removed broadcast_58_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1299
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1275
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1317
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1330
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1271
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1285
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1248
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned shuffle 14
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1279
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1293
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1284
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1312
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1277
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1289
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1262
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1257
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1335
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1264
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1329
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1319
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1294
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1255
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1298
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1325
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1320
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1290
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1278
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1297
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1258
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1292
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1295
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1315
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1318
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1282
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1268
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1291
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1300
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1269
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1309
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1273
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1253
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1256
2020-05-19 05:25:17 INFO  ContextCleaner:54 - Cleaned accumulator 1336
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/16.delta
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/16.delta
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:17 INFO  Executor:54 - Finished task 1.0 in stage 31.0 (TID 183). 33106 bytes result sent to driver
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 2.0 in stage 31.0 (TID 184, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 31.0 (TID 183) in 153 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 2.0 in stage 31.0 (TID 184)
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26ce3e6c
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2684161a
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:17 INFO  Executor:54 - Finished task 0.0 in stage 31.0 (TID 182). 34090 bytes result sent to driver
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 3.0 in stage 31.0 (TID 185, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 3.0 in stage 31.0 (TID 185)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 31.0 (TID 182) in 179 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@647ea936
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@244db81b
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/16.delta
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/16.delta
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:17 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:17 INFO  Executor:54 - Finished task 3.0 in stage 31.0 (TID 185). 35905 bytes result sent to driver
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Starting task 4.0 in stage 31.0 (TID 186, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:17 INFO  Executor:54 - Running task 4.0 in stage 31.0 (TID 186)
2020-05-19 05:25:17 INFO  TaskSetManager:54 - Finished task 3.0 in stage 31.0 (TID 185) in 106 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23572c0d
2020-05-19 05:25:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35f76895
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 2.0 in stage 31.0 (TID 184). 34820 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Starting task 5.0 in stage 31.0 (TID 187, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:18 INFO  Executor:54 - Running task 5.0 in stage 31.0 (TID 187)
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 2.0 in stage 31.0 (TID 184) in 171 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f0e632d
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7669387c
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/16.delta
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/16.delta
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 4.0 in stage 31.0 (TID 186). 35829 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Starting task 6.0 in stage 31.0 (TID 188, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:18 INFO  Executor:54 - Running task 6.0 in stage 31.0 (TID 188)
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 4.0 in stage 31.0 (TID 186) in 144 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1af104f9
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a7d36f5
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 5.0 in stage 31.0 (TID 187). 37837 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Starting task 7.0 in stage 31.0 (TID 189, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:18 INFO  Executor:54 - Running task 7.0 in stage 31.0 (TID 189)
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 5.0 in stage 31.0 (TID 187) in 208 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/16.delta
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bb9fb2a
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47f441e8
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 6.0 in stage 31.0 (TID 188). 38615 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Starting task 8.0 in stage 31.0 (TID 190, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:18 INFO  Executor:54 - Running task 8.0 in stage 31.0 (TID 190)
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 6.0 in stage 31.0 (TID 188) in 188 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f58d7a0
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ba041
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/16.delta
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/16.delta
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 7.0 in stage 31.0 (TID 189). 36299 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Starting task 9.0 in stage 31.0 (TID 191, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 7.0 in stage 31.0 (TID 189) in 223 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:18 INFO  Executor:54 - Running task 9.0 in stage 31.0 (TID 191)
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@133c3b0e
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@621bc51e
2020-05-19 05:25:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 15 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 8.0 in stage 31.0 (TID 190). 35149 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 8.0 in stage 31.0 (TID 190) in 199 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 16 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/16.delta
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:18 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 16 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:18 INFO  Executor:54 - Finished task 9.0 in stage 31.0 (TID 191). 34604 bytes result sent to driver
2020-05-19 05:25:18 INFO  TaskSetManager:54 - Finished task 9.0 in stage 31.0 (TID 191) in 122 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2020-05-19 05:25:18 INFO  DAGScheduler:54 - ResultStage 31 (start at NativeMethodAccessorImpl.java:0) finished in 0.885 s
2020-05-19 05:25:18 INFO  DAGScheduler:54 - Job 30 finished: start at NativeMethodAccessorImpl.java:0, took 0.937999 s
2020-05-19 05:25:18 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@418951d3 is committing.
-------------------------------------------
Batch: 15
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:18 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@418951d3 committed.
2020-05-19 05:25:18 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:18 INFO  DAGScheduler:54 - Job 31 finished: start at NativeMethodAccessorImpl.java:0, took 0.000039 s
2020-05-19 05:25:18 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:17.066Z",
  "batchId" : 15,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.591715976331361,
  "processedRowsPerSecond" : 0.5494505494505494,
  "durationMs" : {
    "addBatch" : 1591,
    "getBatch" : 4,
    "getOffset" : 5,
    "queryPlanning" : 155,
    "triggerExecution" : 1819,
    "walCommit" : 62
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:07:00.000Z",
    "max" : "2018-12-28T17:07:00.000Z",
    "min" : "2018-12-28T17:07:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2814,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3128
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3129
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.591715976331361,
    "processedRowsPerSecond" : 0.5494505494505494
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:19 INFO  MicroBatchExecution:54 - Committed offsets for batch 16. Metadata OffsetSeqMetadata(1546297020000,1589865918982,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:19 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3228,"0":3129}}), end = {"department.police.service.call":{"1":3228,"0":3131}}
2020-05-19 05:25:19 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:19 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3129,3131,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3228,3228,None)
2020-05-19 05:25:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_64 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_64_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:19 INFO  BlockManagerInfo:54 - Added broadcast_64_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:19 INFO  SparkContext:54 - Created broadcast 64 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_65 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_65_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:19 INFO  BlockManagerInfo:54 - Added broadcast_65_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:19 INFO  SparkContext:54 - Created broadcast 65 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:19 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2253b9d8. The input RDD has 10 partitions.
2020-05-19 05:25:19 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Registering RDD 246 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Got job 32 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Final stage: ResultStage 33 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 32)
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 32)
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 32 (MapPartitionsRDD[246] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_66 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:19 INFO  BlockManagerInfo:54 - Added broadcast_66_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:19 INFO  SparkContext:54 - Created broadcast 66 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[246] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:19 INFO  TaskSchedulerImpl:54 - Adding task set 32.0 with 2 tasks
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 32.0 (TID 192, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 32.0 (TID 193, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 0.0 in stage 32.0 (TID 192)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 1.0 in stage 32.0 (TID 193)
2020-05-19 05:25:19 INFO  KafkaSourceRDD:54 - Beginning offset 3228 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 0.0 in stage 32.0 (TID 192). 2074 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 32.0 (TID 192) in 26 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 1.0 in stage 32.0 (TID 193). 2246 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 32.0 (TID 193) in 27 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2020-05-19 05:25:19 INFO  DAGScheduler:54 - ShuffleMapStage 32 (start at NativeMethodAccessorImpl.java:0) finished in 0.034 s
2020-05-19 05:25:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:19 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 33)
2020-05-19 05:25:19 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Submitting ResultStage 33 (MapPartitionsRDD[252] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_67 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:19 INFO  MemoryStore:54 - Block broadcast_67_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:19 INFO  BlockManagerInfo:54 - Added broadcast_67_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:19 INFO  SparkContext:54 - Created broadcast 67 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:19 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 33 (MapPartitionsRDD[252] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:19 INFO  TaskSchedulerImpl:54 - Adding task set 33.0 with 10 tasks
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 33.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 33.0 (TID 195, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 0.0 in stage 33.0 (TID 194)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  Executor:54 - Running task 1.0 in stage 33.0 (TID 195)
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f523c1
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a219445
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4530941d
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77fe1008
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/17.delta
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 0.0 in stage 33.0 (TID 194). 34047 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 2.0 in stage 33.0 (TID 196, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 33.0 (TID 194) in 122 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:19 INFO  Executor:54 - Running task 2.0 in stage 33.0 (TID 196)
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 1.0 in stage 33.0 (TID 195). 33063 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 3.0 in stage 33.0 (TID 197, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 3.0 in stage 33.0 (TID 197)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 33.0 (TID 195) in 131 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37921c2b
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4650469c
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@480dc80
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5181605f
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 2.0 in stage 33.0 (TID 196). 34829 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 4.0 in stage 33.0 (TID 198, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 2.0 in stage 33.0 (TID 196) in 124 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 4.0 in stage 33.0 (TID 198)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19552e7
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@500d752e
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 3.0 in stage 33.0 (TID 197). 35905 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 5.0 in stage 33.0 (TID 199, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 5.0 in stage 33.0 (TID 199)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 3.0 in stage 33.0 (TID 197) in 195 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@729112b9
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e6b9bc4
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 4.0 in stage 33.0 (TID 198). 35829 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 6.0 in stage 33.0 (TID 200, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 4.0 in stage 33.0 (TID 198) in 155 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 6.0 in stage 33.0 (TID 200)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d75a89b
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45a7245e
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/17.delta
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 5.0 in stage 33.0 (TID 199). 37837 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 7.0 in stage 33.0 (TID 201, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 7.0 in stage 33.0 (TID 201)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 5.0 in stage 33.0 (TID 199) in 164 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@356d7ff4
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f0374f3
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/17.delta
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:19 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:19 INFO  Executor:54 - Finished task 6.0 in stage 33.0 (TID 200). 38606 bytes result sent to driver
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Starting task 8.0 in stage 33.0 (TID 202, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:19 INFO  Executor:54 - Running task 8.0 in stage 33.0 (TID 202)
2020-05-19 05:25:19 INFO  TaskSetManager:54 - Finished task 6.0 in stage 33.0 (TID 200) in 143 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33f35e
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d6546bf
2020-05-19 05:25:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/17.delta
2020-05-19 05:25:20 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:20 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:20 INFO  Executor:54 - Finished task 7.0 in stage 33.0 (TID 201). 36299 bytes result sent to driver
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Starting task 9.0 in stage 33.0 (TID 203, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:20 INFO  Executor:54 - Running task 9.0 in stage 33.0 (TID 203)
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Finished task 7.0 in stage 33.0 (TID 201) in 102 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e329421
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f530fc5
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 16 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:20 INFO  Executor:54 - Finished task 8.0 in stage 33.0 (TID 202). 35149 bytes result sent to driver
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Finished task 8.0 in stage 33.0 (TID 202) in 79 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Committed version 17 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/17.delta
2020-05-19 05:25:20 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:20 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 17 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:20 INFO  Executor:54 - Finished task 9.0 in stage 33.0 (TID 203). 34604 bytes result sent to driver
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Finished task 9.0 in stage 33.0 (TID 203) in 145 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1353
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1407
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1356
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1396
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1406
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1391
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1360
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1370
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1340
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1349
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1357
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1418
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1381
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Removed broadcast_66_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - ResultStage 33 (start at NativeMethodAccessorImpl.java:0) finished in 0.741 s
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Job 32 finished: start at NativeMethodAccessorImpl.java:0, took 0.793595 s
2020-05-19 05:25:20 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2253b9d8 is committing.
-------------------------------------------
Batch: 16
-------------------------------------------
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1354
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1404
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1379
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1367
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1363
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1339
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1389
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1399
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1361
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1380
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1346
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1401
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1402
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1413
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1385
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1411
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1414
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1393
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1410
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1375
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1395
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1343
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1345
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1359
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1422
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1423
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1417
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1424
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1427
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1347
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1387
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1368
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1419
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1376
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1382
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1378
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1341
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1403
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1372
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1364
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1409
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Removed broadcast_61_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1390
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1362
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1352
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1394
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Removed broadcast_63_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1416
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1383
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1425
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1392
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1365
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1420
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1348
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1384
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1366
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1400
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1351
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1398
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1412
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1377
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1355
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1373
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1358
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1405
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1350
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1415
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1374
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned shuffle 15
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1342
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1397
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1369
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1337
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1371
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Removed broadcast_60_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1344
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1388
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1421
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1386
2020-05-19 05:25:20 INFO  ContextCleaner:54 - Cleaned accumulator 1408
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:20 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2253b9d8 committed.
2020-05-19 05:25:20 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Job 33 finished: start at NativeMethodAccessorImpl.java:0, took 0.000035 s
2020-05-19 05:25:20 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:18.978Z",
  "batchId" : 16,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0460251046025104,
  "processedRowsPerSecond" : 1.4336917562724014,
  "durationMs" : {
    "addBatch" : 1277,
    "getBatch" : 5,
    "getOffset" : 4,
    "queryPlanning" : 50,
    "triggerExecution" : 1395,
    "walCommit" : 57
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:06:00.000Z",
    "max" : "2018-12-28T17:06:00.000Z",
    "min" : "2018-12-28T17:06:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2814,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3129
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3131
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0460251046025104,
    "processedRowsPerSecond" : 1.4336917562724014
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:20 INFO  MicroBatchExecution:54 - Committed offsets for batch 17. Metadata OffsetSeqMetadata(1546297020000,1589865920422,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:20 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3228,"0":3131}}), end = {"department.police.service.call":{"1":3228,"0":3133}}
2020-05-19 05:25:20 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:20 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3131,3133,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3228,3228,None)
2020-05-19 05:25:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_68 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_68_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Added broadcast_68_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  SparkContext:54 - Created broadcast 68 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_69 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_69_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Added broadcast_69_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  SparkContext:54 - Created broadcast 69 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:20 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4fac24c2. The input RDD has 10 partitions.
2020-05-19 05:25:20 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Registering RDD 261 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Got job 34 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Final stage: ResultStage 35 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 34)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 34)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 34 (MapPartitionsRDD[261] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_70 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_70_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Added broadcast_70_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  SparkContext:54 - Created broadcast 70 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[261] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:20 INFO  TaskSchedulerImpl:54 - Adding task set 34.0 with 2 tasks
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 34.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 34.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:20 INFO  Executor:54 - Running task 1.0 in stage 34.0 (TID 205)
2020-05-19 05:25:20 INFO  Executor:54 - Running task 0.0 in stage 34.0 (TID 204)
2020-05-19 05:25:20 INFO  KafkaSourceRDD:54 - Beginning offset 3228 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:20 INFO  Executor:54 - Finished task 0.0 in stage 34.0 (TID 204). 2074 bytes result sent to driver
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 34.0 (TID 204) in 23 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:20 INFO  Executor:54 - Finished task 1.0 in stage 34.0 (TID 205). 2203 bytes result sent to driver
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Finished task 1.0 in stage 34.0 (TID 205) in 36 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2020-05-19 05:25:20 INFO  DAGScheduler:54 - ShuffleMapStage 34 (start at NativeMethodAccessorImpl.java:0) finished in 0.048 s
2020-05-19 05:25:20 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:20 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 35)
2020-05-19 05:25:20 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Submitting ResultStage 35 (MapPartitionsRDD[267] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_71 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:20 INFO  MemoryStore:54 - Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:20 INFO  BlockManagerInfo:54 - Added broadcast_71_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:20 INFO  SparkContext:54 - Created broadcast 71 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:20 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 35 (MapPartitionsRDD[267] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:20 INFO  TaskSchedulerImpl:54 - Adding task set 35.0 with 10 tasks
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 35.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 35.0 (TID 207, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:20 INFO  Executor:54 - Running task 1.0 in stage 35.0 (TID 207)
2020-05-19 05:25:20 INFO  Executor:54 - Running task 0.0 in stage 35.0 (TID 206)
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67ba5848
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57b7c92d
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52c07f27
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@203e77c8
2020-05-19 05:25:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:20 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 1.0 in stage 35.0 (TID 207). 33063 bytes result sent to driver
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 0.0 in stage 35.0 (TID 206). 34047 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 2.0 in stage 35.0 (TID 208, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 2.0 in stage 35.0 (TID 208)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 1.0 in stage 35.0 (TID 207) in 150 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 3.0 in stage 35.0 (TID 209, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 3.0 in stage 35.0 (TID 209)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 35.0 (TID 206) in 155 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fb33fea
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63f946f3
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69ef725f
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@450d83db
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 3.0 in stage 35.0 (TID 209). 35905 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 4.0 in stage 35.0 (TID 210, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 4.0 in stage 35.0 (TID 210)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 3.0 in stage 35.0 (TID 209) in 140 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f0d033b
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18c45c3
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 2.0 in stage 35.0 (TID 208). 34829 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 5.0 in stage 35.0 (TID 211, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 2.0 in stage 35.0 (TID 208) in 164 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 5.0 in stage 35.0 (TID 211)
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b7aa3a8
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6275e40f
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/18.delta
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 4.0 in stage 35.0 (TID 210). 35829 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 6.0 in stage 35.0 (TID 212, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 4.0 in stage 35.0 (TID 210) in 164 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 6.0 in stage 35.0 (TID 212)
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 5.0 in stage 35.0 (TID 211). 37837 bytes result sent to driver
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 7.0 in stage 35.0 (TID 213, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b324666
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e6a413
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 5.0 in stage 35.0 (TID 211) in 150 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 7.0 in stage 35.0 (TID 213)
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@408c8801
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56804548
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/18.delta
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 6.0 in stage 35.0 (TID 212). 38606 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 8.0 in stage 35.0 (TID 214, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 6.0 in stage 35.0 (TID 212) in 142 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 8.0 in stage 35.0 (TID 214)
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f128033
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 7.0 in stage 35.0 (TID 213). 36299 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Starting task 9.0 in stage 35.0 (TID 215, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:21 INFO  Executor:54 - Running task 9.0 in stage 35.0 (TID 215)
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 7.0 in stage 35.0 (TID 213) in 147 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2635edb1
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55c2f288
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@572eaf89
2020-05-19 05:25:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 17 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/18.delta
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 18 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/18.delta
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:21 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 9.0 in stage 35.0 (TID 215). 34604 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 9.0 in stage 35.0 (TID 215) in 129 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 18 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:21 INFO  Executor:54 - Finished task 8.0 in stage 35.0 (TID 214). 35149 bytes result sent to driver
2020-05-19 05:25:21 INFO  TaskSetManager:54 - Finished task 8.0 in stage 35.0 (TID 214) in 152 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:21 INFO  TaskSchedulerImpl:54 - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2020-05-19 05:25:21 INFO  DAGScheduler:54 - ResultStage 35 (start at NativeMethodAccessorImpl.java:0) finished in 0.760 s
2020-05-19 05:25:21 INFO  DAGScheduler:54 - Job 34 finished: start at NativeMethodAccessorImpl.java:0, took 0.817060 s
2020-05-19 05:25:21 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4fac24c2 is committing.
-------------------------------------------
Batch: 17
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:21 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4fac24c2 committed.
2020-05-19 05:25:21 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:21 INFO  DAGScheduler:54 - Job 35 finished: start at NativeMethodAccessorImpl.java:0, took 0.000044 s
2020-05-19 05:25:21 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:20.418Z",
  "batchId" : 17,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3888888888888888,
  "processedRowsPerSecond" : 1.3986013986013988,
  "durationMs" : {
    "addBatch" : 1278,
    "getBatch" : 5,
    "getOffset" : 4,
    "queryPlanning" : 46,
    "triggerExecution" : 1430,
    "walCommit" : 97
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:05:30.000Z",
    "max" : "2018-12-28T17:06:00.000Z",
    "min" : "2018-12-28T17:05:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2814,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3131
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3133
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3888888888888888,
    "processedRowsPerSecond" : 1.3986013986013988
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:22 INFO  MicroBatchExecution:54 - Committed offsets for batch 18. Metadata OffsetSeqMetadata(1546297020000,1589865921959,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:22 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3228,"0":3133}}), end = {"department.police.service.call":{"1":3229,"0":3133}}
2020-05-19 05:25:22 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:22 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3133,3133,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3228,3229,None)
2020-05-19 05:25:22 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:22 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:22 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_72 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_72_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Added broadcast_72_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:22 INFO  SparkContext:54 - Created broadcast 72 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1496
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1595
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1554
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1597
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1426
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1494
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1507
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1535
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1530
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1486
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1446
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1455
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1430
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1433
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1453
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1525
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1564
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1435
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1438
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1504
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1599
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1573
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1600
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1572
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1512
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1434
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1569
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1582
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1492
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1533
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1549
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1465
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1471
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1548
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1567
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1557
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_67_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1472
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1560
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1565
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1514
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1448
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1505
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1511
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1558
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1591
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1536
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1523
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1475
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1580
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1466
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1502
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1588
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1487
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1495
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned shuffle 16
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1526
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned shuffle 17
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1444
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1447
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1459
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1584
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1605
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1489
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1537
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1585
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1436
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1440
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1593
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1544
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1501
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1568
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1602
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1432
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1577
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1594
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1559
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1480
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1464
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1439
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1547
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1553
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1429
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1483
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1527
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1479
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1570
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1503
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1579
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1441
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1542
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1470
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1484
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1524
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1598
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1442
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1538
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1566
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1534
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1445
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1481
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1603
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1454
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1563
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1550
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1583
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1463
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1590
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1592
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1596
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1461
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1497
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1601
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1581
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1490
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1543
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1431
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1457
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1545
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1552
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1500
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_68_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_65_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1562
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1510
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1518
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1532
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1485
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1561
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1531
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1575
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1587
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_71_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1449
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1519
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1458
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1460
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1521
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1491
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1578
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1529
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_64_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1556
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1528
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1522
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1450
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1508
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1451
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1498
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1539
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1551
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1589
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1499
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1515
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1555
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1467
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1540
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1443
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1477
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1437
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1516
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1541
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1478
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1546
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1452
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1586
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1513
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1509
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1517
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1482
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1520
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1576
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1473
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1574
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1488
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1456
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1476
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_70_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1468
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1469
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1428
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1493
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1506
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1462
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1474
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Removed broadcast_69_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  ContextCleaner:54 - Cleaned accumulator 1571
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_73 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_73_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Added broadcast_73_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  SparkContext:54 - Created broadcast 73 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:22 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@649abc31. The input RDD has 10 partitions.
2020-05-19 05:25:22 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Registering RDD 276 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Got job 36 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Final stage: ResultStage 37 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 36)
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 36)
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 36 (MapPartitionsRDD[276] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_74 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_74_piece0 stored as bytes in memory (estimated size 15.7 KB, free 365.0 MB)
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Added broadcast_74_piece0 in memory on 234cbc3ca30b:38543 (size: 15.7 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  SparkContext:54 - Created broadcast 74 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[276] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:22 INFO  TaskSchedulerImpl:54 - Adding task set 36.0 with 2 tasks
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 36.0 (TID 216, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 1.0 in stage 36.0 (TID 217, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 1.0 in stage 36.0 (TID 217)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 0.0 in stage 36.0 (TID 216)
2020-05-19 05:25:22 INFO  KafkaSourceRDD:54 - Beginning offset 3133 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 1.0 in stage 36.0 (TID 217). 2074 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 1.0 in stage 36.0 (TID 217) in 30 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 0.0 in stage 36.0 (TID 216). 2203 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 36.0 (TID 216) in 42 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2020-05-19 05:25:22 INFO  DAGScheduler:54 - ShuffleMapStage 36 (start at NativeMethodAccessorImpl.java:0) finished in 0.069 s
2020-05-19 05:25:22 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:22 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 37)
2020-05-19 05:25:22 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Submitting ResultStage 37 (MapPartitionsRDD[282] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_75 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:22 INFO  MemoryStore:54 - Block broadcast_75_piece0 stored as bytes in memory (estimated size 19.0 KB, free 364.9 MB)
2020-05-19 05:25:22 INFO  BlockManagerInfo:54 - Added broadcast_75_piece0 in memory on 234cbc3ca30b:38543 (size: 19.0 KB, free: 366.2 MB)
2020-05-19 05:25:22 INFO  SparkContext:54 - Created broadcast 75 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:22 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 37 (MapPartitionsRDD[282] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:22 INFO  TaskSchedulerImpl:54 - Adding task set 37.0 with 10 tasks
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 37.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 1.0 in stage 37.0 (TID 219, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 1.0 in stage 37.0 (TID 219)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 0.0 in stage 37.0 (TID 218)
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f48d8d2
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fbedd88
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e9b891c
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32be419c
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/19.delta
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/19.delta
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 1.0 in stage 37.0 (TID 219). 33063 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 2.0 in stage 37.0 (TID 220, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 1.0 in stage 37.0 (TID 219) in 112 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 2.0 in stage 37.0 (TID 220)
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36c09c0f
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f36283d
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 0.0 in stage 37.0 (TID 218). 34047 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 3.0 in stage 37.0 (TID 221, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 37.0 (TID 218) in 132 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 3.0 in stage 37.0 (TID 221)
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2675d3bb
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3115fc1d
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/19.delta
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/19.delta
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:22 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 3.0 in stage 37.0 (TID 221). 35905 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 4.0 in stage 37.0 (TID 222, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 4.0 in stage 37.0 (TID 222)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 3.0 in stage 37.0 (TID 221) in 126 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183ff86a
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ff3cfcb
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:22 INFO  Executor:54 - Finished task 2.0 in stage 37.0 (TID 220). 34820 bytes result sent to driver
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Starting task 5.0 in stage 37.0 (TID 223, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:22 INFO  TaskSetManager:54 - Finished task 2.0 in stage 37.0 (TID 220) in 159 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:22 INFO  Executor:54 - Running task 5.0 in stage 37.0 (TID 223)
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63261dbb
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@780c66fc
2020-05-19 05:25:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/19.delta
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/19.delta
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 5.0 in stage 37.0 (TID 223). 37837 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 6.0 in stage 37.0 (TID 224, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 6.0 in stage 37.0 (TID 224)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 5.0 in stage 37.0 (TID 223) in 114 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e47be30
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f07a94
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 4.0 in stage 37.0 (TID 222). 35829 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 7.0 in stage 37.0 (TID 225, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 7.0 in stage 37.0 (TID 225)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 4.0 in stage 37.0 (TID 222) in 183 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/19.delta
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7454169c
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e8c7ff
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 6.0 in stage 37.0 (TID 224). 38606 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 8.0 in stage 37.0 (TID 226, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 8.0 in stage 37.0 (TID 226)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 6.0 in stage 37.0 (TID 224) in 96 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c81ad86
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3de9df5f
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/19.delta
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/19.delta
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 7.0 in stage 37.0 (TID 225). 36299 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 9.0 in stage 37.0 (TID 227, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 9.0 in stage 37.0 (TID 227)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 7.0 in stage 37.0 (TID 225) in 96 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@367db751
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1660eed7
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 18 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 8.0 in stage 37.0 (TID 226). 35149 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 8.0 in stage 37.0 (TID 226) in 74 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 19 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/19.delta
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:23 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 19 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 9.0 in stage 37.0 (TID 227). 34604 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 9.0 in stage 37.0 (TID 227) in 70 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2020-05-19 05:25:23 INFO  DAGScheduler:54 - ResultStage 37 (start at NativeMethodAccessorImpl.java:0) finished in 0.609 s
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Job 36 finished: start at NativeMethodAccessorImpl.java:0, took 0.688208 s
2020-05-19 05:25:23 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@649abc31 is committing.
-------------------------------------------
Batch: 18
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:23 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@649abc31 committed.
2020-05-19 05:25:23 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Job 37 finished: start at NativeMethodAccessorImpl.java:0, took 0.000038 s
2020-05-19 05:25:23 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:21.950Z",
  "batchId" : 18,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6527415143603134,
  "processedRowsPerSecond" : 0.6934812760055479,
  "durationMs" : {
    "addBatch" : 1282,
    "getBatch" : 4,
    "getOffset" : 8,
    "queryPlanning" : 85,
    "triggerExecution" : 1442,
    "walCommit" : 61
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:04:00.000Z",
    "max" : "2018-12-28T17:04:00.000Z",
    "min" : "2018-12-28T17:04:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2814,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3228,
        "0" : 3133
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3229,
        "0" : 3133
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6527415143603134,
    "processedRowsPerSecond" : 0.6934812760055479
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:23 INFO  MicroBatchExecution:54 - Committed offsets for batch 19. Metadata OffsetSeqMetadata(1546297020000,1589865923471,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:23 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3229,"0":3133}}), end = {"department.police.service.call":{"1":3231,"0":3133}}
2020-05-19 05:25:23 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:23 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3133,3133,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3229,3231,None)
2020-05-19 05:25:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_76 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_76_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:23 INFO  BlockManagerInfo:54 - Added broadcast_76_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:23 INFO  SparkContext:54 - Created broadcast 76 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_77 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_77_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:23 INFO  BlockManagerInfo:54 - Added broadcast_77_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:23 INFO  SparkContext:54 - Created broadcast 77 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:23 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2b390449. The input RDD has 10 partitions.
2020-05-19 05:25:23 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Registering RDD 291 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Got job 38 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Final stage: ResultStage 39 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 38)
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 38)
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 38 (MapPartitionsRDD[291] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_78 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_78_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:23 INFO  BlockManagerInfo:54 - Added broadcast_78_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:23 INFO  SparkContext:54 - Created broadcast 78 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[291] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:23 INFO  TaskSchedulerImpl:54 - Adding task set 38.0 with 2 tasks
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 38.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 1.0 in stage 38.0 (TID 229, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 1.0 in stage 38.0 (TID 229)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 0.0 in stage 38.0 (TID 228)
2020-05-19 05:25:23 INFO  KafkaSourceRDD:54 - Beginning offset 3133 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 1.0 in stage 38.0 (TID 229). 2074 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 1.0 in stage 38.0 (TID 229) in 34 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:23 INFO  Executor:54 - Finished task 0.0 in stage 38.0 (TID 228). 2203 bytes result sent to driver
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 38.0 (TID 228) in 41 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2020-05-19 05:25:23 INFO  DAGScheduler:54 - ShuffleMapStage 38 (start at NativeMethodAccessorImpl.java:0) finished in 0.047 s
2020-05-19 05:25:23 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:23 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:23 INFO  DAGScheduler:54 - waiting: Set(ResultStage 39)
2020-05-19 05:25:23 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Submitting ResultStage 39 (MapPartitionsRDD[297] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_79 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:23 INFO  MemoryStore:54 - Block broadcast_79_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:23 INFO  BlockManagerInfo:54 - Added broadcast_79_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:23 INFO  SparkContext:54 - Created broadcast 79 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:23 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 39 (MapPartitionsRDD[297] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:23 INFO  TaskSchedulerImpl:54 - Adding task set 39.0 with 10 tasks
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 39.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  TaskSetManager:54 - Starting task 1.0 in stage 39.0 (TID 231, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 1.0 in stage 39.0 (TID 231)
2020-05-19 05:25:23 INFO  Executor:54 - Running task 0.0 in stage 39.0 (TID 230)
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@363b771c
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12ca7d2a
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5de9047f
2020-05-19 05:25:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10498690
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 1.0 in stage 39.0 (TID 231). 33158 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 2.0 in stage 39.0 (TID 232, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 2.0 in stage 39.0 (TID 232)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 1.0 in stage 39.0 (TID 231) in 161 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@279f0bc7
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@510c2fa0
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 0.0 in stage 39.0 (TID 230). 34047 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 3.0 in stage 39.0 (TID 233, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 0.0 in stage 39.0 (TID 230) in 182 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 3.0 in stage 39.0 (TID 233)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@272984e2
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f0fa273
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/20.delta
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 2.0 in stage 39.0 (TID 232). 34820 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 4.0 in stage 39.0 (TID 234, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 2.0 in stage 39.0 (TID 232) in 104 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 4.0 in stage 39.0 (TID 234)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@361ede16
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3197a0ad
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 3.0 in stage 39.0 (TID 233). 35948 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 5.0 in stage 39.0 (TID 235, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1691
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1622
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1638
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1658
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1668
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1619
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1680
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1648
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1681
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1616
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1618
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1628
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1606
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1683
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1632
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1685
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1629
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1654
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1655
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1659
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1694
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1663
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1687
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1620
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 3.0 in stage 39.0 (TID 233) in 224 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:24 INFO  BlockManagerInfo:54 - Removed broadcast_75_piece0 on 234cbc3ca30b:38543 in memory (size: 19.0 KB, free: 366.1 MB)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 5.0 in stage 39.0 (TID 235)
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1609
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1639
2020-05-19 05:25:24 INFO  BlockManagerInfo:54 - Removed broadcast_73_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1650
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1689
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1660
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1688
2020-05-19 05:25:24 INFO  BlockManagerInfo:54 - Removed broadcast_74_piece0 on 234cbc3ca30b:38543 in memory (size: 15.7 KB, free: 366.1 MB)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1614
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1644
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1630
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1647
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1662
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1634
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1675
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1637
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1623
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1621
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1676
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1617
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1640
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1611
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1608
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1645
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1672
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1679
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1665
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1669
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1643
2020-05-19 05:25:24 INFO  BlockManagerInfo:54 - Removed broadcast_78_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1612
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1674
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1615
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1625
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1686
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1671
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1653
2020-05-19 05:25:24 INFO  BlockManagerInfo:54 - Removed broadcast_72_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1682
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1670
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1631
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1684
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1656
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1627
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1613
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1624
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1664
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1607
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1642
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1646
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1692
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1635
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1610
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1678
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1673
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1657
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1626
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1633
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1661
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned shuffle 18
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1690
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1677
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1604
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1636
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1641
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1667
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1651
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1649
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1666
2020-05-19 05:25:24 INFO  ContextCleaner:54 - Cleaned accumulator 1652
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24faaf1b
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6221c40
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 4.0 in stage 39.0 (TID 234). 35872 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 6.0 in stage 39.0 (TID 236, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 4.0 in stage 39.0 (TID 234) in 273 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 6.0 in stage 39.0 (TID 236)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@521ffcc1
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e908a27
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 5.0 in stage 39.0 (TID 235). 37837 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 7.0 in stage 39.0 (TID 237, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 5.0 in stage 39.0 (TID 235) in 167 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 7.0 in stage 39.0 (TID 237)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71762630
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2109cc9c
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/20.delta
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 7.0 in stage 39.0 (TID 237). 36299 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 8.0 in stage 39.0 (TID 238, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 7.0 in stage 39.0 (TID 237) in 82 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 8.0 in stage 39.0 (TID 238)
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c88f1ec
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d3dd204
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 6.0 in stage 39.0 (TID 236). 38615 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Starting task 9.0 in stage 39.0 (TID 239, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:24 INFO  Executor:54 - Running task 9.0 in stage 39.0 (TID 239)
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 6.0 in stage 39.0 (TID 236) in 125 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@306622a2
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@751152cd
2020-05-19 05:25:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 19 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 20 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/20.delta
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:24 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 8.0 in stage 39.0 (TID 238). 35149 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 8.0 in stage 39.0 (TID 238) in 100 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 20 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:24 INFO  Executor:54 - Finished task 9.0 in stage 39.0 (TID 239). 34604 bytes result sent to driver
2020-05-19 05:25:24 INFO  TaskSetManager:54 - Finished task 9.0 in stage 39.0 (TID 239) in 99 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:24 INFO  TaskSchedulerImpl:54 - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2020-05-19 05:25:24 INFO  DAGScheduler:54 - ResultStage 39 (start at NativeMethodAccessorImpl.java:0) finished in 0.767 s
2020-05-19 05:25:24 INFO  DAGScheduler:54 - Job 38 finished: start at NativeMethodAccessorImpl.java:0, took 0.822755 s
2020-05-19 05:25:24 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2b390449 is committing.
-------------------------------------------
Batch: 19
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:24 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2b390449 committed.
2020-05-19 05:25:24 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:24 INFO  DAGScheduler:54 - Job 39 finished: start at NativeMethodAccessorImpl.java:0, took 0.000041 s
2020-05-19 05:25:24 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:23.467Z",
  "batchId" : 19,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3183915622940015,
  "processedRowsPerSecond" : 1.3623978201634879,
  "durationMs" : {
    "addBatch" : 1352,
    "getBatch" : 5,
    "getOffset" : 3,
    "queryPlanning" : 58,
    "triggerExecution" : 1468,
    "walCommit" : 48
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:04:00.000Z",
    "max" : "2018-12-28T17:04:00.000Z",
    "min" : "2018-12-28T17:04:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3229,
        "0" : 3133
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3231,
        "0" : 3133
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3183915622940015,
    "processedRowsPerSecond" : 1.3623978201634879
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:25 INFO  MicroBatchExecution:54 - Committed offsets for batch 20. Metadata OffsetSeqMetadata(1546297020000,1589865924983,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:25 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3231,"0":3133}}), end = {"department.police.service.call":{"1":3232,"0":3133}}
2020-05-19 05:25:25 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:25 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3133,3133,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3231,3232,None)
2020-05-19 05:25:25 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:25 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:25 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_80 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_80_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:25 INFO  BlockManagerInfo:54 - Added broadcast_80_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:25 INFO  SparkContext:54 - Created broadcast 80 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_81 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_81_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:25 INFO  BlockManagerInfo:54 - Added broadcast_81_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:25 INFO  SparkContext:54 - Created broadcast 81 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:25 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25534092. The input RDD has 10 partitions.
2020-05-19 05:25:25 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Registering RDD 306 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Got job 40 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Final stage: ResultStage 41 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 40)
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 40)
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 40 (MapPartitionsRDD[306] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_82 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_82_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:25 INFO  BlockManagerInfo:54 - Added broadcast_82_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:25 INFO  SparkContext:54 - Created broadcast 82 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[306] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:25 INFO  TaskSchedulerImpl:54 - Adding task set 40.0 with 2 tasks
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 40.0 (TID 240, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 1.0 in stage 40.0 (TID 241, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 0.0 in stage 40.0 (TID 240)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 1.0 in stage 40.0 (TID 241)
2020-05-19 05:25:25 INFO  KafkaSourceRDD:54 - Beginning offset 3133 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 1.0 in stage 40.0 (TID 241). 2117 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 1.0 in stage 40.0 (TID 241) in 30 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 0.0 in stage 40.0 (TID 240). 2203 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 40.0 (TID 240) in 39 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2020-05-19 05:25:25 INFO  DAGScheduler:54 - ShuffleMapStage 40 (start at NativeMethodAccessorImpl.java:0) finished in 0.045 s
2020-05-19 05:25:25 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:25 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:25 INFO  DAGScheduler:54 - waiting: Set(ResultStage 41)
2020-05-19 05:25:25 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Submitting ResultStage 41 (MapPartitionsRDD[312] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_83 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:25 INFO  MemoryStore:54 - Block broadcast_83_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:25 INFO  BlockManagerInfo:54 - Added broadcast_83_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:25 INFO  SparkContext:54 - Created broadcast 83 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:25 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 41 (MapPartitionsRDD[312] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:25 INFO  TaskSchedulerImpl:54 - Adding task set 41.0 with 10 tasks
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 41.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 1.0 in stage 41.0 (TID 243, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 1.0 in stage 41.0 (TID 243)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 0.0 in stage 41.0 (TID 242)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c5a17eb
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c8809e5
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76e67aab
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4812ccd4
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/21.delta
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/21.delta
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 1.0 in stage 41.0 (TID 243). 33158 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 2.0 in stage 41.0 (TID 244, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 2.0 in stage 41.0 (TID 244)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 1.0 in stage 41.0 (TID 243) in 145 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75289bfe
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ee00be3
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 0.0 in stage 41.0 (TID 242). 34047 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 3.0 in stage 41.0 (TID 245, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 41.0 (TID 242) in 156 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 3.0 in stage 41.0 (TID 245)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@497e8441
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2326eb3f
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/21.delta
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/21.delta
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 2.0 in stage 41.0 (TID 244). 34820 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 4.0 in stage 41.0 (TID 246, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 4.0 in stage 41.0 (TID 246)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 2.0 in stage 41.0 (TID 244) in 122 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29000122
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@108f3718
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 3.0 in stage 41.0 (TID 245). 35905 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 5.0 in stage 41.0 (TID 247, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 3.0 in stage 41.0 (TID 245) in 168 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 5.0 in stage 41.0 (TID 247)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1620b8e3
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19b746ed
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/21.delta
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 4.0 in stage 41.0 (TID 246). 35829 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 6.0 in stage 41.0 (TID 248, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 6.0 in stage 41.0 (TID 248)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 4.0 in stage 41.0 (TID 246) in 122 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27fdbe30
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f1702fc
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/21.delta
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/21.delta
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:25 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 5.0 in stage 41.0 (TID 247). 37837 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 7.0 in stage 41.0 (TID 249, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 7.0 in stage 41.0 (TID 249)
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Finished task 5.0 in stage 41.0 (TID 247) in 145 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1081419
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@161f7023
2020-05-19 05:25:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:25 INFO  Executor:54 - Finished task 6.0 in stage 41.0 (TID 248). 38615 bytes result sent to driver
2020-05-19 05:25:25 INFO  TaskSetManager:54 - Starting task 8.0 in stage 41.0 (TID 250, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:25 INFO  Executor:54 - Running task 8.0 in stage 41.0 (TID 250)
2020-05-19 05:25:26 INFO  TaskSetManager:54 - Finished task 6.0 in stage 41.0 (TID 248) in 132 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@549f05b9
2020-05-19 05:25:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4090f27e
2020-05-19 05:25:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/21.delta
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/21.delta
2020-05-19 05:25:26 INFO  Executor:54 - Finished task 7.0 in stage 41.0 (TID 249). 36299 bytes result sent to driver
2020-05-19 05:25:26 INFO  TaskSetManager:54 - Starting task 9.0 in stage 41.0 (TID 251, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:26 INFO  Executor:54 - Running task 9.0 in stage 41.0 (TID 251)
2020-05-19 05:25:26 INFO  TaskSetManager:54 - Finished task 7.0 in stage 41.0 (TID 249) in 126 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea775a3
2020-05-19 05:25:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31ba195
2020-05-19 05:25:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 20 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:26 INFO  Executor:54 - Finished task 8.0 in stage 41.0 (TID 250). 35149 bytes result sent to driver
2020-05-19 05:25:26 INFO  TaskSetManager:54 - Finished task 8.0 in stage 41.0 (TID 250) in 125 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 21 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/21.delta
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:26 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 21 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:26 INFO  Executor:54 - Finished task 9.0 in stage 41.0 (TID 251). 34604 bytes result sent to driver
2020-05-19 05:25:26 INFO  TaskSetManager:54 - Finished task 9.0 in stage 41.0 (TID 251) in 147 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2020-05-19 05:25:26 INFO  DAGScheduler:54 - ResultStage 41 (start at NativeMethodAccessorImpl.java:0) finished in 0.749 s
2020-05-19 05:25:26 INFO  DAGScheduler:54 - Job 40 finished: start at NativeMethodAccessorImpl.java:0, took 0.799763 s
2020-05-19 05:25:26 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25534092 is committing.
-------------------------------------------
Batch: 20
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:26 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@25534092 committed.
2020-05-19 05:25:26 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:26 INFO  DAGScheduler:54 - Job 41 finished: start at NativeMethodAccessorImpl.java:0, took 0.000038 s
2020-05-19 05:25:26 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:24.976Z",
  "batchId" : 20,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6626905235255136,
  "processedRowsPerSecond" : 0.6385696040868455,
  "durationMs" : {
    "addBatch" : 1429,
    "getBatch" : 4,
    "getOffset" : 7,
    "queryPlanning" : 55,
    "triggerExecution" : 1566,
    "walCommit" : 70
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:03:00.000Z",
    "max" : "2018-12-28T17:03:00.000Z",
    "min" : "2018-12-28T17:03:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3231,
        "0" : 3133
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3232,
        "0" : 3133
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6626905235255136,
    "processedRowsPerSecond" : 0.6385696040868455
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:26 INFO  MicroBatchExecution:54 - Committed offsets for batch 21. Metadata OffsetSeqMetadata(1546297020000,1589865926651,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:26 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3232,"0":3133}}), end = {"department.police.service.call":{"1":3234,"0":3133}}
2020-05-19 05:25:26 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:26 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3133,3133,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3232,3234,None)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1816
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1853
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_77_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1798
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1807
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1778
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1800
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1859
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1718
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1696
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1840
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1797
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1819
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1765
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1758
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1836
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1728
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1858
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1850
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1808
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1717
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1802
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1775
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1789
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1709
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1861
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1763
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1783
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_82_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1753
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1752
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1867
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1721
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_76_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1839
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1856
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1863
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1865
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1786
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1777
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1787
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1708
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1774
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1745
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1780
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1814
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1818
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1846
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1700
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1811
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1761
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_80_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1801
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1697
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1693
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1732
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1755
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1870
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1748
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1743
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1744
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1770
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1826
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1831
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1698
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1834
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1771
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1869
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1843
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1821
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1730
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1722
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1706
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1794
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1782
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1792
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1720
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1768
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1844
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1790
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1824
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1837
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_81_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1804
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1760
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1872
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1739
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1711
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1754
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1862
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1855
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1849
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1805
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1857
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1779
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1749
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1796
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1822
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1764
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1838
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1740
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1772
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1828
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1756
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1845
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1723
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1704
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1705
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1734
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1738
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1731
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1769
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1825
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1784
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1712
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1773
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1795
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1735
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1741
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1701
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned shuffle 19
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1860
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1815
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1866
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1737
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1820
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1830
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1766
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1833
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1757
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1719
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1810
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1835
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1733
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1699
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1727
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1854
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1713
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1725
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1813
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1776
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1806
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1868
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1841
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1842
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1714
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1702
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1736
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1803
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1762
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1799
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1864
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1707
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1851
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_79_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1695
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1829
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1812
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1751
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1809
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Removed broadcast_83_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1715
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1747
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1793
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1788
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1759
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1729
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1767
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1823
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1827
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1716
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1746
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1785
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1726
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1781
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1832
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1817
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1710
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1703
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1852
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1750
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned shuffle 20
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1742
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1724
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1848
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1847
2020-05-19 05:25:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:27 INFO  ContextCleaner:54 - Cleaned accumulator 1791
2020-05-19 05:25:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_84 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_84_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Added broadcast_84_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  SparkContext:54 - Created broadcast 84 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_85 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_85_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Added broadcast_85_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  SparkContext:54 - Created broadcast 85 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:27 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2a74c32d. The input RDD has 10 partitions.
2020-05-19 05:25:27 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Registering RDD 321 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Got job 42 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Final stage: ResultStage 43 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 42)
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 42)
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 42 (MapPartitionsRDD[321] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_86 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_86_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Added broadcast_86_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  SparkContext:54 - Created broadcast 86 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[321] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:27 INFO  TaskSchedulerImpl:54 - Adding task set 42.0 with 2 tasks
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 42.0 (TID 252, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 1.0 in stage 42.0 (TID 253, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 1.0 in stage 42.0 (TID 253)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 0.0 in stage 42.0 (TID 252)
2020-05-19 05:25:27 INFO  KafkaSourceRDD:54 - Beginning offset 3133 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 1.0 in stage 42.0 (TID 253). 2074 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 1.0 in stage 42.0 (TID 253) in 31 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 0.0 in stage 42.0 (TID 252). 2203 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 42.0 (TID 252) in 37 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2020-05-19 05:25:27 INFO  DAGScheduler:54 - ShuffleMapStage 42 (start at NativeMethodAccessorImpl.java:0) finished in 0.044 s
2020-05-19 05:25:27 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:27 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:27 INFO  DAGScheduler:54 - waiting: Set(ResultStage 43)
2020-05-19 05:25:27 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Submitting ResultStage 43 (MapPartitionsRDD[327] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_87 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:27 INFO  MemoryStore:54 - Block broadcast_87_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:27 INFO  BlockManagerInfo:54 - Added broadcast_87_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:27 INFO  SparkContext:54 - Created broadcast 87 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:27 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 43 (MapPartitionsRDD[327] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:27 INFO  TaskSchedulerImpl:54 - Adding task set 43.0 with 10 tasks
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 43.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 1.0 in stage 43.0 (TID 255, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 1.0 in stage 43.0 (TID 255)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 0.0 in stage 43.0 (TID 254)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ca66cdc
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d8a8125
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12b9ba99
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e4f05a8
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 1.0 in stage 43.0 (TID 255). 33158 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 2.0 in stage 43.0 (TID 256, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 2.0 in stage 43.0 (TID 256)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 1.0 in stage 43.0 (TID 255) in 129 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@542a54c3
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dbaa90c
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 0.0 in stage 43.0 (TID 254). 34047 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 3.0 in stage 43.0 (TID 257, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 3.0 in stage 43.0 (TID 257)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 43.0 (TID 254) in 156 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c52e58
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2901dba5
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 2.0 in stage 43.0 (TID 256). 34820 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 4.0 in stage 43.0 (TID 258, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 4.0 in stage 43.0 (TID 258)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 2.0 in stage 43.0 (TID 256) in 88 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7651808a
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d67a2d8
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 4.0 in stage 43.0 (TID 258). 35829 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 5.0 in stage 43.0 (TID 259, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 5.0 in stage 43.0 (TID 259)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 4.0 in stage 43.0 (TID 258) in 64 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ccc66c0
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2794a98d
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 3.0 in stage 43.0 (TID 257). 35905 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 6.0 in stage 43.0 (TID 260, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 3.0 in stage 43.0 (TID 257) in 147 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 6.0 in stage 43.0 (TID 260)
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aeb2ed5
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24029809
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/22.delta
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/22.delta
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:27 INFO  Executor:54 - Finished task 5.0 in stage 43.0 (TID 259). 37837 bytes result sent to driver
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Starting task 7.0 in stage 43.0 (TID 261, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:27 INFO  Executor:54 - Running task 7.0 in stage 43.0 (TID 261)
2020-05-19 05:25:27 INFO  TaskSetManager:54 - Finished task 5.0 in stage 43.0 (TID 259) in 99 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:27 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@406425af
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b58b3a3
2020-05-19 05:25:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:28 INFO  Executor:54 - Finished task 6.0 in stage 43.0 (TID 260). 38615 bytes result sent to driver
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Starting task 8.0 in stage 43.0 (TID 262, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Finished task 6.0 in stage 43.0 (TID 260) in 121 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:28 INFO  Executor:54 - Running task 8.0 in stage 43.0 (TID 262)
2020-05-19 05:25:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d3bf238
2020-05-19 05:25:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@521340cc
2020-05-19 05:25:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/22.delta
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:28 INFO  Executor:54 - Finished task 7.0 in stage 43.0 (TID 261). 36299 bytes result sent to driver
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Starting task 9.0 in stage 43.0 (TID 263, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Finished task 7.0 in stage 43.0 (TID 261) in 116 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:28 INFO  Executor:54 - Running task 9.0 in stage 43.0 (TID 263)
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/22.delta
2020-05-19 05:25:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55c88a43
2020-05-19 05:25:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f613b49
2020-05-19 05:25:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 21 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:28 INFO  Executor:54 - Finished task 8.0 in stage 43.0 (TID 262). 35149 bytes result sent to driver
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Finished task 8.0 in stage 43.0 (TID 262) in 113 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 22 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/22.delta
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:28 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 22 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:28 INFO  Executor:54 - Finished task 9.0 in stage 43.0 (TID 263). 34604 bytes result sent to driver
2020-05-19 05:25:28 INFO  TaskSetManager:54 - Finished task 9.0 in stage 43.0 (TID 263) in 87 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2020-05-19 05:25:28 INFO  DAGScheduler:54 - ResultStage 43 (start at NativeMethodAccessorImpl.java:0) finished in 0.592 s
2020-05-19 05:25:28 INFO  DAGScheduler:54 - Job 42 finished: start at NativeMethodAccessorImpl.java:0, took 0.653717 s
2020-05-19 05:25:28 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2a74c32d is committing.
-------------------------------------------
Batch: 21
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:28 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2a74c32d committed.
2020-05-19 05:25:28 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:28 INFO  DAGScheduler:54 - Job 43 finished: start at NativeMethodAccessorImpl.java:0, took 0.000041 s
2020-05-19 05:25:28 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:26.646Z",
  "batchId" : 21,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1976047904191618,
  "processedRowsPerSecond" : 1.0683760683760684,
  "durationMs" : {
    "addBatch" : 1586,
    "getBatch" : 16,
    "getOffset" : 5,
    "queryPlanning" : 168,
    "triggerExecution" : 1872,
    "walCommit" : 96
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:02:30.000Z",
    "max" : "2018-12-28T17:03:00.000Z",
    "min" : "2018-12-28T17:02:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3232,
        "0" : 3133
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3133
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1976047904191618,
    "processedRowsPerSecond" : 1.0683760683760684
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:28 INFO  MicroBatchExecution:54 - Committed offsets for batch 22. Metadata OffsetSeqMetadata(1546297020000,1589865928616,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:28 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3234,"0":3133}}), end = {"department.police.service.call":{"1":3234,"0":3135}}
2020-05-19 05:25:28 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:28 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3133,3135,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3234,3234,None)
2020-05-19 05:25:28 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:28 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:28 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:28 INFO  MemoryStore:54 - Block broadcast_88 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_88_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Added broadcast_88_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:29 INFO  SparkContext:54 - Created broadcast 88 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_89 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_89_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Added broadcast_89_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:29 INFO  SparkContext:54 - Created broadcast 89 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:29 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@253c9cc6. The input RDD has 10 partitions.
2020-05-19 05:25:29 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Registering RDD 336 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Got job 44 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Final stage: ResultStage 45 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 44)
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 44)
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 44 (MapPartitionsRDD[336] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_90 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_90_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Added broadcast_90_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:29 INFO  SparkContext:54 - Created broadcast 90 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[336] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:29 INFO  TaskSchedulerImpl:54 - Adding task set 44.0 with 2 tasks
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 44.0 (TID 264, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 44.0 (TID 265, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 1.0 in stage 44.0 (TID 265)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 0.0 in stage 44.0 (TID 264)
2020-05-19 05:25:29 INFO  KafkaSourceRDD:54 - Beginning offset 3234 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1884
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1935
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1945
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Removed broadcast_85_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1921
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1907
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1885
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1951
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1947
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1886
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1931
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1927
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1920
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1906
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1875
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1882
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1899
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Removed broadcast_86_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1939
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1897
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1905
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1874
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1946
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1900
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1917
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1876
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1936
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1888
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1914
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Removed broadcast_87_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1879
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1930
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1892
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1896
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1918
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1938
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1955
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1883
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1873
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1952
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1940
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1958
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1898
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1895
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1937
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1904
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1941
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1942
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1922
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1894
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1880
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1878
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 1.0 in stage 44.0 (TID 265). 2117 bytes result sent to driver
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Removed broadcast_84_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1959
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1871
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1925
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1902
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1919
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1881
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1934
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1889
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1908
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1887
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1916
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1929
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1903
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1943
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1953
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1911
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1923
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1924
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1901
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1928
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1948
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1944
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1912
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1957
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1893
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1956
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1891
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1913
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1915
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1949
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1950
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1932
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1926
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 44.0 (TID 265) in 61 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned shuffle 21
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1961
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1910
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1909
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1890
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1954
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1933
2020-05-19 05:25:29 INFO  ContextCleaner:54 - Cleaned accumulator 1877
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 0.0 in stage 44.0 (TID 264). 2246 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 44.0 (TID 264) in 81 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2020-05-19 05:25:29 INFO  DAGScheduler:54 - ShuffleMapStage 44 (start at NativeMethodAccessorImpl.java:0) finished in 0.093 s
2020-05-19 05:25:29 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:29 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:29 INFO  DAGScheduler:54 - waiting: Set(ResultStage 45)
2020-05-19 05:25:29 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Submitting ResultStage 45 (MapPartitionsRDD[342] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_91 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:29 INFO  MemoryStore:54 - Block broadcast_91_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:29 INFO  BlockManagerInfo:54 - Added broadcast_91_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:29 INFO  SparkContext:54 - Created broadcast 91 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 45 (MapPartitionsRDD[342] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:29 INFO  TaskSchedulerImpl:54 - Adding task set 45.0 with 10 tasks
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 45.0 (TID 266, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 45.0 (TID 267, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 1.0 in stage 45.0 (TID 267)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 0.0 in stage 45.0 (TID 266)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14a30c02
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@699bc6fa
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d9a87ec
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14dbb75c
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 0.0 in stage 45.0 (TID 266). 34047 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 45.0 (TID 268, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 45.0 (TID 266) in 130 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 2.0 in stage 45.0 (TID 268)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33e5d88e
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 1.0 in stage 45.0 (TID 267). 33158 bytes result sent to driver
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@780df0bc
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 3.0 in stage 45.0 (TID 269, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:29 INFO  Executor:54 - Running task 3.0 in stage 45.0 (TID 269)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 45.0 (TID 267) in 143 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2afcc60b
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74648743
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 2.0 in stage 45.0 (TID 268). 34829 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 4.0 in stage 45.0 (TID 270, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 4.0 in stage 45.0 (TID 270)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 45.0 (TID 268) in 98 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12bc2487
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 3.0 in stage 45.0 (TID 269). 35905 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 5.0 in stage 45.0 (TID 271, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 5.0 in stage 45.0 (TID 271)
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6768f838
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 3.0 in stage 45.0 (TID 269) in 116 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72feef75
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@786469c1
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 4.0 in stage 45.0 (TID 270). 35829 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 6.0 in stage 45.0 (TID 272, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 6.0 in stage 45.0 (TID 272)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 4.0 in stage 45.0 (TID 270) in 160 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d7e0b53
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5f1f55
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 5.0 in stage 45.0 (TID 271). 37837 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 7.0 in stage 45.0 (TID 273, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 7.0 in stage 45.0 (TID 273)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 5.0 in stage 45.0 (TID 271) in 156 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d1adfb2
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79b338c8
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/23.delta
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 6.0 in stage 45.0 (TID 272). 38615 bytes result sent to driver
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 7.0 in stage 45.0 (TID 273). 36299 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 8.0 in stage 45.0 (TID 274, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  Executor:54 - Running task 8.0 in stage 45.0 (TID 274)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 6.0 in stage 45.0 (TID 272) in 145 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Starting task 9.0 in stage 45.0 (TID 275, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 7.0 in stage 45.0 (TID 273) in 128 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@217f6e5f
2020-05-19 05:25:29 INFO  Executor:54 - Running task 9.0 in stage 45.0 (TID 275)
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f55c6f7
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cef0a6a
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@228e587
2020-05-19 05:25:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 22 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 23 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/23.delta
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:29 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 8.0 in stage 45.0 (TID 274). 35149 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 8.0 in stage 45.0 (TID 274) in 112 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 23 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:29 INFO  Executor:54 - Finished task 9.0 in stage 45.0 (TID 275). 34604 bytes result sent to driver
2020-05-19 05:25:29 INFO  TaskSetManager:54 - Finished task 9.0 in stage 45.0 (TID 275) in 133 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2020-05-19 05:25:29 INFO  DAGScheduler:54 - ResultStage 45 (start at NativeMethodAccessorImpl.java:0) finished in 0.675 s
2020-05-19 05:25:29 INFO  DAGScheduler:54 - Job 44 finished: start at NativeMethodAccessorImpl.java:0, took 0.780865 s
2020-05-19 05:25:29 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@253c9cc6 is committing.
-------------------------------------------
Batch: 22
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:30 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@253c9cc6 committed.
2020-05-19 05:25:30 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Job 45 finished: start at NativeMethodAccessorImpl.java:0, took 0.000042 s
2020-05-19 05:25:30 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:28.609Z",
  "batchId" : 22,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0188487009679061,
  "processedRowsPerSecond" : 1.2135922330097089,
  "durationMs" : {
    "addBatch" : 1420,
    "getBatch" : 5,
    "getOffset" : 7,
    "queryPlanning" : 120,
    "triggerExecution" : 1648,
    "walCommit" : 96
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:02:00.000Z",
    "max" : "2018-12-28T17:02:00.000Z",
    "min" : "2018-12-28T17:02:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3133
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3135
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0188487009679061,
    "processedRowsPerSecond" : 1.2135922330097089
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:30 INFO  MicroBatchExecution:54 - Committed offsets for batch 23. Metadata OffsetSeqMetadata(1546297020000,1589865930382,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:30 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3234,"0":3135}}), end = {"department.police.service.call":{"1":3234,"0":3137}}
2020-05-19 05:25:30 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:30 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3135,3137,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3234,3234,None)
2020-05-19 05:25:30 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:30 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:30 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_92 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_92_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:30 INFO  BlockManagerInfo:54 - Added broadcast_92_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:30 INFO  SparkContext:54 - Created broadcast 92 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_93 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_93_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:30 INFO  BlockManagerInfo:54 - Added broadcast_93_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:30 INFO  SparkContext:54 - Created broadcast 93 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:30 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@ff05ff2. The input RDD has 10 partitions.
2020-05-19 05:25:30 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Registering RDD 351 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Got job 46 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Final stage: ResultStage 47 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 46)
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 46)
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 46 (MapPartitionsRDD[351] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_94 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_94_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:30 INFO  BlockManagerInfo:54 - Added broadcast_94_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:30 INFO  SparkContext:54 - Created broadcast 94 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[351] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:30 INFO  TaskSchedulerImpl:54 - Adding task set 46.0 with 2 tasks
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 46.0 (TID 276, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 46.0 (TID 277, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:30 INFO  Executor:54 - Running task 0.0 in stage 46.0 (TID 276)
2020-05-19 05:25:30 INFO  Executor:54 - Running task 1.0 in stage 46.0 (TID 277)
2020-05-19 05:25:30 INFO  KafkaSourceRDD:54 - Beginning offset 3234 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:30 INFO  Executor:54 - Finished task 1.0 in stage 46.0 (TID 277). 2074 bytes result sent to driver
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Finished task 1.0 in stage 46.0 (TID 277) in 27 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:30 INFO  Executor:54 - Finished task 0.0 in stage 46.0 (TID 276). 2203 bytes result sent to driver
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 46.0 (TID 276) in 32 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2020-05-19 05:25:30 INFO  DAGScheduler:54 - ShuffleMapStage 46 (start at NativeMethodAccessorImpl.java:0) finished in 0.042 s
2020-05-19 05:25:30 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:30 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:30 INFO  DAGScheduler:54 - waiting: Set(ResultStage 47)
2020-05-19 05:25:30 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Submitting ResultStage 47 (MapPartitionsRDD[357] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_95 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:30 INFO  MemoryStore:54 - Block broadcast_95_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:30 INFO  BlockManagerInfo:54 - Added broadcast_95_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:30 INFO  SparkContext:54 - Created broadcast 95 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:30 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 47 (MapPartitionsRDD[357] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:30 INFO  TaskSchedulerImpl:54 - Adding task set 47.0 with 10 tasks
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 47.0 (TID 278, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 47.0 (TID 279, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:30 INFO  Executor:54 - Running task 1.0 in stage 47.0 (TID 279)
2020-05-19 05:25:30 INFO  Executor:54 - Running task 0.0 in stage 47.0 (TID 278)
2020-05-19 05:25:30 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:30 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:30 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@197f1feb
2020-05-19 05:25:30 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:30 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:30 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:30 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@182aead5
2020-05-19 05:25:30 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:30 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:30 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:30 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:30 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:30 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@556d07a0
2020-05-19 05:25:30 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:30 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:30 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:30 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b25e1e5
2020-05-19 05:25:30 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:30 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:30 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/24.delta
2020-05-19 05:25:30 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:30 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:30 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/24.delta
2020-05-19 05:25:30 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:30 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 0.0 in stage 47.0 (TID 278). 34047 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 2.0 in stage 47.0 (TID 280, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 2.0 in stage 47.0 (TID 280)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 47.0 (TID 278) in 125 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24fd1bf5
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e03ad2
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 1.0 in stage 47.0 (TID 279). 33158 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 3.0 in stage 47.0 (TID 281, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 1.0 in stage 47.0 (TID 279) in 143 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 3.0 in stage 47.0 (TID 281)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b771cc
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78a083da
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 2.0 in stage 47.0 (TID 280). 34820 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 4.0 in stage 47.0 (TID 282, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 4.0 in stage 47.0 (TID 282)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 2.0 in stage 47.0 (TID 280) in 120 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4757a1ca
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45822450
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 3.0 in stage 47.0 (TID 281). 35905 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 5.0 in stage 47.0 (TID 283, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 5.0 in stage 47.0 (TID 283)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 3.0 in stage 47.0 (TID 281) in 143 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ddf417e
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d7200b7
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 4.0 in stage 47.0 (TID 282). 35829 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 6.0 in stage 47.0 (TID 284, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 4.0 in stage 47.0 (TID 282) in 131 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 6.0 in stage 47.0 (TID 284)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32836c8e
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60f03c2d
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 5.0 in stage 47.0 (TID 283). 37837 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 7.0 in stage 47.0 (TID 285, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 7.0 in stage 47.0 (TID 285)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 5.0 in stage 47.0 (TID 283) in 190 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34c844f3
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1630bae9
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 6.0 in stage 47.0 (TID 284). 38615 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 8.0 in stage 47.0 (TID 286, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 6.0 in stage 47.0 (TID 284) in 153 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 8.0 in stage 47.0 (TID 286)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62a8c0da
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d2fbe0
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/24.delta
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1981
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1969
2020-05-19 05:25:31 INFO  BlockManagerInfo:54 - Removed broadcast_94_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1970
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2010
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1999
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1998
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2032
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2024
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2006
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2000
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1979
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2028
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2016
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1983
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1996
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1965
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2047
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1963
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2043
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1997
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2033
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1995
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1977
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2039
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2027
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2011
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1987
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned shuffle 22
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1986
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2026
2020-05-19 05:25:31 INFO  BlockManagerInfo:54 - Removed broadcast_89_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1978
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1990
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2020
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2023
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2001
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1960
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2021
2020-05-19 05:25:31 INFO  BlockManagerInfo:54 - Removed broadcast_88_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2005
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1966
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2009
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1994
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1962
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1985
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2046
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1980
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2040
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2030
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1973
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1993
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2035
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2004
2020-05-19 05:25:31 INFO  BlockManagerInfo:54 - Removed broadcast_91_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2041
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1989
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2037
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2031
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2008
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2045
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2003
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1975
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2044
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1984
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1974
2020-05-19 05:25:31 INFO  BlockManagerInfo:54 - Removed broadcast_90_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1976
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1988
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2038
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2034
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2042
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2050
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1972
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2018
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2019
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1971
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2007
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1964
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2013
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1968
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2014
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1991
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2036
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2048
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2017
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1992
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2012
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2025
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1982
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2002
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 1967
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2015
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2022
2020-05-19 05:25:31 INFO  ContextCleaner:54 - Cleaned accumulator 2029
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/24.delta
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 7.0 in stage 47.0 (TID 285). 36342 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Starting task 9.0 in stage 47.0 (TID 287, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 7.0 in stage 47.0 (TID 285) in 190 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:31 INFO  Executor:54 - Running task 9.0 in stage 47.0 (TID 287)
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@769b0cdd
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:31 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:31 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:31 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42c1576d
2020-05-19 05:25:31 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 23 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Committed version 24 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/24.delta
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 8.0 in stage 47.0 (TID 286). 35192 bytes result sent to driver
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:31 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 8.0 in stage 47.0 (TID 286) in 230 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:31 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 24 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:31 INFO  Executor:54 - Finished task 9.0 in stage 47.0 (TID 287). 34595 bytes result sent to driver
2020-05-19 05:25:31 INFO  TaskSetManager:54 - Finished task 9.0 in stage 47.0 (TID 287) in 142 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:31 INFO  TaskSchedulerImpl:54 - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2020-05-19 05:25:31 INFO  DAGScheduler:54 - ResultStage 47 (start at NativeMethodAccessorImpl.java:0) finished in 0.806 s
2020-05-19 05:25:31 INFO  DAGScheduler:54 - Job 46 finished: start at NativeMethodAccessorImpl.java:0, took 0.855070 s
2020-05-19 05:25:31 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@ff05ff2 is committing.
-------------------------------------------
Batch: 23
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:31 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@ff05ff2 committed.
2020-05-19 05:25:31 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:31 INFO  DAGScheduler:54 - Job 47 finished: start at NativeMethodAccessorImpl.java:0, took 0.000039 s
2020-05-19 05:25:31 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:30.377Z",
  "batchId" : 23,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1312217194570136,
  "processedRowsPerSecond" : 1.2562814070351758,
  "durationMs" : {
    "addBatch" : 1417,
    "getBatch" : 5,
    "getOffset" : 5,
    "queryPlanning" : 78,
    "triggerExecution" : 1592,
    "walCommit" : 86
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:01:00.000Z",
    "max" : "2018-12-28T17:01:00.000Z",
    "min" : "2018-12-28T17:01:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3135
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3137
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1312217194570136,
    "processedRowsPerSecond" : 1.2562814070351758
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:32 INFO  MicroBatchExecution:54 - Committed offsets for batch 24. Metadata OffsetSeqMetadata(1546297020000,1589865932069,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:32 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3234,"0":3137}}), end = {"department.police.service.call":{"1":3234,"0":3138}}
2020-05-19 05:25:32 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:32 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3137,3138,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3234,3234,None)
2020-05-19 05:25:32 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:32 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:32 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_96 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_96_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:32 INFO  BlockManagerInfo:54 - Added broadcast_96_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:32 INFO  SparkContext:54 - Created broadcast 96 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_97 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_97_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:32 INFO  BlockManagerInfo:54 - Added broadcast_97_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:32 INFO  SparkContext:54 - Created broadcast 97 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:32 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@296ad0d4. The input RDD has 10 partitions.
2020-05-19 05:25:32 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Registering RDD 366 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Got job 48 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Final stage: ResultStage 49 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 48)
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 48)
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 48 (MapPartitionsRDD[366] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_98 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_98_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:32 INFO  BlockManagerInfo:54 - Added broadcast_98_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:32 INFO  SparkContext:54 - Created broadcast 98 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[366] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:32 INFO  TaskSchedulerImpl:54 - Adding task set 48.0 with 2 tasks
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 48.0 (TID 288, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 1.0 in stage 48.0 (TID 289, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 0.0 in stage 48.0 (TID 288)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 1.0 in stage 48.0 (TID 289)
2020-05-19 05:25:32 INFO  KafkaSourceRDD:54 - Beginning offset 3234 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 0.0 in stage 48.0 (TID 288). 2203 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 48.0 (TID 288) in 14 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 1.0 in stage 48.0 (TID 289). 2074 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 1.0 in stage 48.0 (TID 289) in 18 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:32 INFO  TaskSchedulerImpl:54 - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2020-05-19 05:25:32 INFO  DAGScheduler:54 - ShuffleMapStage 48 (start at NativeMethodAccessorImpl.java:0) finished in 0.032 s
2020-05-19 05:25:32 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:32 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 49)
2020-05-19 05:25:32 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Submitting ResultStage 49 (MapPartitionsRDD[372] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_99 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:32 INFO  MemoryStore:54 - Block broadcast_99_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:32 INFO  BlockManagerInfo:54 - Added broadcast_99_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:32 INFO  SparkContext:54 - Created broadcast 99 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:32 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 49 (MapPartitionsRDD[372] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:32 INFO  TaskSchedulerImpl:54 - Adding task set 49.0 with 10 tasks
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 49.0 (TID 290, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 1.0 in stage 49.0 (TID 291, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 0.0 in stage 49.0 (TID 290)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 1.0 in stage 49.0 (TID 291)
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65aea408
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35be8282
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9358d69
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3385ad7a
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/25.delta
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/25.delta
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 0.0 in stage 49.0 (TID 290). 34047 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 2.0 in stage 49.0 (TID 292, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 1.0 in stage 49.0 (TID 291). 33158 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 49.0 (TID 290) in 90 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 2.0 in stage 49.0 (TID 292)
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25db95cb
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c843b88
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 3.0 in stage 49.0 (TID 293, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 3.0 in stage 49.0 (TID 293)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 1.0 in stage 49.0 (TID 291) in 99 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a2effc1
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc4f762
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/25.delta
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/25.delta
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 2.0 in stage 49.0 (TID 292). 34820 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 4.0 in stage 49.0 (TID 294, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 3.0 in stage 49.0 (TID 293). 35905 bytes result sent to driver
2020-05-19 05:25:32 INFO  Executor:54 - Running task 4.0 in stage 49.0 (TID 294)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 2.0 in stage 49.0 (TID 292) in 129 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 5.0 in stage 49.0 (TID 295, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 5.0 in stage 49.0 (TID 295)
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@907fec4
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14712580
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74b5d75c
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b089626
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 3.0 in stage 49.0 (TID 293) in 134 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/25.delta
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/25.delta
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:32 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 5.0 in stage 49.0 (TID 295). 37837 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 6.0 in stage 49.0 (TID 296, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 5.0 in stage 49.0 (TID 295) in 114 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 6.0 in stage 49.0 (TID 296)
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c4d6b08
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c7edc04
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:32 INFO  Executor:54 - Finished task 4.0 in stage 49.0 (TID 294). 35829 bytes result sent to driver
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Starting task 7.0 in stage 49.0 (TID 297, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:32 INFO  TaskSetManager:54 - Finished task 4.0 in stage 49.0 (TID 294) in 162 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:32 INFO  Executor:54 - Running task 7.0 in stage 49.0 (TID 297)
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f097d88
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:32 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:32 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:32 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10b338d1
2020-05-19 05:25:32 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:32 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/25.delta
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/25.delta
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:33 INFO  Executor:54 - Finished task 6.0 in stage 49.0 (TID 296). 38615 bytes result sent to driver
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Starting task 8.0 in stage 49.0 (TID 298, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:33 INFO  Executor:54 - Running task 8.0 in stage 49.0 (TID 298)
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Finished task 6.0 in stage 49.0 (TID 296) in 132 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:33 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:33 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:33 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@232d876
2020-05-19 05:25:33 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:33 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:33 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:33 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3514495b
2020-05-19 05:25:33 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:33 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:33 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:33 INFO  Executor:54 - Finished task 7.0 in stage 49.0 (TID 297). 36299 bytes result sent to driver
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Starting task 9.0 in stage 49.0 (TID 299, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:33 INFO  Executor:54 - Running task 9.0 in stage 49.0 (TID 299)
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Finished task 7.0 in stage 49.0 (TID 297) in 141 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:33 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:33 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:33 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69b678d0
2020-05-19 05:25:33 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:33 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:33 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:33 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b433719
2020-05-19 05:25:33 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 24 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:33 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:33 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/25.delta
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Committed version 25 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/25.delta
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:33 INFO  Executor:54 - Finished task 8.0 in stage 49.0 (TID 298). 35149 bytes result sent to driver
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Finished task 8.0 in stage 49.0 (TID 298) in 160 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:33 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:33 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 25 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:33 INFO  Executor:54 - Finished task 9.0 in stage 49.0 (TID 299). 34595 bytes result sent to driver
2020-05-19 05:25:33 INFO  TaskSetManager:54 - Finished task 9.0 in stage 49.0 (TID 299) in 165 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2020-05-19 05:25:33 INFO  DAGScheduler:54 - ResultStage 49 (start at NativeMethodAccessorImpl.java:0) finished in 0.688 s
2020-05-19 05:25:33 INFO  DAGScheduler:54 - Job 48 finished: start at NativeMethodAccessorImpl.java:0, took 0.727537 s
2020-05-19 05:25:33 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@296ad0d4 is committing.
-------------------------------------------
Batch: 24
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:33 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@296ad0d4 committed.
2020-05-19 05:25:33 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:33 INFO  DAGScheduler:54 - Job 49 finished: start at NativeMethodAccessorImpl.java:0, took 0.000039 s
2020-05-19 05:25:33 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:32.066Z",
  "batchId" : 24,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.5920663114268798,
  "processedRowsPerSecond" : 0.7052186177715092,
  "durationMs" : {
    "addBatch" : 1230,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 82,
    "triggerExecution" : 1418,
    "walCommit" : 98
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:00:00.000Z",
    "max" : "2018-12-28T17:00:00.000Z",
    "min" : "2018-12-28T17:00:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2815,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3137
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3138
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.5920663114268798,
    "processedRowsPerSecond" : 0.7052186177715092
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:33 INFO  MicroBatchExecution:54 - Committed offsets for batch 25. Metadata OffsetSeqMetadata(1546297020000,1589865933558,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:33 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3234,"0":3138}}), end = {"department.police.service.call":{"1":3236,"0":3138}}
2020-05-19 05:25:33 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:33 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3138,3138,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3234,3236,None)
2020-05-19 05:25:33 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:33 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:33 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2191
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2175
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2051
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2181
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2154
2020-05-19 05:25:33 INFO  MemoryStore:54 - Block broadcast_100 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2204
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2085
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2138
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2082
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2228
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2185
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_96_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2142
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2218
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2223
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2146
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2084
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2168
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2092
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2143
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2190
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2078
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2127
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2056
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2114
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned shuffle 24
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2140
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_95_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2057
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2149
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2161
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2060
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2207
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2049
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2063
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2118
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2121
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2167
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_98_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2108
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2189
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2136
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2217
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2178
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2165
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2170
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2171
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2216
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2174
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2209
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2169
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2116
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2186
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2224
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2065
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2153
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2176
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2077
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2133
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2087
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2141
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2157
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2066
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2119
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2152
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2062
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2126
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2213
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2070
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2113
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2067
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2091
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2135
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2225
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2180
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2110
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2212
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2072
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2179
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2129
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2055
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2163
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2083
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2215
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2220
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2088
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2158
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2219
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2112
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2054
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2202
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2194
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_99_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2061
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2089
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2102
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2162
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2073
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2074
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2155
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2111
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2103
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2193
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2200
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2128
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2094
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2182
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2097
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2139
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2150
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2159
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2205
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2183
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2221
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2058
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2196
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_97_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2177
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2090
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2148
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2192
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2145
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2130
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2098
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2131
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2076
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2105
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2208
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2173
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2079
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2086
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2144
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2068
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2117
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2151
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2109
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2100
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2124
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2195
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2184
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2172
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2188
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2147
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2206
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2099
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2122
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2095
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2214
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2106
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2226
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2053
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2199
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2203
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2052
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2069
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2132
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2222
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2071
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2120
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2123
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2134
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2101
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2093
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2201
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned shuffle 23
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2164
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2166
2020-05-19 05:25:33 INFO  MemoryStore:54 - Block broadcast_100_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.8 MB)
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Added broadcast_100_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_92_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2160
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2211
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2064
2020-05-19 05:25:33 INFO  BlockManagerInfo:54 - Removed broadcast_93_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2107
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2137
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2115
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2081
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2080
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2156
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2198
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2210
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2104
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2075
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2059
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2125
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2197
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2096
2020-05-19 05:25:33 INFO  SparkContext:54 - Created broadcast 100 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:33 INFO  ContextCleaner:54 - Cleaned accumulator 2187
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_101 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_101_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:34 INFO  BlockManagerInfo:54 - Added broadcast_101_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:34 INFO  SparkContext:54 - Created broadcast 101 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:34 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71c8fe69. The input RDD has 10 partitions.
2020-05-19 05:25:34 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Registering RDD 381 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Got job 50 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Final stage: ResultStage 51 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 50)
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 50)
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 50 (MapPartitionsRDD[381] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_102 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_102_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:34 INFO  BlockManagerInfo:54 - Added broadcast_102_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:34 INFO  SparkContext:54 - Created broadcast 102 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[381] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:34 INFO  TaskSchedulerImpl:54 - Adding task set 50.0 with 2 tasks
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 50.0 (TID 300, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 1.0 in stage 50.0 (TID 301, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 1.0 in stage 50.0 (TID 301)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 0.0 in stage 50.0 (TID 300)
2020-05-19 05:25:34 INFO  KafkaSourceRDD:54 - Beginning offset 3138 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 1.0 in stage 50.0 (TID 301). 2074 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 1.0 in stage 50.0 (TID 301) in 12 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 0.0 in stage 50.0 (TID 300). 2203 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 50.0 (TID 300) in 22 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:34 INFO  TaskSchedulerImpl:54 - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2020-05-19 05:25:34 INFO  DAGScheduler:54 - ShuffleMapStage 50 (start at NativeMethodAccessorImpl.java:0) finished in 0.029 s
2020-05-19 05:25:34 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:34 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:34 INFO  DAGScheduler:54 - waiting: Set(ResultStage 51)
2020-05-19 05:25:34 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Submitting ResultStage 51 (MapPartitionsRDD[387] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_103 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:34 INFO  MemoryStore:54 - Block broadcast_103_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:34 INFO  BlockManagerInfo:54 - Added broadcast_103_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:34 INFO  SparkContext:54 - Created broadcast 103 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 51 (MapPartitionsRDD[387] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:34 INFO  TaskSchedulerImpl:54 - Adding task set 51.0 with 10 tasks
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 51.0 (TID 302, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 1.0 in stage 51.0 (TID 303, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 1.0 in stage 51.0 (TID 303)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 0.0 in stage 51.0 (TID 302)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51d76c6f
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4380e646
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67c55c66
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6111dd27
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/26.delta
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 1.0 in stage 51.0 (TID 303). 33158 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 2.0 in stage 51.0 (TID 304, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 2.0 in stage 51.0 (TID 304)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 1.0 in stage 51.0 (TID 303) in 152 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3040510c
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@526bf44
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 0.0 in stage 51.0 (TID 302). 34047 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 3.0 in stage 51.0 (TID 305, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 3.0 in stage 51.0 (TID 305)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 51.0 (TID 302) in 169 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19455420
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b961132
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/26.delta
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 2.0 in stage 51.0 (TID 304). 34820 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 4.0 in stage 51.0 (TID 306, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 4.0 in stage 51.0 (TID 306)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 2.0 in stage 51.0 (TID 304) in 127 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7321a360
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a40581b
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 3.0 in stage 51.0 (TID 305). 36009 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 5.0 in stage 51.0 (TID 307, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 3.0 in stage 51.0 (TID 305) in 129 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 5.0 in stage 51.0 (TID 307)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e44d83
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e2114c4
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 4.0 in stage 51.0 (TID 306). 35829 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 6.0 in stage 51.0 (TID 308, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 6.0 in stage 51.0 (TID 308)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 4.0 in stage 51.0 (TID 306) in 129 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b319b2c
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dbab724
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 5.0 in stage 51.0 (TID 307). 37837 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 7.0 in stage 51.0 (TID 309, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 7.0 in stage 51.0 (TID 309)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 5.0 in stage 51.0 (TID 307) in 147 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/26.delta
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d330c
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16bcc3bb
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 6.0 in stage 51.0 (TID 308). 38615 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 8.0 in stage 51.0 (TID 310, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 6.0 in stage 51.0 (TID 308) in 127 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 8.0 in stage 51.0 (TID 310)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68c29d2
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d1c67b9
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/26.delta
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 7.0 in stage 51.0 (TID 309). 36299 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Starting task 9.0 in stage 51.0 (TID 311, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:34 INFO  Executor:54 - Running task 9.0 in stage 51.0 (TID 311)
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 7.0 in stage 51.0 (TID 309) in 184 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d83d74e
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:34 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:34 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:34 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b826cc8
2020-05-19 05:25:34 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 25 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Committed version 26 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/26.delta
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 8.0 in stage 51.0 (TID 310). 35149 bytes result sent to driver
2020-05-19 05:25:34 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 8.0 in stage 51.0 (TID 310) in 190 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:34 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 26 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:34 INFO  Executor:54 - Finished task 9.0 in stage 51.0 (TID 311). 34595 bytes result sent to driver
2020-05-19 05:25:34 INFO  TaskSetManager:54 - Finished task 9.0 in stage 51.0 (TID 311) in 124 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:34 INFO  TaskSchedulerImpl:54 - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2020-05-19 05:25:34 INFO  DAGScheduler:54 - ResultStage 51 (start at NativeMethodAccessorImpl.java:0) finished in 0.755 s
2020-05-19 05:25:34 INFO  DAGScheduler:54 - Job 50 finished: start at NativeMethodAccessorImpl.java:0, took 0.796451 s
2020-05-19 05:25:34 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71c8fe69 is committing.
-------------------------------------------
Batch: 25
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:35 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71c8fe69 committed.
2020-05-19 05:25:35 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Job 51 finished: start at NativeMethodAccessorImpl.java:0, took 0.000038 s
2020-05-19 05:25:35 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:33.555Z",
  "batchId" : 25,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3431833445265278,
  "processedRowsPerSecond" : 1.2594458438287153,
  "durationMs" : {
    "addBatch" : 1339,
    "getBatch" : 8,
    "getOffset" : 3,
    "queryPlanning" : 124,
    "triggerExecution" : 1588,
    "walCommit" : 108
  },
  "eventTime" : {
    "avg" : "2018-12-28T17:00:00.000Z",
    "max" : "2018-12-28T17:00:00.000Z",
    "min" : "2018-12-28T17:00:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2816,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3234,
        "0" : 3138
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3236,
        "0" : 3138
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3431833445265278,
    "processedRowsPerSecond" : 1.2594458438287153
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:35 INFO  MicroBatchExecution:54 - Committed offsets for batch 26. Metadata OffsetSeqMetadata(1546297020000,1589865935242,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:35 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3236,"0":3138}}), end = {"department.police.service.call":{"1":3236,"0":3139}}
2020-05-19 05:25:35 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:35 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3138,3139,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3236,3236,None)
2020-05-19 05:25:35 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:35 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:35 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_104 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_104_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:35 INFO  BlockManagerInfo:54 - Added broadcast_104_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:35 INFO  SparkContext:54 - Created broadcast 104 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_105 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_105_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:35 INFO  BlockManagerInfo:54 - Added broadcast_105_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:35 INFO  SparkContext:54 - Created broadcast 105 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:35 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@45e8b112. The input RDD has 10 partitions.
2020-05-19 05:25:35 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Registering RDD 396 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Got job 52 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Final stage: ResultStage 53 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 52)
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 52)
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 52 (MapPartitionsRDD[396] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_106 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_106_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:35 INFO  BlockManagerInfo:54 - Added broadcast_106_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:35 INFO  SparkContext:54 - Created broadcast 106 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[396] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:35 INFO  TaskSchedulerImpl:54 - Adding task set 52.0 with 2 tasks
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 52.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Starting task 1.0 in stage 52.0 (TID 313, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:35 INFO  Executor:54 - Running task 1.0 in stage 52.0 (TID 313)
2020-05-19 05:25:35 INFO  Executor:54 - Running task 0.0 in stage 52.0 (TID 312)
2020-05-19 05:25:35 INFO  KafkaSourceRDD:54 - Beginning offset 3236 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:35 INFO  Executor:54 - Finished task 0.0 in stage 52.0 (TID 312). 2117 bytes result sent to driver
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 52.0 (TID 312) in 29 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:35 INFO  Executor:54 - Finished task 1.0 in stage 52.0 (TID 313). 2203 bytes result sent to driver
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Finished task 1.0 in stage 52.0 (TID 313) in 32 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:35 INFO  TaskSchedulerImpl:54 - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2020-05-19 05:25:35 INFO  DAGScheduler:54 - ShuffleMapStage 52 (start at NativeMethodAccessorImpl.java:0) finished in 0.038 s
2020-05-19 05:25:35 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:35 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:35 INFO  DAGScheduler:54 - waiting: Set(ResultStage 53)
2020-05-19 05:25:35 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Submitting ResultStage 53 (MapPartitionsRDD[402] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_107 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:35 INFO  MemoryStore:54 - Block broadcast_107_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:35 INFO  BlockManagerInfo:54 - Added broadcast_107_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:35 INFO  SparkContext:54 - Created broadcast 107 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:35 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 53 (MapPartitionsRDD[402] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:35 INFO  TaskSchedulerImpl:54 - Adding task set 53.0 with 10 tasks
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 53.0 (TID 314, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:35 INFO  TaskSetManager:54 - Starting task 1.0 in stage 53.0 (TID 315, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:35 INFO  Executor:54 - Running task 1.0 in stage 53.0 (TID 315)
2020-05-19 05:25:35 INFO  Executor:54 - Running task 0.0 in stage 53.0 (TID 314)
2020-05-19 05:25:35 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:35 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:35 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@392a5220
2020-05-19 05:25:35 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:35 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:35 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:35 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38256871
2020-05-19 05:25:35 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:35 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:35 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:35 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:35 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:35 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53450d53
2020-05-19 05:25:35 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:35 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:35 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:35 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7962b83c
2020-05-19 05:25:35 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:35 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:35 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/27.delta
2020-05-19 05:25:35 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:35 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/27.delta
2020-05-19 05:25:35 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:35 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:35 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 0.0 in stage 53.0 (TID 314). 34047 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 2.0 in stage 53.0 (TID 316, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 53.0 (TID 314) in 136 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 2.0 in stage 53.0 (TID 316)
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 1.0 in stage 53.0 (TID 315). 33158 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 3.0 in stage 53.0 (TID 317, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 3.0 in stage 53.0 (TID 317)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655b3107
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 53.0 (TID 315) in 147 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@133442d3
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@696e028c
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46dfc152
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:36 INFO  BlockManagerInfo:54 - Removed broadcast_100_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2232
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2274
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2237
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2293
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2262
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2277
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2269
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2234
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2239
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2280
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2311
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2243
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2286
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2303
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2233
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2292
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2260
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2279
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2314
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2261
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2298
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2291
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2242
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2285
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2272
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2302
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2247
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2287
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2301
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2310
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2238
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2263
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2268
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2256
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2236
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2259
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2275
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2295
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2248
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2270
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2265
2020-05-19 05:25:36 INFO  BlockManagerInfo:54 - Removed broadcast_101_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2307
2020-05-19 05:25:36 INFO  BlockManagerInfo:54 - Removed broadcast_106_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2304
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2254
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2288
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned shuffle 25
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2240
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2317
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2283
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2313
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2255
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2308
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2241
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2230
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2294
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2305
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2267
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2251
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2276
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2278
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2300
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2271
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2306
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2299
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2244
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2312
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2257
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2315
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2266
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2289
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2246
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2227
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2290
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2297
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2252
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2282
2020-05-19 05:25:36 INFO  BlockManagerInfo:54 - Removed broadcast_102_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2250
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2253
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2258
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2309
2020-05-19 05:25:36 INFO  BlockManagerInfo:54 - Removed broadcast_103_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2249
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2229
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2235
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2281
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2231
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2264
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2284
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2245
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2296
2020-05-19 05:25:36 INFO  ContextCleaner:54 - Cleaned accumulator 2273
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 2.0 in stage 53.0 (TID 316). 34958 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 4.0 in stage 53.0 (TID 318, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 2.0 in stage 53.0 (TID 316) in 199 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 4.0 in stage 53.0 (TID 318)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@345410bd
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b87f92e
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 3.0 in stage 53.0 (TID 317). 36052 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 5.0 in stage 53.0 (TID 319, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 3.0 in stage 53.0 (TID 317) in 214 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 5.0 in stage 53.0 (TID 319)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55197167
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b2df296
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 4.0 in stage 53.0 (TID 318). 35829 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 6.0 in stage 53.0 (TID 320, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 6.0 in stage 53.0 (TID 320)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 4.0 in stage 53.0 (TID 318) in 91 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b760fca
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47cec99c
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 5.0 in stage 53.0 (TID 319). 37837 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 7.0 in stage 53.0 (TID 321, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 5.0 in stage 53.0 (TID 319) in 118 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 7.0 in stage 53.0 (TID 321)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dc6ae73
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44072162
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 6.0 in stage 53.0 (TID 320). 38615 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 8.0 in stage 53.0 (TID 322, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 8.0 in stage 53.0 (TID 322)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 6.0 in stage 53.0 (TID 320) in 136 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ac8b80
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b3b7504
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 7.0 in stage 53.0 (TID 321). 36299 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Starting task 9.0 in stage 53.0 (TID 323, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:36 INFO  Executor:54 - Running task 9.0 in stage 53.0 (TID 323)
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 7.0 in stage 53.0 (TID 321) in 146 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@445b54c7
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:36 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:36 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/27.delta
2020-05-19 05:25:36 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6004c750
2020-05-19 05:25:36 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 26 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 8.0 in stage 53.0 (TID 322). 35149 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 8.0 in stage 53.0 (TID 322) in 82 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Committed version 27 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/27.delta
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:36 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:36 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 27 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:36 INFO  Executor:54 - Finished task 9.0 in stage 53.0 (TID 323). 34595 bytes result sent to driver
2020-05-19 05:25:36 INFO  TaskSetManager:54 - Finished task 9.0 in stage 53.0 (TID 323) in 106 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2020-05-19 05:25:36 INFO  DAGScheduler:54 - ResultStage 53 (start at NativeMethodAccessorImpl.java:0) finished in 0.725 s
2020-05-19 05:25:36 INFO  DAGScheduler:54 - Job 52 finished: start at NativeMethodAccessorImpl.java:0, took 0.770916 s
2020-05-19 05:25:36 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@45e8b112 is committing.
-------------------------------------------
Batch: 26
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:36 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@45e8b112 committed.
2020-05-19 05:25:36 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:36 INFO  DAGScheduler:54 - Job 53 finished: start at NativeMethodAccessorImpl.java:0, took 0.000042 s
2020-05-19 05:25:36 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:35.239Z",
  "batchId" : 26,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.5938242280285035,
  "processedRowsPerSecond" : 0.6191950464396285,
  "durationMs" : {
    "addBatch" : 1370,
    "getBatch" : 6,
    "getOffset" : 2,
    "queryPlanning" : 133,
    "triggerExecution" : 1615,
    "walCommit" : 103
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:59:00.000Z",
    "max" : "2018-12-28T16:59:00.000Z",
    "min" : "2018-12-28T16:59:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2817,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3236,
        "0" : 3138
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3236,
        "0" : 3139
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.5938242280285035,
    "processedRowsPerSecond" : 0.6191950464396285
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:37 INFO  MicroBatchExecution:54 - Committed offsets for batch 27. Metadata OffsetSeqMetadata(1546297020000,1589865936981,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:37 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3236,"0":3139}}), end = {"department.police.service.call":{"1":3237,"0":3140}}
2020-05-19 05:25:37 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:37 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3139,3140,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3236,3237,None)
2020-05-19 05:25:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:37 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_108 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_108_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:37 INFO  BlockManagerInfo:54 - Added broadcast_108_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:37 INFO  SparkContext:54 - Created broadcast 108 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_109 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_109_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:37 INFO  BlockManagerInfo:54 - Added broadcast_109_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:37 INFO  SparkContext:54 - Created broadcast 109 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:37 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3997d19b. The input RDD has 10 partitions.
2020-05-19 05:25:37 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Registering RDD 411 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Got job 54 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Final stage: ResultStage 55 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 54)
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 54)
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 54 (MapPartitionsRDD[411] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_110 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_110_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:37 INFO  BlockManagerInfo:54 - Added broadcast_110_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:37 INFO  SparkContext:54 - Created broadcast 110 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[411] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:37 INFO  TaskSchedulerImpl:54 - Adding task set 54.0 with 2 tasks
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 54.0 (TID 324, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 54.0 (TID 325, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 0.0 in stage 54.0 (TID 324)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 1.0 in stage 54.0 (TID 325)
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 1.0 in stage 54.0 (TID 325). 2203 bytes result sent to driver
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 0.0 in stage 54.0 (TID 324). 2203 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 54.0 (TID 325) in 34 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 54.0 (TID 324) in 35 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2020-05-19 05:25:37 INFO  DAGScheduler:54 - ShuffleMapStage 54 (start at NativeMethodAccessorImpl.java:0) finished in 0.048 s
2020-05-19 05:25:37 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:37 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 55)
2020-05-19 05:25:37 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Submitting ResultStage 55 (MapPartitionsRDD[417] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_111 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:37 INFO  MemoryStore:54 - Block broadcast_111_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:37 INFO  BlockManagerInfo:54 - Added broadcast_111_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:37 INFO  SparkContext:54 - Created broadcast 111 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:37 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 55 (MapPartitionsRDD[417] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:37 INFO  TaskSchedulerImpl:54 - Adding task set 55.0 with 10 tasks
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 55.0 (TID 326, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 55.0 (TID 327, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 1.0 in stage 55.0 (TID 327)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 0.0 in stage 55.0 (TID 326)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28260331
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fa83cac
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d94cd96
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3513d8fa
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/28.delta
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 0.0 in stage 55.0 (TID 326). 34047 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 2.0 in stage 55.0 (TID 328, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:37 INFO  Executor:54 - Running task 2.0 in stage 55.0 (TID 328)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 55.0 (TID 326) in 106 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 1.0 in stage 55.0 (TID 327). 33158 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 3.0 in stage 55.0 (TID 329, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 3.0 in stage 55.0 (TID 329)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 55.0 (TID 327) in 109 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37564939
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7780f403
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72261a70
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56db07ae
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 9 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 3.0 in stage 55.0 (TID 329). 36009 bytes result sent to driver
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/28.delta
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 4.0 in stage 55.0 (TID 330, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 3.0 in stage 55.0 (TID 329) in 78 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 4.0 in stage 55.0 (TID 330)
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e3b4e48
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f6ce003
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 2.0 in stage 55.0 (TID 328). 34915 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 5.0 in stage 55.0 (TID 331, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 2.0 in stage 55.0 (TID 328) in 127 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 5.0 in stage 55.0 (TID 331)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dfc7dc0
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59feb72b
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 4.0 in stage 55.0 (TID 330). 35928 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 6.0 in stage 55.0 (TID 332, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 6.0 in stage 55.0 (TID 332)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 4.0 in stage 55.0 (TID 330) in 149 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24b0d544
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e56262b
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 5.0 in stage 55.0 (TID 331). 37837 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 7.0 in stage 55.0 (TID 333, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 7.0 in stage 55.0 (TID 333)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 5.0 in stage 55.0 (TID 331) in 150 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79ce32c8
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cb96e9f
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/28.delta
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:37 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 6.0 in stage 55.0 (TID 332). 38615 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 8.0 in stage 55.0 (TID 334, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 8.0 in stage 55.0 (TID 334)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 6.0 in stage 55.0 (TID 332) in 151 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48ecc1c8
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33a281fe
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:37 INFO  Executor:54 - Finished task 7.0 in stage 55.0 (TID 333). 36299 bytes result sent to driver
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Starting task 9.0 in stage 55.0 (TID 335, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:37 INFO  Executor:54 - Running task 9.0 in stage 55.0 (TID 335)
2020-05-19 05:25:37 INFO  TaskSetManager:54 - Finished task 7.0 in stage 55.0 (TID 333) in 135 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7021654f
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:37 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:37 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:37 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49393625
2020-05-19 05:25:37 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 27 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:37 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/28.delta
2020-05-19 05:25:38 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:38 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:38 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:38 INFO  Executor:54 - Finished task 8.0 in stage 55.0 (TID 334). 35149 bytes result sent to driver
2020-05-19 05:25:38 INFO  TaskSetManager:54 - Finished task 8.0 in stage 55.0 (TID 334) in 105 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:38 INFO  HDFSBackedStateStoreProvider:54 - Committed version 28 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/28.delta
2020-05-19 05:25:38 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:38 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:38 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 28 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:38 INFO  Executor:54 - Finished task 9.0 in stage 55.0 (TID 335). 34702 bytes result sent to driver
2020-05-19 05:25:38 INFO  TaskSetManager:54 - Finished task 9.0 in stage 55.0 (TID 335) in 111 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:38 INFO  TaskSchedulerImpl:54 - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2020-05-19 05:25:38 INFO  DAGScheduler:54 - ResultStage 55 (start at NativeMethodAccessorImpl.java:0) finished in 0.624 s
2020-05-19 05:25:38 INFO  DAGScheduler:54 - Job 54 finished: start at NativeMethodAccessorImpl.java:0, took 0.676931 s
2020-05-19 05:25:38 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3997d19b is committing.
-------------------------------------------
Batch: 27
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:38 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3997d19b committed.
2020-05-19 05:25:38 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:38 INFO  DAGScheduler:54 - Job 55 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:25:38 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:36.975Z",
  "batchId" : 27,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1520737327188941,
  "processedRowsPerSecond" : 1.4814814814814814,
  "durationMs" : {
    "addBatch" : 1146,
    "getBatch" : 5,
    "getOffset" : 6,
    "queryPlanning" : 95,
    "triggerExecution" : 1350,
    "walCommit" : 96
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:58:30.000Z",
    "max" : "2018-12-28T16:59:00.000Z",
    "min" : "2018-12-28T16:58:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2819,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3236,
        "0" : 3139
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3237,
        "0" : 3140
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1520737327188941,
    "processedRowsPerSecond" : 1.4814814814814814
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_110_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2366
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2320
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2359
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2376
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2461
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2445
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2372
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2353
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2396
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2474
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2325
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2465
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2470
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2468
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2360
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2404
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2344
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2385
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_111_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2402
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2364
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2399
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2467
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2338
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2367
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2384
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_104_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_109_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2382
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2457
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2406
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2346
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2486
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2377
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2444
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2451
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2442
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2378
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2350
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2331
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2443
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2333
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2489
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2454
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2480
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2400
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2478
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2450
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2345
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2383
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2369
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned shuffle 26
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2393
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_107_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2316
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2362
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2462
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2343
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2351
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_105_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2484
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2328
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2394
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2357
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2329
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2349
2020-05-19 05:25:38 INFO  BlockManagerInfo:54 - Removed broadcast_108_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2482
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2352
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2455
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2446
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2458
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2483
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2460
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2472
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2452
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2401
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2363
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2356
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2391
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2347
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2386
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2375
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2464
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2456
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2481
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2487
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2466
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2392
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2473
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2390
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2403
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2339
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2398
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2361
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2477
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2322
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2336
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2479
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2334
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2371
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2453
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2319
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2327
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2387
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2490
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2337
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2388
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2389
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2354
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2379
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2448
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2370
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2475
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2488
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2365
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2326
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2381
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2492
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2471
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2318
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2330
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2340
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2335
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2358
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2459
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2469
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2332
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2485
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2348
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2380
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2374
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2463
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2373
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2449
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2395
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2447
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2321
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2368
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2323
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2355
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2491
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2324
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2342
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2341
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2476
2020-05-19 05:25:38 INFO  ContextCleaner:54 - Cleaned accumulator 2397
2020-05-19 05:25:38 INFO  MicroBatchExecution:54 - Committed offsets for batch 28. Metadata OffsetSeqMetadata(1546297020000,1589865938545,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:38 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3237,"0":3140}}), end = {"department.police.service.call":{"1":3238,"0":3141}}
2020-05-19 05:25:38 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:38 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3140,3141,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3237,3238,None)
2020-05-19 05:25:38 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:38 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:38 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_112 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_112_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:25:39 INFO  BlockManagerInfo:54 - Added broadcast_112_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:39 INFO  SparkContext:54 - Created broadcast 112 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_113 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_113_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:39 INFO  BlockManagerInfo:54 - Added broadcast_113_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:39 INFO  SparkContext:54 - Created broadcast 113 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:39 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5dca1ba0. The input RDD has 10 partitions.
2020-05-19 05:25:39 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Registering RDD 426 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Got job 56 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Final stage: ResultStage 57 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 56)
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 56)
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 56 (MapPartitionsRDD[426] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_114 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_114_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:39 INFO  BlockManagerInfo:54 - Added broadcast_114_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:39 INFO  SparkContext:54 - Created broadcast 114 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[426] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:39 INFO  TaskSchedulerImpl:54 - Adding task set 56.0 with 2 tasks
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 56.0 (TID 336, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 56.0 (TID 337, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 0.0 in stage 56.0 (TID 336)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 1.0 in stage 56.0 (TID 337)
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 1.0 in stage 56.0 (TID 337). 2203 bytes result sent to driver
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 0.0 in stage 56.0 (TID 336). 2203 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 56.0 (TID 337) in 42 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 56.0 (TID 336) in 44 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2020-05-19 05:25:39 INFO  DAGScheduler:54 - ShuffleMapStage 56 (start at NativeMethodAccessorImpl.java:0) finished in 0.052 s
2020-05-19 05:25:39 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:39 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 57)
2020-05-19 05:25:39 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Submitting ResultStage 57 (MapPartitionsRDD[432] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_115 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:39 INFO  MemoryStore:54 - Block broadcast_115_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:39 INFO  BlockManagerInfo:54 - Added broadcast_115_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:39 INFO  SparkContext:54 - Created broadcast 115 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 57 (MapPartitionsRDD[432] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:39 INFO  TaskSchedulerImpl:54 - Adding task set 57.0 with 10 tasks
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 57.0 (TID 338, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 57.0 (TID 339, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 1.0 in stage 57.0 (TID 339)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  Executor:54 - Running task 0.0 in stage 57.0 (TID 338)
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a550119
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2545fe30
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d6282da
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66051cc9
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 0.0 in stage 57.0 (TID 338). 34047 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 2.0 in stage 57.0 (TID 340, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 2.0 in stage 57.0 (TID 340)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 57.0 (TID 338) in 82 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@209f102a
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c78a4b8
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 1.0 in stage 57.0 (TID 339). 33158 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 3.0 in stage 57.0 (TID 341, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 57.0 (TID 339) in 96 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 3.0 in stage 57.0 (TID 341)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bd9e120
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@772838ce
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/29.delta
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 3.0 in stage 57.0 (TID 341). 36009 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 4.0 in stage 57.0 (TID 342, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 3.0 in stage 57.0 (TID 341) in 60 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 4.0 in stage 57.0 (TID 342)
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 2.0 in stage 57.0 (TID 340). 34915 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 5.0 in stage 57.0 (TID 343, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 2.0 in stage 57.0 (TID 340) in 87 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 5.0 in stage 57.0 (TID 343)
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370bcb83
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@556808c
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39db6282
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55d69efa
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 5.0 in stage 57.0 (TID 343). 37944 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 6.0 in stage 57.0 (TID 344, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 5.0 in stage 57.0 (TID 343) in 113 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 6.0 in stage 57.0 (TID 344)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c8e926e
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25794bae
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 4.0 in stage 57.0 (TID 342). 35928 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 7.0 in stage 57.0 (TID 345, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 7.0 in stage 57.0 (TID 345)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 4.0 in stage 57.0 (TID 342) in 177 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@712e8e80
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c26dccb
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/29.delta
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 7.0 in stage 57.0 (TID 345). 36299 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 8.0 in stage 57.0 (TID 346, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 8.0 in stage 57.0 (TID 346)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 7.0 in stage 57.0 (TID 345) in 122 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7feba5c9
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3499c13c
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 6.0 in stage 57.0 (TID 344). 38724 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Starting task 9.0 in stage 57.0 (TID 347, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:39 INFO  Executor:54 - Running task 9.0 in stage 57.0 (TID 347)
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 6.0 in stage 57.0 (TID 344) in 200 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69a61353
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:39 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:39 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:39 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6de270f8
2020-05-19 05:25:39 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 28 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Committed version 29 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/29.delta
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:39 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 8.0 in stage 57.0 (TID 346). 35149 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 8.0 in stage 57.0 (TID 346) in 146 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:39 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 29 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:39 INFO  Executor:54 - Finished task 9.0 in stage 57.0 (TID 347). 34702 bytes result sent to driver
2020-05-19 05:25:39 INFO  TaskSetManager:54 - Finished task 9.0 in stage 57.0 (TID 347) in 138 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2020-05-19 05:25:39 INFO  DAGScheduler:54 - ResultStage 57 (start at NativeMethodAccessorImpl.java:0) finished in 0.621 s
2020-05-19 05:25:39 INFO  DAGScheduler:54 - Job 56 finished: start at NativeMethodAccessorImpl.java:0, took 0.689602 s
2020-05-19 05:25:39 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5dca1ba0 is committing.
-------------------------------------------
Batch: 28
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:40 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5dca1ba0 committed.
2020-05-19 05:25:40 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Job 57 finished: start at NativeMethodAccessorImpl.java:0, took 0.000047 s
2020-05-19 05:25:40 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:38.540Z",
  "batchId" : 28,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.2779552715654952,
  "processedRowsPerSecond" : 1.226241569589209,
  "durationMs" : {
    "addBatch" : 1335,
    "getBatch" : 6,
    "getOffset" : 4,
    "queryPlanning" : 178,
    "triggerExecution" : 1631,
    "walCommit" : 107
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:58:00.000Z",
    "max" : "2018-12-28T16:58:00.000Z",
    "min" : "2018-12-28T16:58:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2821,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3237,
        "0" : 3140
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3238,
        "0" : 3141
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.2779552715654952,
    "processedRowsPerSecond" : 1.226241569589209
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:40 INFO  MicroBatchExecution:54 - Committed offsets for batch 29. Metadata OffsetSeqMetadata(1546297020000,1589865940244,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:40 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3238,"0":3141}}), end = {"department.police.service.call":{"1":3238,"0":3142}}
2020-05-19 05:25:40 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:40 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3141,3142,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3238,3238,None)
2020-05-19 05:25:40 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:40 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:40 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_116 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_116_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Added broadcast_116_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:40 INFO  SparkContext:54 - Created broadcast 116 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_117 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_117_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Added broadcast_117_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:40 INFO  SparkContext:54 - Created broadcast 117 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:40 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7ec2881a. The input RDD has 10 partitions.
2020-05-19 05:25:40 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2584
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2568
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Registering RDD 441 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Got job 58 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Final stage: ResultStage 59 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 58)
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 58)
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 58 (MapPartitionsRDD[441] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned shuffle 28
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2541
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2520
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2508
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2535
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2412
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2538
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2579
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2409
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2428
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2438
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2556
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2521
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2495
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2416
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2551
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2422
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2533
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2557
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2498
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2511
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_118 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_118_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Removed broadcast_113_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Added broadcast_118_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2545
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2418
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2496
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2569
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2407
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2577
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2552
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2529
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2505
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2411
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2512
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2580
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned shuffle 27
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2574
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2543
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2534
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2433
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2439
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2425
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2515
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2435
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2507
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2571
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2549
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2573
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2548
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2576
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2413
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2567
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2426
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2510
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2528
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2527
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2525
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2516
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2582
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2440
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2441
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2559
2020-05-19 05:25:40 INFO  SparkContext:54 - Created broadcast 118 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[441] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Removed broadcast_112_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:40 INFO  TaskSchedulerImpl:54 - Adding task set 58.0 with 2 tasks
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2581
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2421
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2546
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2432
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2539
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2437
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2504
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 58.0 (TID 348, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Starting task 1.0 in stage 58.0 (TID 349, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:40 INFO  Executor:54 - Running task 0.0 in stage 58.0 (TID 348)
2020-05-19 05:25:40 INFO  Executor:54 - Running task 1.0 in stage 58.0 (TID 349)
2020-05-19 05:25:40 INFO  KafkaSourceRDD:54 - Beginning offset 3238 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Removed broadcast_115_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2575
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2524
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2547
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2560
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2522
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2408
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2532
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2530
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2544
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2430
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2420
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Removed broadcast_114_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2570
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2536
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2509
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2493
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2526
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2554
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2523
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2566
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2531
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2558
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2494
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2434
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2419
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2501
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2417
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2405
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2410
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2542
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2572
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2517
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2550
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2423
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2553
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2429
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2555
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2431
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2497
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2499
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2561
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2562
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2414
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2519
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2427
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2415
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2537
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2502
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2565
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2540
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2500
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2506
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2513
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2578
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2514
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2518
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2436
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2563
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2424
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2503
2020-05-19 05:25:40 INFO  ContextCleaner:54 - Cleaned accumulator 2564
2020-05-19 05:25:40 INFO  Executor:54 - Finished task 1.0 in stage 58.0 (TID 349). 2117 bytes result sent to driver
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Finished task 1.0 in stage 58.0 (TID 349) in 28 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:40 INFO  Executor:54 - Finished task 0.0 in stage 58.0 (TID 348). 2203 bytes result sent to driver
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 58.0 (TID 348) in 48 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2020-05-19 05:25:40 INFO  DAGScheduler:54 - ShuffleMapStage 58 (start at NativeMethodAccessorImpl.java:0) finished in 0.059 s
2020-05-19 05:25:40 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:40 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 59)
2020-05-19 05:25:40 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Submitting ResultStage 59 (MapPartitionsRDD[447] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_119 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:40 INFO  MemoryStore:54 - Block broadcast_119_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:40 INFO  BlockManagerInfo:54 - Added broadcast_119_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:40 INFO  SparkContext:54 - Created broadcast 119 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:40 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 59 (MapPartitionsRDD[447] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:40 INFO  TaskSchedulerImpl:54 - Adding task set 59.0 with 10 tasks
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 59.0 (TID 350, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Starting task 1.0 in stage 59.0 (TID 351, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:40 INFO  Executor:54 - Running task 0.0 in stage 59.0 (TID 350)
2020-05-19 05:25:40 INFO  Executor:54 - Running task 1.0 in stage 59.0 (TID 351)
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ce4db90
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64d1465a
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49027d17
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fbe1f27
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 6 ms
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/30.delta
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/30.delta
2020-05-19 05:25:40 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:40 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:40 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:40 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:40 INFO  Executor:54 - Finished task 0.0 in stage 59.0 (TID 350). 34047 bytes result sent to driver
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Starting task 2.0 in stage 59.0 (TID 352, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:40 INFO  Executor:54 - Running task 2.0 in stage 59.0 (TID 352)
2020-05-19 05:25:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 59.0 (TID 350) in 130 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f1e1c15
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:40 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:40 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:40 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7967f423
2020-05-19 05:25:40 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:40 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 1.0 in stage 59.0 (TID 351). 33158 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 3.0 in stage 59.0 (TID 353, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 3.0 in stage 59.0 (TID 353)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 59.0 (TID 351) in 191 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d4565ee
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d4857bc
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 2.0 in stage 59.0 (TID 352). 34915 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 4.0 in stage 59.0 (TID 354, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 4.0 in stage 59.0 (TID 354)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 2.0 in stage 59.0 (TID 352) in 162 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@482e51bf
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77c5d498
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 3.0 in stage 59.0 (TID 353). 36009 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 5.0 in stage 59.0 (TID 355, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 5.0 in stage 59.0 (TID 355)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 3.0 in stage 59.0 (TID 353) in 141 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a7e856
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78718b38
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 5.0 in stage 59.0 (TID 355). 37944 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 6.0 in stage 59.0 (TID 356, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 5.0 in stage 59.0 (TID 355) in 74 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 6.0 in stage 59.0 (TID 356)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65773b55
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28309f01
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 4.0 in stage 59.0 (TID 354). 36032 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 7.0 in stage 59.0 (TID 357, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 7.0 in stage 59.0 (TID 357)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 4.0 in stage 59.0 (TID 354) in 128 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48acfd90
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61825f97
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/30.delta
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 7.0 in stage 59.0 (TID 357). 36299 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 8.0 in stage 59.0 (TID 358, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 7.0 in stage 59.0 (TID 357) in 102 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 8.0 in stage 59.0 (TID 358)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31910326
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65bf2b00
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 6.0 in stage 59.0 (TID 356). 38724 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Starting task 9.0 in stage 59.0 (TID 359, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:41 INFO  Executor:54 - Running task 9.0 in stage 59.0 (TID 359)
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 6.0 in stage 59.0 (TID 356) in 137 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5735ad8d
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:41 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:41 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:41 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a37be1f
2020-05-19 05:25:41 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 29 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Committed version 30 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/30.delta
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:41 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 8.0 in stage 59.0 (TID 358). 35149 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 8.0 in stage 59.0 (TID 358) in 92 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:41 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 30 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:41 INFO  Executor:54 - Finished task 9.0 in stage 59.0 (TID 359). 34702 bytes result sent to driver
2020-05-19 05:25:41 INFO  TaskSetManager:54 - Finished task 9.0 in stage 59.0 (TID 359) in 94 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2020-05-19 05:25:41 INFO  DAGScheduler:54 - ResultStage 59 (start at NativeMethodAccessorImpl.java:0) finished in 0.638 s
2020-05-19 05:25:41 INFO  DAGScheduler:54 - Job 58 finished: start at NativeMethodAccessorImpl.java:0, took 0.704084 s
2020-05-19 05:25:41 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7ec2881a is committing.
-------------------------------------------
Batch: 29
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:41 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7ec2881a committed.
2020-05-19 05:25:41 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:41 INFO  DAGScheduler:54 - Job 59 finished: start at NativeMethodAccessorImpl.java:0, took 0.000039 s
2020-05-19 05:25:41 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:40.240Z",
  "batchId" : 29,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.5882352941176471,
  "processedRowsPerSecond" : 0.6988120195667366,
  "durationMs" : {
    "addBatch" : 1247,
    "getBatch" : 7,
    "getOffset" : 4,
    "queryPlanning" : 84,
    "triggerExecution" : 1431,
    "walCommit" : 86
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:58:00.000Z",
    "max" : "2018-12-28T16:58:00.000Z",
    "min" : "2018-12-28T16:58:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2822,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3238,
        "0" : 3141
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3238,
        "0" : 3142
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.5882352941176471,
    "processedRowsPerSecond" : 0.6988120195667366
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:41 INFO  MicroBatchExecution:54 - Committed offsets for batch 30. Metadata OffsetSeqMetadata(1546297020000,1589865941791,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:41 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3238,"0":3142}}), end = {"department.police.service.call":{"1":3240,"0":3142}}
2020-05-19 05:25:41 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:41 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3142,3142,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3238,3240,None)
2020-05-19 05:25:41 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:41 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:41 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_120 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_120_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Added broadcast_120_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  SparkContext:54 - Created broadcast 120 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_121 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_121_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Added broadcast_121_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  SparkContext:54 - Created broadcast 121 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:42 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2984386f. The input RDD has 10 partitions.
2020-05-19 05:25:42 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Registering RDD 456 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Got job 60 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Final stage: ResultStage 61 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 60)
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 60)
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 60 (MapPartitionsRDD[456] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_122 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_122_piece0 stored as bytes in memory (estimated size 15.7 KB, free 364.3 MB)
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Added broadcast_122_piece0 in memory on 234cbc3ca30b:38543 (size: 15.7 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  SparkContext:54 - Created broadcast 122 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[456] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:42 INFO  TaskSchedulerImpl:54 - Adding task set 60.0 with 2 tasks
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 60.0 (TID 360, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 1.0 in stage 60.0 (TID 361, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 1.0 in stage 60.0 (TID 361)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 0.0 in stage 60.0 (TID 360)
2020-05-19 05:25:42 INFO  KafkaSourceRDD:54 - Beginning offset 3142 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 1.0 in stage 60.0 (TID 361). 2074 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 1.0 in stage 60.0 (TID 361) in 20 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 0.0 in stage 60.0 (TID 360). 2203 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 60.0 (TID 360) in 24 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2020-05-19 05:25:42 INFO  DAGScheduler:54 - ShuffleMapStage 60 (start at NativeMethodAccessorImpl.java:0) finished in 0.033 s
2020-05-19 05:25:42 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:42 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:42 INFO  DAGScheduler:54 - waiting: Set(ResultStage 61)
2020-05-19 05:25:42 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Submitting ResultStage 61 (MapPartitionsRDD[462] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_123 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:42 INFO  MemoryStore:54 - Block broadcast_123_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Added broadcast_123_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  SparkContext:54 - Created broadcast 123 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 61 (MapPartitionsRDD[462] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:42 INFO  TaskSchedulerImpl:54 - Adding task set 61.0 with 10 tasks
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 61.0 (TID 362, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 1.0 in stage 61.0 (TID 363, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 1.0 in stage 61.0 (TID 363)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 0.0 in stage 61.0 (TID 362)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bbe71f7
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9092483
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@229868d6
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e3d6f2d
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 1.0 in stage 61.0 (TID 363). 33158 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 2.0 in stage 61.0 (TID 364, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 1.0 in stage 61.0 (TID 363) in 111 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:42 INFO  Executor:54 - Running task 2.0 in stage 61.0 (TID 364)
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 0.0 in stage 61.0 (TID 362). 34149 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 3.0 in stage 61.0 (TID 365, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 61.0 (TID 362) in 118 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 3.0 in stage 61.0 (TID 365)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49f30b11
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d40de4c
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53dc7f19
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bee4d51
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/31.delta
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 2.0 in stage 61.0 (TID 364). 34915 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 4.0 in stage 61.0 (TID 366, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 2.0 in stage 61.0 (TID 364) in 129 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 4.0 in stage 61.0 (TID 366)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e384df
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46c2722
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 3.0 in stage 61.0 (TID 365). 36009 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 5.0 in stage 61.0 (TID 367, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 5.0 in stage 61.0 (TID 367)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 3.0 in stage 61.0 (TID 365) in 141 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370986bc
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ec44155
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/31.delta
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 4.0 in stage 61.0 (TID 366). 36032 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 6.0 in stage 61.0 (TID 368, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 4.0 in stage 61.0 (TID 366) in 96 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 6.0 in stage 61.0 (TID 368)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bdc67ab
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71bee167
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 5.0 in stage 61.0 (TID 367). 37944 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 7.0 in stage 61.0 (TID 369, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 7.0 in stage 61.0 (TID 369)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 5.0 in stage 61.0 (TID 367) in 115 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd2ecd
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bbfadaf
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 6.0 in stage 61.0 (TID 368). 38826 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 8.0 in stage 61.0 (TID 370, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 6.0 in stage 61.0 (TID 368) in 118 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 8.0 in stage 61.0 (TID 370)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c05e705
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dd68b10
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 7.0 in stage 61.0 (TID 369). 36342 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Starting task 9.0 in stage 61.0 (TID 371, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 7.0 in stage 61.0 (TID 369) in 143 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:42 INFO  Executor:54 - Running task 9.0 in stage 61.0 (TID 371)
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/31.delta
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Removed broadcast_119_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@553d6c6a
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:42 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:42 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:42 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d72cca0
2020-05-19 05:25:42 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 30 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2668
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2614
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2645
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2663
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2671
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2608
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2633
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2628
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2603
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2627
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2632
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Removed broadcast_116_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Removed broadcast_118_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2615
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2647
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2583
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2661
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2651
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2620
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2588
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2650
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2646
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Removed broadcast_117_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2635
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2637
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2639
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2653
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2606
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2601
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2617
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2670
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2634
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2673
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2642
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2597
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2638
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2589
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2654
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2643
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2610
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2609
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2596
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2644
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:42 INFO  BlockManagerInfo:54 - Removed broadcast_122_piece0 on 234cbc3ca30b:38543 in memory (size: 15.7 KB, free: 366.2 MB)
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2629
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2625
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2599
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2630
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2612
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2587
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2623
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2586
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2605
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2604
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2667
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2669
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2649
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2607
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2662
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2636
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2641
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2590
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2659
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2613
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2656
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2626
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2616
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2655
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2592
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2593
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned shuffle 29
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2624
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2652
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2618
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2585
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2619
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2640
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2600
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2595
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2648
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2591
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2611
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2631
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2657
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2598
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2658
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2622
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2666
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2660
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2602
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2665
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2664
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2594
2020-05-19 05:25:42 INFO  ContextCleaner:54 - Cleaned accumulator 2621
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 8.0 in stage 61.0 (TID 370). 35192 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 8.0 in stage 61.0 (TID 370) in 129 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Committed version 31 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/31.delta
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:42 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:42 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 31 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:42 INFO  Executor:54 - Finished task 9.0 in stage 61.0 (TID 371). 34702 bytes result sent to driver
2020-05-19 05:25:42 INFO  TaskSetManager:54 - Finished task 9.0 in stage 61.0 (TID 371) in 132 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2020-05-19 05:25:42 INFO  DAGScheduler:54 - ResultStage 61 (start at NativeMethodAccessorImpl.java:0) finished in 0.647 s
2020-05-19 05:25:42 INFO  DAGScheduler:54 - Job 60 finished: start at NativeMethodAccessorImpl.java:0, took 0.685200 s
2020-05-19 05:25:42 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2984386f is committing.
-------------------------------------------
Batch: 30
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:43 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2984386f committed.
2020-05-19 05:25:43 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Job 61 finished: start at NativeMethodAccessorImpl.java:0, took 0.000045 s
2020-05-19 05:25:43 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:41.786Z",
  "batchId" : 30,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.2936610608020698,
  "processedRowsPerSecond" : 1.41643059490085,
  "durationMs" : {
    "addBatch" : 1270,
    "getBatch" : 5,
    "getOffset" : 3,
    "queryPlanning" : 68,
    "triggerExecution" : 1412,
    "walCommit" : 64
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:56:30.000Z",
    "max" : "2018-12-28T16:57:00.000Z",
    "min" : "2018-12-28T16:56:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2824,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3238,
        "0" : 3142
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3240,
        "0" : 3142
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.2936610608020698,
    "processedRowsPerSecond" : 1.41643059490085
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:43 INFO  MicroBatchExecution:54 - Committed offsets for batch 31. Metadata OffsetSeqMetadata(1546297020000,1589865943244,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:43 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3240,"0":3142}}), end = {"department.police.service.call":{"1":3240,"0":3143}}
2020-05-19 05:25:43 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:43 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3142,3143,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3240,3240,None)
2020-05-19 05:25:43 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:43 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:43 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e0a88df
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_124 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:43 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/31.snapshot
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_124_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:43 INFO  BlockManagerInfo:54 - Added broadcast_124_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:43 INFO  SparkContext:54 - Created broadcast 124 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b780899
2020-05-19 05:25:43 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/31.snapshot
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d87d66e
2020-05-19 05:25:43 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/31.snapshot
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f891f80
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_125 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:43 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/31.snapshot
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@570e0c7b
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_125_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:43 INFO  BlockManagerInfo:54 - Added broadcast_125_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:43 INFO  SparkContext:54 - Created broadcast 125 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:43 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@46396990. The input RDD has 10 partitions.
2020-05-19 05:25:43 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Registering RDD 471 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Got job 62 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Final stage: ResultStage 63 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 62)
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 62)
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 62 (MapPartitionsRDD[471] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_126 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_126_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:43 INFO  BlockManagerInfo:54 - Added broadcast_126_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:43 INFO  SparkContext:54 - Created broadcast 126 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[471] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:43 INFO  TaskSchedulerImpl:54 - Adding task set 62.0 with 2 tasks
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 62.0 (TID 372, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Starting task 1.0 in stage 62.0 (TID 373, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:43 INFO  Executor:54 - Running task 0.0 in stage 62.0 (TID 372)
2020-05-19 05:25:43 INFO  Executor:54 - Running task 1.0 in stage 62.0 (TID 373)
2020-05-19 05:25:43 INFO  KafkaSourceRDD:54 - Beginning offset 3240 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:43 INFO  Executor:54 - Finished task 0.0 in stage 62.0 (TID 372). 2074 bytes result sent to driver
2020-05-19 05:25:43 INFO  Executor:54 - Finished task 1.0 in stage 62.0 (TID 373). 2203 bytes result sent to driver
2020-05-19 05:25:43 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/31.snapshot
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 62.0 (TID 372) in 32 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:43 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c59eac3
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Finished task 1.0 in stage 62.0 (TID 373) in 33 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2020-05-19 05:25:43 INFO  DAGScheduler:54 - ShuffleMapStage 62 (start at NativeMethodAccessorImpl.java:0) finished in 0.041 s
2020-05-19 05:25:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:43 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 63)
2020-05-19 05:25:43 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Submitting ResultStage 63 (MapPartitionsRDD[477] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_127 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:43 INFO  MemoryStore:54 - Block broadcast_127_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:43 INFO  BlockManagerInfo:54 - Added broadcast_127_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:43 INFO  SparkContext:54 - Created broadcast 127 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:43 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 63 (MapPartitionsRDD[477] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:43 INFO  TaskSchedulerImpl:54 - Adding task set 63.0 with 10 tasks
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 63.0 (TID 374, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:43 INFO  TaskSetManager:54 - Starting task 1.0 in stage 63.0 (TID 375, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:43 INFO  Executor:54 - Running task 1.0 in stage 63.0 (TID 375)
2020-05-19 05:25:43 INFO  Executor:54 - Running task 0.0 in stage 63.0 (TID 374)
2020-05-19 05:25:43 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:43 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c5d21c8
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3877fddc
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c12d4e1
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27ab633d
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/31.snapshot
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ffe6f80
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/31.snapshot
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/32.delta
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183c00e0
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/32.delta
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 0.0 in stage 63.0 (TID 374). 34149 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 2.0 in stage 63.0 (TID 376, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 2.0 in stage 63.0 (TID 376)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 63.0 (TID 374) in 113 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bf7e643
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32ff9d4d
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/31.snapshot
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ff6aa48
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 1.0 in stage 63.0 (TID 375). 33158 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 3.0 in stage 63.0 (TID 377, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 1.0 in stage 63.0 (TID 375) in 169 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 3.0 in stage 63.0 (TID 377)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33f481e0
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52f0bf2d
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/31.snapshot
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c8a5087
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 2.0 in stage 63.0 (TID 376). 34915 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 4.0 in stage 63.0 (TID 378, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 4.0 in stage 63.0 (TID 378)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 2.0 in stage 63.0 (TID 376) in 137 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72f4aaad
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2205a05e
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Written snapshot file for version 31 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] at file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/31.snapshot
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 3.0 in stage 63.0 (TID 377). 36009 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 5.0 in stage 63.0 (TID 379, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 5.0 in stage 63.0 (TID 379)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 3.0 in stage 63.0 (TID 377) in 147 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f2ee7f4
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@501b929c
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 4.0 in stage 63.0 (TID 378). 36032 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 6.0 in stage 63.0 (TID 380, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 6.0 in stage 63.0 (TID 380)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 4.0 in stage 63.0 (TID 378) in 92 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d89d2a
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f8897c
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 6.0 in stage 63.0 (TID 380). 38826 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 7.0 in stage 63.0 (TID 381, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 7.0 in stage 63.0 (TID 381)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 6.0 in stage 63.0 (TID 380) in 94 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e2efbe
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 5.0 in stage 63.0 (TID 379). 37944 bytes result sent to driver
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 8.0 in stage 63.0 (TID 382, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612c853d
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 5.0 in stage 63.0 (TID 379) in 124 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 8.0 in stage 63.0 (TID 382)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bdda637
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6561a79e
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 7.0 in stage 63.0 (TID 381). 36299 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Starting task 9.0 in stage 63.0 (TID 383, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 7.0 in stage 63.0 (TID 381) in 100 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:44 INFO  Executor:54 - Running task 9.0 in stage 63.0 (TID 383)
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668adb85
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:44 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:44 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:44 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@702bbf2c
2020-05-19 05:25:44 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 31 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:44 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 8.0 in stage 63.0 (TID 382). 35149 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 8.0 in stage 63.0 (TID 382) in 134 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Committed version 32 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/32.delta
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:44 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:44 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 32 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:44 INFO  Executor:54 - Finished task 9.0 in stage 63.0 (TID 383). 34702 bytes result sent to driver
2020-05-19 05:25:44 INFO  TaskSetManager:54 - Finished task 9.0 in stage 63.0 (TID 383) in 126 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2020-05-19 05:25:44 INFO  DAGScheduler:54 - ResultStage 63 (start at NativeMethodAccessorImpl.java:0) finished in 0.672 s
2020-05-19 05:25:44 INFO  DAGScheduler:54 - Job 62 finished: start at NativeMethodAccessorImpl.java:0, took 0.718990 s
2020-05-19 05:25:44 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@46396990 is committing.
-------------------------------------------
Batch: 31
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:44 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@46396990 committed.
2020-05-19 05:25:44 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:44 INFO  DAGScheduler:54 - Job 63 finished: start at NativeMethodAccessorImpl.java:0, took 0.000040 s
2020-05-19 05:25:44 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:43.240Z",
  "batchId" : 31,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.687757909215956,
  "processedRowsPerSecond" : 0.6349206349206349,
  "durationMs" : {
    "addBatch" : 1387,
    "getBatch" : 13,
    "getOffset" : 4,
    "queryPlanning" : 94,
    "triggerExecution" : 1575,
    "walCommit" : 75
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:55:00.000Z",
    "max" : "2018-12-28T16:55:00.000Z",
    "min" : "2018-12-28T16:55:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2824,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3240,
        "0" : 3142
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3240,
        "0" : 3143
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.687757909215956,
    "processedRowsPerSecond" : 0.6349206349206349
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:45 INFO  MicroBatchExecution:54 - Committed offsets for batch 32. Metadata OffsetSeqMetadata(1546297020000,1589865944937,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:45 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3240,"0":3143}}), end = {"department.police.service.call":{"1":3242,"0":3143}}
2020-05-19 05:25:45 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:45 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3143,3143,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3240,3242,None)
2020-05-19 05:25:45 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:45 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:45 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2740
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2732
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2813
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2717
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_125_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2693
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2737
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2720
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2774
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2804
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2692
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2677
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2837
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2681
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2698
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2828
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2790
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2679
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2706
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2697
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2760
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2789
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2838
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2821
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2809
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2783
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2812
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2747
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2734
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2807
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2730
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2763
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2814
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2791
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2802
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2762
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2736
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2786
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2742
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2767
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2792
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2797
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2696
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2711
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2678
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2703
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2826
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2723
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2829
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2817
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2843
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2844
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2758
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2733
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2704
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2686
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2759
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2842
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2751
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2768
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2816
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2834
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2806
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2765
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2746
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2811
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2712
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2726
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2778
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2833
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2761
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2729
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2810
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2846
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2772
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2710
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2745
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2775
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_123_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2680
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2721
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2777
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2823
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2830
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2764
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2796
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2741
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2691
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2674
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2727
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2684
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2728
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2800
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2808
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2748
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2683
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2744
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2795
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2722
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2738
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2690
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2849
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2716
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2825
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2705
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2803
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2755
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2794
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2818
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2836
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2725
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2757
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2771
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2848
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2831
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2845
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2832
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2840
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2847
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2709
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2750
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2820
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2839
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2799
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2779
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2707
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned shuffle 30
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2689
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2776
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2701
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2782
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_126_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2714
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2749
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2781
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2695
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2754
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_121_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2801
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2685
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2841
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2787
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2819
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2824
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2752
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2708
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_124_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2835
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2785
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2688
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2694
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2788
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2676
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2700
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2743
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2687
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2753
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2851
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2699
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2798
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2827
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_127_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2770
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2702
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2715
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2735
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2766
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2784
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2719
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2731
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2713
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2773
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2682
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2815
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_128 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Removed broadcast_120_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2718
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2822
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2805
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2780
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2793
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned shuffle 31
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2672
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2756
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2675
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2769
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2739
2020-05-19 05:25:45 INFO  ContextCleaner:54 - Cleaned accumulator 2724
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_128_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Added broadcast_128_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  SparkContext:54 - Created broadcast 128 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_129 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_129_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Added broadcast_129_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  SparkContext:54 - Created broadcast 129 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:45 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3dbd6ab4. The input RDD has 10 partitions.
2020-05-19 05:25:45 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Registering RDD 486 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Got job 64 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Final stage: ResultStage 65 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 64)
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 64)
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 64 (MapPartitionsRDD[486] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_130 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_130_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Added broadcast_130_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  SparkContext:54 - Created broadcast 130 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[486] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:45 INFO  TaskSchedulerImpl:54 - Adding task set 64.0 with 2 tasks
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 64.0 (TID 384, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 64.0 (TID 385, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 0.0 in stage 64.0 (TID 384)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 1.0 in stage 64.0 (TID 385)
2020-05-19 05:25:45 INFO  KafkaSourceRDD:54 - Beginning offset 3143 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 0.0 in stage 64.0 (TID 384). 2246 bytes result sent to driver
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 1.0 in stage 64.0 (TID 385). 2074 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 64.0 (TID 384) in 40 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 64.0 (TID 385) in 40 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2020-05-19 05:25:45 INFO  DAGScheduler:54 - ShuffleMapStage 64 (start at NativeMethodAccessorImpl.java:0) finished in 0.045 s
2020-05-19 05:25:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:45 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 65)
2020-05-19 05:25:45 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Submitting ResultStage 65 (MapPartitionsRDD[492] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_131 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:45 INFO  MemoryStore:54 - Block broadcast_131_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:45 INFO  BlockManagerInfo:54 - Added broadcast_131_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:45 INFO  SparkContext:54 - Created broadcast 131 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:45 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 65 (MapPartitionsRDD[492] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:45 INFO  TaskSchedulerImpl:54 - Adding task set 65.0 with 10 tasks
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 65.0 (TID 386, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 65.0 (TID 387, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 1.0 in stage 65.0 (TID 387)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 0.0 in stage 65.0 (TID 386)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f55b2fe
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30666777
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@616c0329
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8b84f46
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 1.0 in stage 65.0 (TID 387). 33158 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 2.0 in stage 65.0 (TID 388, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 65.0 (TID 387) in 107 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 2.0 in stage 65.0 (TID 388)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@436bb656
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30b067fb
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 0.0 in stage 65.0 (TID 386). 34259 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 3.0 in stage 65.0 (TID 389, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 3.0 in stage 65.0 (TID 389)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 65.0 (TID 386) in 131 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6401f7a
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1797b04e
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/33.delta
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 2.0 in stage 65.0 (TID 388). 34915 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 4.0 in stage 65.0 (TID 390, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 4.0 in stage 65.0 (TID 390)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 2.0 in stage 65.0 (TID 388) in 117 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e22ecb5
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d612bd8
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 3.0 in stage 65.0 (TID 389). 36009 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 5.0 in stage 65.0 (TID 391, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 3.0 in stage 65.0 (TID 389) in 148 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 5.0 in stage 65.0 (TID 391)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33fc3a2a
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11db2de3
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 4.0 in stage 65.0 (TID 390). 36032 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 6.0 in stage 65.0 (TID 392, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 6.0 in stage 65.0 (TID 392)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 4.0 in stage 65.0 (TID 390) in 119 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@131bb892
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c718d8c
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/33.delta
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 5.0 in stage 65.0 (TID 391). 37944 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 7.0 in stage 65.0 (TID 393, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 7.0 in stage 65.0 (TID 393)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 5.0 in stage 65.0 (TID 391) in 139 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c80fc7d
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@473ba232
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 6.0 in stage 65.0 (TID 392). 38826 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 8.0 in stage 65.0 (TID 394, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 8.0 in stage 65.0 (TID 394)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 6.0 in stage 65.0 (TID 392) in 141 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14ae14f7
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:45 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74cd7f9
2020-05-19 05:25:45 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/33.delta
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:45 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:45 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:45 INFO  Executor:54 - Finished task 7.0 in stage 65.0 (TID 393). 36299 bytes result sent to driver
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Starting task 9.0 in stage 65.0 (TID 395, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:45 INFO  Executor:54 - Running task 9.0 in stage 65.0 (TID 395)
2020-05-19 05:25:45 INFO  TaskSetManager:54 - Finished task 7.0 in stage 65.0 (TID 393) in 132 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:45 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:45 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d44092f
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:46 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:46 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f05b45f
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 32 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/33.delta
2020-05-19 05:25:46 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:46 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Committed version 33 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/33.delta
2020-05-19 05:25:46 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:46 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:46 INFO  Executor:54 - Finished task 8.0 in stage 65.0 (TID 394). 35149 bytes result sent to driver
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Finished task 8.0 in stage 65.0 (TID 394) in 168 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 33 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:46 INFO  Executor:54 - Finished task 9.0 in stage 65.0 (TID 395). 34702 bytes result sent to driver
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Finished task 9.0 in stage 65.0 (TID 395) in 124 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2020-05-19 05:25:46 INFO  DAGScheduler:54 - ResultStage 65 (start at NativeMethodAccessorImpl.java:0) finished in 0.669 s
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Job 64 finished: start at NativeMethodAccessorImpl.java:0, took 0.720109 s
2020-05-19 05:25:46 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3dbd6ab4 is committing.
-------------------------------------------
Batch: 32
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:46 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3dbd6ab4 committed.
2020-05-19 05:25:46 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Job 65 finished: start at NativeMethodAccessorImpl.java:0, took 0.000041 s
2020-05-19 05:25:46 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:44.934Z",
  "batchId" : 32,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1806375442739079,
  "processedRowsPerSecond" : 1.3717421124828533,
  "durationMs" : {
    "addBatch" : 1300,
    "getBatch" : 8,
    "getOffset" : 3,
    "queryPlanning" : 65,
    "triggerExecution" : 1458,
    "walCommit" : 82
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:55:00.000Z",
    "max" : "2018-12-28T16:55:00.000Z",
    "min" : "2018-12-28T16:55:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2825,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 704525
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3240,
        "0" : 3143
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3242,
        "0" : 3143
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1806375442739079,
    "processedRowsPerSecond" : 1.3717421124828533
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:46 INFO  MicroBatchExecution:54 - Committed offsets for batch 33. Metadata OffsetSeqMetadata(1546297020000,1589865946452,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:46 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3242,"0":3143}}), end = {"department.police.service.call":{"1":3243,"0":3144}}
2020-05-19 05:25:46 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:46 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3143,3144,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3242,3243,None)
2020-05-19 05:25:46 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:46 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:46 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_132 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_132_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:46 INFO  BlockManagerInfo:54 - Added broadcast_132_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:46 INFO  SparkContext:54 - Created broadcast 132 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_133 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_133_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:46 INFO  BlockManagerInfo:54 - Added broadcast_133_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:46 INFO  SparkContext:54 - Created broadcast 133 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:46 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@394eacd1. The input RDD has 10 partitions.
2020-05-19 05:25:46 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Registering RDD 501 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Got job 66 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Final stage: ResultStage 67 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 66)
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 66)
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 66 (MapPartitionsRDD[501] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_134 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_134_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:46 INFO  BlockManagerInfo:54 - Added broadcast_134_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:46 INFO  SparkContext:54 - Created broadcast 134 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[501] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:46 INFO  TaskSchedulerImpl:54 - Adding task set 66.0 with 2 tasks
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 66.0 (TID 396, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Starting task 1.0 in stage 66.0 (TID 397, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:46 INFO  Executor:54 - Running task 1.0 in stage 66.0 (TID 397)
2020-05-19 05:25:46 INFO  Executor:54 - Running task 0.0 in stage 66.0 (TID 396)
2020-05-19 05:25:46 INFO  Executor:54 - Finished task 1.0 in stage 66.0 (TID 397). 2203 bytes result sent to driver
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Finished task 1.0 in stage 66.0 (TID 397) in 17 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:46 INFO  Executor:54 - Finished task 0.0 in stage 66.0 (TID 396). 2203 bytes result sent to driver
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 66.0 (TID 396) in 27 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2020-05-19 05:25:46 INFO  DAGScheduler:54 - ShuffleMapStage 66 (start at NativeMethodAccessorImpl.java:0) finished in 0.041 s
2020-05-19 05:25:46 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:46 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:46 INFO  DAGScheduler:54 - waiting: Set(ResultStage 67)
2020-05-19 05:25:46 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Submitting ResultStage 67 (MapPartitionsRDD[507] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_135 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:46 INFO  MemoryStore:54 - Block broadcast_135_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:46 INFO  BlockManagerInfo:54 - Added broadcast_135_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:46 INFO  SparkContext:54 - Created broadcast 135 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:46 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 67 (MapPartitionsRDD[507] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:46 INFO  TaskSchedulerImpl:54 - Adding task set 67.0 with 10 tasks
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 67.0 (TID 398, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:46 INFO  TaskSetManager:54 - Starting task 1.0 in stage 67.0 (TID 399, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:46 INFO  Executor:54 - Running task 1.0 in stage 67.0 (TID 399)
2020-05-19 05:25:46 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:46 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  Executor:54 - Running task 0.0 in stage 67.0 (TID 398)
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9760bcb
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:46 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:46 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35796687
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:46 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:46 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a110f5a
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:46 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:46 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:46 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48f7c46d
2020-05-19 05:25:46 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:46 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:46 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/34.delta
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 1.0 in stage 67.0 (TID 399). 33158 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 2.0 in stage 67.0 (TID 400, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 2.0 in stage 67.0 (TID 400)
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2882
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2888
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2901
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2898
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2881
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2906
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2937
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2896
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2862
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2894
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2916
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2909
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2889
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2911
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2892
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2913
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2921
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2923
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2899
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2914
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2865
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2867
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2879
2020-05-19 05:25:47 INFO  BlockManagerInfo:54 - Removed broadcast_130_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 1.0 in stage 67.0 (TID 399) in 136 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2926
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2907
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2883
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2864
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  BlockManagerInfo:54 - Removed broadcast_134_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2905
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2930
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2860
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2866
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2871
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2880
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2891
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2935
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2884
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2875
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2910
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2902
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2876
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2912
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2887
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f2d09bc
2020-05-19 05:25:47 INFO  BlockManagerInfo:54 - Removed broadcast_128_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2934
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2919
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2869
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2873
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2893
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2853
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2885
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2925
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2858
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2861
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2855
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2863
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2933
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2917
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2940
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2931
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2850
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2895
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2904
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2938
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2936
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2915
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2868
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2859
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2932
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2872
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2897
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2903
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2927
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2922
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2929
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2856
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2886
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2900
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2924
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2920
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2918
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2870
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2890
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2928
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2878
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2908
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46a31389
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:47 INFO  BlockManagerInfo:54 - Removed broadcast_129_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 0.0 in stage 67.0 (TID 398). 34302 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 3.0 in stage 67.0 (TID 401, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 67.0 (TID 398) in 166 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 3.0 in stage 67.0 (TID 401)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@402eef0b
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2877
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2874
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned shuffle 32
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c4197ad
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:47 INFO  BlockManagerInfo:54 - Removed broadcast_131_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2854
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2857
2020-05-19 05:25:47 INFO  ContextCleaner:54 - Cleaned accumulator 2852
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/34.delta
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 2.0 in stage 67.0 (TID 400). 34915 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 4.0 in stage 67.0 (TID 402, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 4.0 in stage 67.0 (TID 402)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 2.0 in stage 67.0 (TID 400) in 126 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39113da
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20ad9960
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 3.0 in stage 67.0 (TID 401). 36118 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 5.0 in stage 67.0 (TID 403, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 3.0 in stage 67.0 (TID 401) in 113 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 5.0 in stage 67.0 (TID 403)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7970ef67
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/34.delta
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@442c5481
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/34.delta
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 4.0 in stage 67.0 (TID 402). 36032 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 6.0 in stage 67.0 (TID 404, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 4.0 in stage 67.0 (TID 402) in 148 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 6.0 in stage 67.0 (TID 404)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44df2092
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@131d65ab
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 5.0 in stage 67.0 (TID 403). 37944 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 7.0 in stage 67.0 (TID 405, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 7.0 in stage 67.0 (TID 405)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 5.0 in stage 67.0 (TID 403) in 173 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a908a8d
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25d439cd
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 6.0 in stage 67.0 (TID 404). 38826 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 8.0 in stage 67.0 (TID 406, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 6.0 in stage 67.0 (TID 404) in 135 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 8.0 in stage 67.0 (TID 406)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b82e05a
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@658e322
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 7.0 in stage 67.0 (TID 405). 36299 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Starting task 9.0 in stage 67.0 (TID 407, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 7.0 in stage 67.0 (TID 405) in 148 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:47 INFO  Executor:54 - Running task 9.0 in stage 67.0 (TID 407)
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5362df90
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:47 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:47 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:47 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1347187a
2020-05-19 05:25:47 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 8.0 in stage 67.0 (TID 406). 35149 bytes result sent to driver
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 33 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 8.0 in stage 67.0 (TID 406) in 97 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Committed version 34 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/34.delta
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:47 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:47 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 34 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:47 INFO  Executor:54 - Finished task 9.0 in stage 67.0 (TID 407). 34702 bytes result sent to driver
2020-05-19 05:25:47 INFO  TaskSetManager:54 - Finished task 9.0 in stage 67.0 (TID 407) in 113 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2020-05-19 05:25:47 INFO  DAGScheduler:54 - ResultStage 67 (start at NativeMethodAccessorImpl.java:0) finished in 0.712 s
2020-05-19 05:25:47 INFO  DAGScheduler:54 - Job 66 finished: start at NativeMethodAccessorImpl.java:0, took 0.766413 s
2020-05-19 05:25:47 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@394eacd1 is committing.
-------------------------------------------
Batch: 33
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:47 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@394eacd1 committed.
2020-05-19 05:25:47 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:47 INFO  DAGScheduler:54 - Job 67 finished: start at NativeMethodAccessorImpl.java:0, took 0.000042 s
2020-05-19 05:25:47 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:46.448Z",
  "batchId" : 33,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.321003963011889,
  "processedRowsPerSecond" : 1.3869625520110958,
  "durationMs" : {
    "addBatch" : 1275,
    "getBatch" : 5,
    "getOffset" : 4,
    "queryPlanning" : 102,
    "triggerExecution" : 1442,
    "walCommit" : 55
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:54:30.000Z",
    "max" : "2018-12-28T16:55:00.000Z",
    "min" : "2018-12-28T16:54:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2826,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 707189
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3242,
        "0" : 3143
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3243,
        "0" : 3144
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.321003963011889,
    "processedRowsPerSecond" : 1.3869625520110958
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:48 INFO  MicroBatchExecution:54 - Committed offsets for batch 34. Metadata OffsetSeqMetadata(1546297020000,1589865948007,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:48 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3243,"0":3144}}), end = {"department.police.service.call":{"1":3244,"0":3144}}
2020-05-19 05:25:48 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:48 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3144,3144,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3243,3244,None)
2020-05-19 05:25:48 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:48 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:48 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_136 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_136_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:48 INFO  BlockManagerInfo:54 - Added broadcast_136_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:48 INFO  SparkContext:54 - Created broadcast 136 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_137 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_137_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:48 INFO  BlockManagerInfo:54 - Added broadcast_137_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:48 INFO  SparkContext:54 - Created broadcast 137 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:48 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5d8bbfca. The input RDD has 10 partitions.
2020-05-19 05:25:48 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Registering RDD 516 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Got job 68 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Final stage: ResultStage 69 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 68)
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 68)
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 68 (MapPartitionsRDD[516] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_138 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_138_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:48 INFO  BlockManagerInfo:54 - Added broadcast_138_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:48 INFO  SparkContext:54 - Created broadcast 138 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[516] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:48 INFO  TaskSchedulerImpl:54 - Adding task set 68.0 with 2 tasks
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 68.0 (TID 408, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 1.0 in stage 68.0 (TID 409, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 0.0 in stage 68.0 (TID 408)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 1.0 in stage 68.0 (TID 409)
2020-05-19 05:25:48 INFO  KafkaSourceRDD:54 - Beginning offset 3144 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 1.0 in stage 68.0 (TID 409). 2074 bytes result sent to driver
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 0.0 in stage 68.0 (TID 408). 2203 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 1.0 in stage 68.0 (TID 409) in 25 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 68.0 (TID 408) in 26 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2020-05-19 05:25:48 INFO  DAGScheduler:54 - ShuffleMapStage 68 (start at NativeMethodAccessorImpl.java:0) finished in 0.033 s
2020-05-19 05:25:48 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:48 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 69)
2020-05-19 05:25:48 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Submitting ResultStage 69 (MapPartitionsRDD[522] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_139 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:48 INFO  MemoryStore:54 - Block broadcast_139_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:48 INFO  BlockManagerInfo:54 - Added broadcast_139_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:48 INFO  SparkContext:54 - Created broadcast 139 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:48 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 69 (MapPartitionsRDD[522] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:48 INFO  TaskSchedulerImpl:54 - Adding task set 69.0 with 10 tasks
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 69.0 (TID 410, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 1.0 in stage 69.0 (TID 411, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 0.0 in stage 69.0 (TID 410)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 1.0 in stage 69.0 (TID 411)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61b313d1
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26df7c21
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e2a2b8c
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d8007a4
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/35.delta
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/35.delta
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 0.0 in stage 69.0 (TID 410). 34259 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 2.0 in stage 69.0 (TID 412, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 69.0 (TID 410) in 78 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 2.0 in stage 69.0 (TID 412)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@372dcefe
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@273acddc
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/35.delta
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 1.0 in stage 69.0 (TID 411). 33158 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 3.0 in stage 69.0 (TID 413, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 1.0 in stage 69.0 (TID 411) in 153 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 3.0 in stage 69.0 (TID 413)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65ee7d6
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4346683e
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 2.0 in stage 69.0 (TID 412). 34915 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 4.0 in stage 69.0 (TID 414, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 2.0 in stage 69.0 (TID 412) in 104 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 4.0 in stage 69.0 (TID 414)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@199506b6
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fa1913b
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/35.delta
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/35.delta
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 3.0 in stage 69.0 (TID 413). 36118 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 5.0 in stage 69.0 (TID 415, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 3.0 in stage 69.0 (TID 413) in 98 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 5.0 in stage 69.0 (TID 415)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17093d4f
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a442bad
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 4.0 in stage 69.0 (TID 414). 36032 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 6.0 in stage 69.0 (TID 416, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 6.0 in stage 69.0 (TID 416)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 4.0 in stage 69.0 (TID 414) in 109 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39838e14
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/35.delta
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78abb151
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/35.delta
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 5.0 in stage 69.0 (TID 415). 37944 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 7.0 in stage 69.0 (TID 417, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 7.0 in stage 69.0 (TID 417)
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 5.0 in stage 69.0 (TID 415) in 94 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5611486
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6430c20b
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:48 INFO  Executor:54 - Finished task 6.0 in stage 69.0 (TID 416). 38826 bytes result sent to driver
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Starting task 8.0 in stage 69.0 (TID 418, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:48 INFO  Executor:54 - Running task 8.0 in stage 69.0 (TID 418)
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cbbe01a
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:48 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:48 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:48 INFO  TaskSetManager:54 - Finished task 6.0 in stage 69.0 (TID 416) in 115 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:48 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40cd2c4c
2020-05-19 05:25:48 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/35.delta
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:48 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/35.delta
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:48 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 7.0 in stage 69.0 (TID 417). 36299 bytes result sent to driver
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Starting task 9.0 in stage 69.0 (TID 419, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:49 INFO  Executor:54 - Running task 9.0 in stage 69.0 (TID 419)
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Finished task 7.0 in stage 69.0 (TID 417) in 186 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3be2c6b3
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@355a848
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 34 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 8.0 in stage 69.0 (TID 418). 35149 bytes result sent to driver
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Finished task 8.0 in stage 69.0 (TID 418) in 149 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Committed version 35 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/35.delta
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 35 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 9.0 in stage 69.0 (TID 419). 34810 bytes result sent to driver
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Finished task 9.0 in stage 69.0 (TID 419) in 105 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2020-05-19 05:25:49 INFO  DAGScheduler:54 - ResultStage 69 (start at NativeMethodAccessorImpl.java:0) finished in 0.639 s
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Job 68 finished: start at NativeMethodAccessorImpl.java:0, took 0.681089 s
2020-05-19 05:25:49 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5d8bbfca is committing.
-------------------------------------------
Batch: 34
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:49 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5d8bbfca committed.
2020-05-19 05:25:49 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Job 69 finished: start at NativeMethodAccessorImpl.java:0, took 0.000776 s
2020-05-19 05:25:49 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:48.004Z",
  "batchId" : 34,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6426735218508998,
  "processedRowsPerSecond" : 0.7363770250368188,
  "durationMs" : {
    "addBatch" : 1245,
    "getBatch" : 5,
    "getOffset" : 3,
    "queryPlanning" : 61,
    "triggerExecution" : 1358,
    "walCommit" : 43
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:54:00.000Z",
    "max" : "2018-12-28T16:54:00.000Z",
    "min" : "2018-12-28T16:54:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2827,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 707189
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3243,
        "0" : 3144
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3244,
        "0" : 3144
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6426735218508998,
    "processedRowsPerSecond" : 0.7363770250368188
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_133_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3074
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3092
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3099
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2978
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3068
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3103
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3007
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3078
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2992
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3112
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3090
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3018
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2947
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2951
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3017
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2946
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2997
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3088
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3002
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3096
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2980
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2963
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3102
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2996
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3073
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3020
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2957
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2969
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3098
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3021
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3115
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3019
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3072
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2964
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3014
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2962
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3066
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3081
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2941
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_139_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2998
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2961
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2972
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2991
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3079
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3095
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2974
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2949
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3029
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3067
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2966
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2968
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3077
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3084
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3105
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3111
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2965
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3093
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3083
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2960
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3075
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2986
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3013
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2948
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3001
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2990
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2984
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2973
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2944
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2985
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2994
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3104
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3113
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3027
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2950
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2989
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2995
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2981
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3010
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3097
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3085
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3110
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3016
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3008
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3076
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3100
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2953
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2983
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2942
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3000
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2945
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_135_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3114
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3023
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3108
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2970
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3069
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3106
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2956
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3012
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3011
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3022
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3086
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3080
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3009
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3004
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2979
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3025
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_132_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2993
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3006
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2988
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2939
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3094
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_136_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3082
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2943
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3071
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2987
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2954
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2959
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3089
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2955
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3107
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3015
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3026
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3087
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2958
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3003
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_138_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3065
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2976
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2999
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3091
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3101
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Removed broadcast_137_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned shuffle 33
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3005
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2975
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2971
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2982
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3070
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2952
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2967
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3024
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 2977
2020-05-19 05:25:49 INFO  ContextCleaner:54 - Cleaned accumulator 3109
2020-05-19 05:25:49 INFO  MicroBatchExecution:54 - Committed offsets for batch 35. Metadata OffsetSeqMetadata(1546297020000,1589865949408,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:49 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3244,"0":3144}}), end = {"department.police.service.call":{"1":3245,"0":3145}}
2020-05-19 05:25:49 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:49 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3144,3145,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3244,3245,None)
2020-05-19 05:25:49 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:49 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:49 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_140 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_140_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Added broadcast_140_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  SparkContext:54 - Created broadcast 140 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_141 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_141_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Added broadcast_141_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  SparkContext:54 - Created broadcast 141 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:49 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@69009810. The input RDD has 10 partitions.
2020-05-19 05:25:49 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Registering RDD 531 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Got job 70 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Final stage: ResultStage 71 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 70)
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 70)
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 70 (MapPartitionsRDD[531] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_142 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_142_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Added broadcast_142_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  SparkContext:54 - Created broadcast 142 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[531] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:49 INFO  TaskSchedulerImpl:54 - Adding task set 70.0 with 2 tasks
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 70.0 (TID 420, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Starting task 1.0 in stage 70.0 (TID 421, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:49 INFO  Executor:54 - Running task 1.0 in stage 70.0 (TID 421)
2020-05-19 05:25:49 INFO  Executor:54 - Running task 0.0 in stage 70.0 (TID 420)
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 0.0 in stage 70.0 (TID 420). 2203 bytes result sent to driver
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 1.0 in stage 70.0 (TID 421). 2203 bytes result sent to driver
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 70.0 (TID 420) in 29 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Finished task 1.0 in stage 70.0 (TID 421) in 33 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2020-05-19 05:25:49 INFO  DAGScheduler:54 - ShuffleMapStage 70 (start at NativeMethodAccessorImpl.java:0) finished in 0.038 s
2020-05-19 05:25:49 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:49 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:49 INFO  DAGScheduler:54 - waiting: Set(ResultStage 71)
2020-05-19 05:25:49 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Submitting ResultStage 71 (MapPartitionsRDD[537] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_143 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:49 INFO  MemoryStore:54 - Block broadcast_143_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:49 INFO  BlockManagerInfo:54 - Added broadcast_143_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:49 INFO  SparkContext:54 - Created broadcast 143 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:49 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 71 (MapPartitionsRDD[537] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:49 INFO  TaskSchedulerImpl:54 - Adding task set 71.0 with 10 tasks
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 71.0 (TID 422, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:49 INFO  TaskSetManager:54 - Starting task 1.0 in stage 71.0 (TID 423, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:49 INFO  Executor:54 - Running task 0.0 in stage 71.0 (TID 422)
2020-05-19 05:25:49 INFO  Executor:54 - Running task 1.0 in stage 71.0 (TID 423)
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cf5b939
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5313a722
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42208bd5
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:49 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:49 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:49 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f75125
2020-05-19 05:25:49 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/36.delta
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/36.delta
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:49 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:49 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:49 INFO  Executor:54 - Finished task 0.0 in stage 71.0 (TID 422). 34259 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 2.0 in stage 71.0 (TID 424, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 2.0 in stage 71.0 (TID 424)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 71.0 (TID 422) in 120 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c1ef8e6
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bf318cc
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 1.0 in stage 71.0 (TID 423). 33265 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 3.0 in stage 71.0 (TID 425, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 3.0 in stage 71.0 (TID 425)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 1.0 in stage 71.0 (TID 423) in 146 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65b5339
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8b512a
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 3.0 in stage 71.0 (TID 425). 36118 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 4.0 in stage 71.0 (TID 426, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 3.0 in stage 71.0 (TID 425) in 115 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 4.0 in stage 71.0 (TID 426)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@abaed82
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c62b6e8
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 2.0 in stage 71.0 (TID 424). 34915 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 5.0 in stage 71.0 (TID 427, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 5.0 in stage 71.0 (TID 427)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 2.0 in stage 71.0 (TID 424) in 173 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d335d74
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4caff6ac
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 4.0 in stage 71.0 (TID 426). 36032 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 6.0 in stage 71.0 (TID 428, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 4.0 in stage 71.0 (TID 426) in 142 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 6.0 in stage 71.0 (TID 428)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b839047
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75238e8e
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 5.0 in stage 71.0 (TID 427). 37944 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 7.0 in stage 71.0 (TID 429, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 7.0 in stage 71.0 (TID 429)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 5.0 in stage 71.0 (TID 427) in 125 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1eaf8b59
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7873a716
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/36.delta
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 7.0 in stage 71.0 (TID 429). 36299 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 8.0 in stage 71.0 (TID 430, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 8.0 in stage 71.0 (TID 430)
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 7.0 in stage 71.0 (TID 429) in 111 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4694eb28
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@585c3329
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 6.0 in stage 71.0 (TID 428). 38826 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Starting task 9.0 in stage 71.0 (TID 431, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:50 INFO  Executor:54 - Running task 9.0 in stage 71.0 (TID 431)
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e211baf
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:50 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:50 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:50 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c73efc3
2020-05-19 05:25:50 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 35 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 6.0 in stage 71.0 (TID 428) in 179 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Committed version 36 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/36.delta
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:50 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 8.0 in stage 71.0 (TID 430). 35254 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 8.0 in stage 71.0 (TID 430) in 124 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:50 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 36 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:50 INFO  Executor:54 - Finished task 9.0 in stage 71.0 (TID 431). 34810 bytes result sent to driver
2020-05-19 05:25:50 INFO  TaskSetManager:54 - Finished task 9.0 in stage 71.0 (TID 431) in 113 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2020-05-19 05:25:50 INFO  DAGScheduler:54 - ResultStage 71 (start at NativeMethodAccessorImpl.java:0) finished in 0.686 s
2020-05-19 05:25:50 INFO  DAGScheduler:54 - Job 70 finished: start at NativeMethodAccessorImpl.java:0, took 0.728539 s
2020-05-19 05:25:50 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@69009810 is committing.
-------------------------------------------
Batch: 35
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:50 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@69009810 committed.
2020-05-19 05:25:50 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:50 INFO  DAGScheduler:54 - Job 71 finished: start at NativeMethodAccessorImpl.java:0, took 0.000036 s
2020-05-19 05:25:50 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:49.405Z",
  "batchId" : 35,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.4275517487508922,
  "processedRowsPerSecond" : 1.4204545454545456,
  "durationMs" : {
    "addBatch" : 1211,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 67,
    "triggerExecution" : 1408,
    "walCommit" : 123
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:53:30.000Z",
    "max" : "2018-12-28T16:54:00.000Z",
    "min" : "2018-12-28T16:53:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2829,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 707189
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3244,
        "0" : 3144
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3245,
        "0" : 3145
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.4275517487508922,
    "processedRowsPerSecond" : 1.4204545454545456
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:50 INFO  MicroBatchExecution:54 - Committed offsets for batch 36. Metadata OffsetSeqMetadata(1546297020000,1589865950906,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:50 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3245,"0":3145}}), end = {"department.police.service.call":{"1":3245,"0":3146}}
2020-05-19 05:25:50 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:50 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3145,3146,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3245,3245,None)
2020-05-19 05:25:51 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:51 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:51 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_144 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_144_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Added broadcast_144_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  SparkContext:54 - Created broadcast 144 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_145 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_145_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Added broadcast_145_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  SparkContext:54 - Created broadcast 145 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:51 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@28a618cb. The input RDD has 10 partitions.
2020-05-19 05:25:51 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Registering RDD 546 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Got job 72 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Final stage: ResultStage 73 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 72)
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 72)
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 72 (MapPartitionsRDD[546] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_146 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_146_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Added broadcast_146_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  SparkContext:54 - Created broadcast 146 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[546] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:51 INFO  TaskSchedulerImpl:54 - Adding task set 72.0 with 2 tasks
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 72.0 (TID 432, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 1.0 in stage 72.0 (TID 433, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 0.0 in stage 72.0 (TID 432)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 1.0 in stage 72.0 (TID 433)
2020-05-19 05:25:51 INFO  KafkaSourceRDD:54 - Beginning offset 3245 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 0.0 in stage 72.0 (TID 432). 2074 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 72.0 (TID 432) in 23 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 1.0 in stage 72.0 (TID 433). 2203 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 1.0 in stage 72.0 (TID 433) in 24 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2020-05-19 05:25:51 INFO  DAGScheduler:54 - ShuffleMapStage 72 (start at NativeMethodAccessorImpl.java:0) finished in 0.033 s
2020-05-19 05:25:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:51 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 73)
2020-05-19 05:25:51 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Submitting ResultStage 73 (MapPartitionsRDD[552] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_147 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:51 INFO  MemoryStore:54 - Block broadcast_147_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3126
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Added broadcast_147_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3147
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3176
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3181
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3050
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3139
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3196
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3031
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3037
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3152
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3129
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3171
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3122
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3192
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3156
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3183
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3140
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3039
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3177
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3165
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3058
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3163
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3032
2020-05-19 05:25:51 INFO  SparkContext:54 - Created broadcast 147 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3154
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3190
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3200
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 73 (MapPartitionsRDD[552] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Removed broadcast_143_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  TaskSchedulerImpl:54 - Adding task set 73.0 with 10 tasks
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 73.0 (TID 434, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 1.0 in stage 73.0 (TID 435, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 0.0 in stage 73.0 (TID 434)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3045
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3151
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3055
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3172
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3130
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3168
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3054
2020-05-19 05:25:51 INFO  Executor:54 - Running task 1.0 in stage 73.0 (TID 435)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned shuffle 34
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3162
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3056
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3137
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3203
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3199
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3064
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3062
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3164
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3124
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3160
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3166
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3118
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69e8b123
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@400ee5f5
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@579759b9
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4378f26c
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned shuffle 35
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3042
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3186
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3030
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3036
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3136
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3204
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3052
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3150
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3173
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3193
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3207
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3132
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3157
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3131
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3185
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3146
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3134
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3051
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3178
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3202
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3155
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3179
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3191
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Removed broadcast_142_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3041
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3201
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3174
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3035
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3189
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3135
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3195
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3057
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Removed broadcast_141_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3047
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3120
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3175
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3033
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3040
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3145
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3119
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3197
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3125
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3034
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3144
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3187
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3133
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3148
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3044
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3184
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3170
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3188
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3194
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3128
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3205
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3127
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3149
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3153
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3038
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3123
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3053
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3059
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3049
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3169
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3138
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3117
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3180
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3116
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3043
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3158
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3061
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3182
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3046
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3167
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3141
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3063
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3048
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3121
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3198
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3159
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3161
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3143
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3142
2020-05-19 05:25:51 INFO  BlockManagerInfo:54 - Removed broadcast_140_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3028
2020-05-19 05:25:51 INFO  ContextCleaner:54 - Cleaned accumulator 3060
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 0.0 in stage 73.0 (TID 434). 34259 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 2.0 in stage 73.0 (TID 436, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 2.0 in stage 73.0 (TID 436)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 73.0 (TID 434) in 102 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fa810b7
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4eb5e52d
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 1.0 in stage 73.0 (TID 435). 33265 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 3.0 in stage 73.0 (TID 437, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 1.0 in stage 73.0 (TID 435) in 119 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 3.0 in stage 73.0 (TID 437)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2724472e
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bff8d32
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/37.delta
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 3.0 in stage 73.0 (TID 437). 36118 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 4.0 in stage 73.0 (TID 438, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 4.0 in stage 73.0 (TID 438)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 3.0 in stage 73.0 (TID 437) in 101 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 2.0 in stage 73.0 (TID 436). 34915 bytes result sent to driver
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@248d24e6
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 5.0 in stage 73.0 (TID 439, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 2.0 in stage 73.0 (TID 436) in 129 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 5.0 in stage 73.0 (TID 439)
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3af820fb
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b321a1c
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12ff86a7
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 4.0 in stage 73.0 (TID 438). 36032 bytes result sent to driver
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 6.0 in stage 73.0 (TID 440, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 5.0 in stage 73.0 (TID 439). 38041 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 7.0 in stage 73.0 (TID 441, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 6.0 in stage 73.0 (TID 440)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 5.0 in stage 73.0 (TID 439) in 150 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 4.0 in stage 73.0 (TID 438) in 160 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4329fc64
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  Executor:54 - Running task 7.0 in stage 73.0 (TID 441)
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@108280d0
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7276d2bc
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e50d522
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 6.0 in stage 73.0 (TID 440). 38826 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 8.0 in stage 73.0 (TID 442, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 6.0 in stage 73.0 (TID 440) in 114 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 8.0 in stage 73.0 (TID 442)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@506e8d49
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b4e9f54
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 7.0 in stage 73.0 (TID 441). 36299 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Starting task 9.0 in stage 73.0 (TID 443, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:51 INFO  Executor:54 - Running task 9.0 in stage 73.0 (TID 443)
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 7.0 in stage 73.0 (TID 441) in 157 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b4e81f
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:51 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:51 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:51 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e1fb51b
2020-05-19 05:25:51 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 36 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Committed version 37 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/37.delta
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:51 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 8.0 in stage 73.0 (TID 442). 35254 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 8.0 in stage 73.0 (TID 442) in 151 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:51 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 37 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:51 INFO  Executor:54 - Finished task 9.0 in stage 73.0 (TID 443). 34810 bytes result sent to driver
2020-05-19 05:25:51 INFO  TaskSetManager:54 - Finished task 9.0 in stage 73.0 (TID 443) in 119 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2020-05-19 05:25:51 INFO  DAGScheduler:54 - ResultStage 73 (start at NativeMethodAccessorImpl.java:0) finished in 0.680 s
2020-05-19 05:25:51 INFO  DAGScheduler:54 - Job 72 finished: start at NativeMethodAccessorImpl.java:0, took 0.718481 s
2020-05-19 05:25:51 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@28a618cb is committing.
-------------------------------------------
Batch: 36
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:52 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@28a618cb committed.
2020-05-19 05:25:52 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Job 73 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:25:52 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:50.900Z",
  "batchId" : 36,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6688963210702341,
  "processedRowsPerSecond" : 0.794912559618442,
  "durationMs" : {
    "addBatch" : 1174,
    "getBatch" : 4,
    "getOffset" : 6,
    "queryPlanning" : 36,
    "triggerExecution" : 1258,
    "walCommit" : 37
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:53:00.000Z",
    "max" : "2018-12-28T16:53:00.000Z",
    "min" : "2018-12-28T16:53:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2830,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3245,
        "0" : 3145
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3245,
        "0" : 3146
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6688963210702341,
    "processedRowsPerSecond" : 0.794912559618442
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:52 INFO  MicroBatchExecution:54 - Committed offsets for batch 37. Metadata OffsetSeqMetadata(1546297020000,1589865952231,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:52 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3245,"0":3146}}), end = {"department.police.service.call":{"1":3246,"0":3146}}
2020-05-19 05:25:52 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:52 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3146,3146,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3245,3246,None)
2020-05-19 05:25:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:52 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_148 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_148_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:52 INFO  BlockManagerInfo:54 - Added broadcast_148_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:52 INFO  SparkContext:54 - Created broadcast 148 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_149 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_149_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:52 INFO  BlockManagerInfo:54 - Added broadcast_149_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:52 INFO  SparkContext:54 - Created broadcast 149 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:52 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4bced455. The input RDD has 10 partitions.
2020-05-19 05:25:52 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Registering RDD 561 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Got job 74 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Final stage: ResultStage 75 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 74)
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 74)
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 74 (MapPartitionsRDD[561] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_150 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_150_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:52 INFO  BlockManagerInfo:54 - Added broadcast_150_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:52 INFO  SparkContext:54 - Created broadcast 150 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[561] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:52 INFO  TaskSchedulerImpl:54 - Adding task set 74.0 with 2 tasks
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 74.0 (TID 444, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 1.0 in stage 74.0 (TID 445, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 0.0 in stage 74.0 (TID 444)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 1.0 in stage 74.0 (TID 445)
2020-05-19 05:25:52 INFO  KafkaSourceRDD:54 - Beginning offset 3146 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 1.0 in stage 74.0 (TID 445). 2074 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 1.0 in stage 74.0 (TID 445) in 10 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 0.0 in stage 74.0 (TID 444). 2203 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 74.0 (TID 444) in 24 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2020-05-19 05:25:52 INFO  DAGScheduler:54 - ShuffleMapStage 74 (start at NativeMethodAccessorImpl.java:0) finished in 0.030 s
2020-05-19 05:25:52 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:52 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:52 INFO  DAGScheduler:54 - waiting: Set(ResultStage 75)
2020-05-19 05:25:52 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Submitting ResultStage 75 (MapPartitionsRDD[567] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_151 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:52 INFO  MemoryStore:54 - Block broadcast_151_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:52 INFO  BlockManagerInfo:54 - Added broadcast_151_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:52 INFO  SparkContext:54 - Created broadcast 151 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:52 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 75 (MapPartitionsRDD[567] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:52 INFO  TaskSchedulerImpl:54 - Adding task set 75.0 with 10 tasks
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 75.0 (TID 446, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 1.0 in stage 75.0 (TID 447, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 0.0 in stage 75.0 (TID 446)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 1.0 in stage 75.0 (TID 447)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f38c88d
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67a04c52
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bfed6a5
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bfb0560
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/38.delta
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/38.delta
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 0.0 in stage 75.0 (TID 446). 34259 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 2.0 in stage 75.0 (TID 448, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 2.0 in stage 75.0 (TID 448)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 75.0 (TID 446) in 98 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36fc541b
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@564c015d
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 1.0 in stage 75.0 (TID 447). 33265 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 3.0 in stage 75.0 (TID 449, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 3.0 in stage 75.0 (TID 449)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 1.0 in stage 75.0 (TID 447) in 132 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76946ea4
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1437e65
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/38.delta
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 2.0 in stage 75.0 (TID 448). 34915 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 4.0 in stage 75.0 (TID 450, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 4.0 in stage 75.0 (TID 450)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 2.0 in stage 75.0 (TID 448) in 84 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75174f80
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748ed66d
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/38.delta
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/38.delta
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 3.0 in stage 75.0 (TID 449). 36118 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 5.0 in stage 75.0 (TID 451, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 5.0 in stage 75.0 (TID 451)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 3.0 in stage 75.0 (TID 449) in 100 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22154281
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56c97c27
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/38.delta
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:52 INFO  Executor:54 - Finished task 4.0 in stage 75.0 (TID 450). 36032 bytes result sent to driver
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Starting task 6.0 in stage 75.0 (TID 452, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:52 INFO  Executor:54 - Running task 6.0 in stage 75.0 (TID 452)
2020-05-19 05:25:52 INFO  TaskSetManager:54 - Finished task 4.0 in stage 75.0 (TID 450) in 132 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3407034b
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:52 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:52 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:52 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d0a09f1
2020-05-19 05:25:52 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:52 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:52 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 5.0 in stage 75.0 (TID 451). 38041 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 7.0 in stage 75.0 (TID 453, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 7.0 in stage 75.0 (TID 453)
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 5.0 in stage 75.0 (TID 451) in 140 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bf5333c
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13a3be50
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/38.delta
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/38.delta
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 6.0 in stage 75.0 (TID 452). 38826 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 8.0 in stage 75.0 (TID 454, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 6.0 in stage 75.0 (TID 452) in 134 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 8.0 in stage 75.0 (TID 454)
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f68192
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f0117ea
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 7.0 in stage 75.0 (TID 453). 36299 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 9.0 in stage 75.0 (TID 455, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 7.0 in stage 75.0 (TID 453) in 98 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 9.0 in stage 75.0 (TID 455)
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@204c3182
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50fb826
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 37 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/38.delta
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Committed version 38 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/38.delta
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:53 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 9.0 in stage 75.0 (TID 455). 34810 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 9.0 in stage 75.0 (TID 455) in 108 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 38 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 8.0 in stage 75.0 (TID 454). 35254 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 8.0 in stage 75.0 (TID 454) in 138 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2020-05-19 05:25:53 INFO  DAGScheduler:54 - ResultStage 75 (start at NativeMethodAccessorImpl.java:0) finished in 0.582 s
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Job 74 finished: start at NativeMethodAccessorImpl.java:0, took 0.620133 s
2020-05-19 05:25:53 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4bced455 is committing.
-------------------------------------------
Batch: 37
-------------------------------------------
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3258
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_146_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3217
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_145_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3209
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3213
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3371
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3277
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3288
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3286
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3218
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3210
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3379
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned shuffle 36
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3245
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3266
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3259
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3337
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3264
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3247
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3348
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3221
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3282
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3274
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3336
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3292
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3231
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3339
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3254
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3268
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3230
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3381
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3225
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3256
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3248
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3232
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3285
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3370
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3212
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_147_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3211
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3352
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3343
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3334
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3271
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3345
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3346
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3283
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3368
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3364
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3332
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3335
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3234
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3361
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3290
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3359
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3249
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3293
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3347
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3273
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3362
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3272
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3296
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_150_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3262
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3236
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3255
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3241
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3206
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3239
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3350
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3340
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3357
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3267
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3279
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3284
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3366
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3341
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3291
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3250
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3228
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3216
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3220
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3224
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3214
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3260
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3363
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3219
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3353
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3233
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3342
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3367
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3287
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3244
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3376
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3358
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3226
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3338
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3349
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3252
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3278
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3289
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3253
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3369
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3354
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3281
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3222
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3280
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3375
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3237
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3246
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3344
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3372
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3243
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3269
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3374
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3257
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3265
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3242
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3227
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3229
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3351
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3275
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3380
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_151_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3238
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3261
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3235
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3270
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3208
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3215
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3333
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3373
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3263
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3251
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3378
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3276
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3365
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3355
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3240
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3360
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3294
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3356
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3223
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Removed broadcast_144_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:53 INFO  ContextCleaner:54 - Cleaned accumulator 3377
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:53 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4bced455 committed.
2020-05-19 05:25:53 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Job 75 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:25:53 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:52.226Z",
  "batchId" : 37,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.7541478129713424,
  "processedRowsPerSecond" : 0.7727975270479134,
  "durationMs" : {
    "addBatch" : 1103,
    "getBatch" : 8,
    "getOffset" : 5,
    "queryPlanning" : 45,
    "triggerExecution" : 1294,
    "walCommit" : 130
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:51:00.000Z",
    "max" : "2018-12-28T16:51:00.000Z",
    "min" : "2018-12-28T16:51:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2830,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3245,
        "0" : 3146
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3246,
        "0" : 3146
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.7541478129713424,
    "processedRowsPerSecond" : 0.7727975270479134
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:53 INFO  MicroBatchExecution:54 - Committed offsets for batch 38. Metadata OffsetSeqMetadata(1546297020000,1589865953567,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:53 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3246,"0":3146}}), end = {"department.police.service.call":{"1":3248,"0":3146}}
2020-05-19 05:25:53 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:53 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3146,3146,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3246,3248,None)
2020-05-19 05:25:53 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:53 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:53 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_152 stored as values in memory (estimated size 281.8 KB, free 364.8 MB)
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_152_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.8 MB)
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Added broadcast_152_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:53 INFO  SparkContext:54 - Created broadcast 152 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_153 stored as values in memory (estimated size 281.8 KB, free 364.5 MB)
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_153_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.5 MB)
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Added broadcast_153_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  SparkContext:54 - Created broadcast 153 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:53 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@32862795. The input RDD has 10 partitions.
2020-05-19 05:25:53 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Registering RDD 576 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Got job 76 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Final stage: ResultStage 77 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 76)
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 76)
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 76 (MapPartitionsRDD[576] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_154 stored as values in memory (estimated size 39.1 KB, free 364.4 MB)
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_154_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.4 MB)
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Added broadcast_154_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  SparkContext:54 - Created broadcast 154 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[576] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:53 INFO  TaskSchedulerImpl:54 - Adding task set 76.0 with 2 tasks
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 76.0 (TID 456, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 76.0 (TID 457, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 0.0 in stage 76.0 (TID 456)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 1.0 in stage 76.0 (TID 457)
2020-05-19 05:25:53 INFO  KafkaSourceRDD:54 - Beginning offset 3146 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 1.0 in stage 76.0 (TID 457). 2074 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 76.0 (TID 457) in 17 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:53 INFO  Executor:54 - Finished task 0.0 in stage 76.0 (TID 456). 2203 bytes result sent to driver
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 76.0 (TID 456) in 24 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2020-05-19 05:25:53 INFO  DAGScheduler:54 - ShuffleMapStage 76 (start at NativeMethodAccessorImpl.java:0) finished in 0.044 s
2020-05-19 05:25:53 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:53 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 77)
2020-05-19 05:25:53 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Submitting ResultStage 77 (MapPartitionsRDD[582] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_155 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:53 INFO  MemoryStore:54 - Block broadcast_155_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:53 INFO  BlockManagerInfo:54 - Added broadcast_155_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:53 INFO  SparkContext:54 - Created broadcast 155 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:53 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 77 (MapPartitionsRDD[582] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:53 INFO  TaskSchedulerImpl:54 - Adding task set 77.0 with 10 tasks
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 77.0 (TID 458, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 77.0 (TID 459, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 1.0 in stage 77.0 (TID 459)
2020-05-19 05:25:53 INFO  Executor:54 - Running task 0.0 in stage 77.0 (TID 458)
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@212999a8
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@371cdee0
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@555bb459
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:53 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:53 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:53 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c8c8540
2020-05-19 05:25:53 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:53 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/39.delta
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 1.0 in stage 77.0 (TID 459). 33265 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 2.0 in stage 77.0 (TID 460, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 2.0 in stage 77.0 (TID 460)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 1.0 in stage 77.0 (TID 459) in 104 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 0.0 in stage 77.0 (TID 458). 34359 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 3.0 in stage 77.0 (TID 461, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 77.0 (TID 458) in 110 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 3.0 in stage 77.0 (TID 461)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@168a2670
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44fd61d3
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e1bc34a
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@198f3c16
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 3.0 in stage 77.0 (TID 461). 36118 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 4.0 in stage 77.0 (TID 462, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 4.0 in stage 77.0 (TID 462)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 3.0 in stage 77.0 (TID 461) in 132 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d8ecc03
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72a9fd73
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 2.0 in stage 77.0 (TID 460). 34915 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 5.0 in stage 77.0 (TID 463, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 5.0 in stage 77.0 (TID 463)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 2.0 in stage 77.0 (TID 460) in 163 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25caf8a1
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66422bba
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 4.0 in stage 77.0 (TID 462). 36032 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 6.0 in stage 77.0 (TID 464, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 6.0 in stage 77.0 (TID 464)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 4.0 in stage 77.0 (TID 462) in 180 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a7516f9
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32275bf3
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 5.0 in stage 77.0 (TID 463). 38041 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 7.0 in stage 77.0 (TID 465, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 7.0 in stage 77.0 (TID 465)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 5.0 in stage 77.0 (TID 463) in 192 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/39.delta
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29013c89
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bb1127
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 6.0 in stage 77.0 (TID 464). 38826 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 8.0 in stage 77.0 (TID 466, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 8.0 in stage 77.0 (TID 466)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 6.0 in stage 77.0 (TID 464) in 90 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9b9f881
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/39.delta
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6425c465
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 7.0 in stage 77.0 (TID 465). 36299 bytes result sent to driver
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Starting task 9.0 in stage 77.0 (TID 467, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 7.0 in stage 77.0 (TID 465) in 118 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:54 INFO  Executor:54 - Running task 9.0 in stage 77.0 (TID 467)
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 8.0 in stage 77.0 (TID 466). 35254 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 8.0 in stage 77.0 (TID 466) in 69 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f600fb0
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:54 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:54 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:54 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7caaf1
2020-05-19 05:25:54 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 38 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Committed version 39 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/39.delta
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:54 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:54 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 39 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:54 INFO  Executor:54 - Finished task 9.0 in stage 77.0 (TID 467). 34810 bytes result sent to driver
2020-05-19 05:25:54 INFO  TaskSetManager:54 - Finished task 9.0 in stage 77.0 (TID 467) in 99 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2020-05-19 05:25:54 INFO  DAGScheduler:54 - ResultStage 77 (start at NativeMethodAccessorImpl.java:0) finished in 0.678 s
2020-05-19 05:25:54 INFO  DAGScheduler:54 - Job 76 finished: start at NativeMethodAccessorImpl.java:0, took 0.730108 s
2020-05-19 05:25:54 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@32862795 is committing.
-------------------------------------------
Batch: 38
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:54 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@32862795 committed.
2020-05-19 05:25:54 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:54 INFO  DAGScheduler:54 - Job 77 finished: start at NativeMethodAccessorImpl.java:0, took 0.000048 s
2020-05-19 05:25:54 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:53.564Z",
  "batchId" : 38,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.4947683109118086,
  "processedRowsPerSecond" : 1.5048908954100828,
  "durationMs" : {
    "addBatch" : 1178,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 65,
    "triggerExecution" : 1329,
    "walCommit" : 76
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:51:00.000Z",
    "max" : "2018-12-28T16:51:00.000Z",
    "min" : "2018-12-28T16:51:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2831,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3246,
        "0" : 3146
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3248,
        "0" : 3146
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.4947683109118086,
    "processedRowsPerSecond" : 1.5048908954100828
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:55 INFO  MicroBatchExecution:54 - Committed offsets for batch 39. Metadata OffsetSeqMetadata(1546297020000,1589865955004,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:55 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3248,"0":3146}}), end = {"department.police.service.call":{"1":3248,"0":3147}}
2020-05-19 05:25:55 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:55 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3146,3147,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3248,3248,None)
2020-05-19 05:25:55 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:55 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:55 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_156 stored as values in memory (estimated size 281.8 KB, free 364.1 MB)
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_156_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Added broadcast_156_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  SparkContext:54 - Created broadcast 156 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_157 stored as values in memory (estimated size 281.8 KB, free 363.8 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3425
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3427
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3385
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3411
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3456
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3328
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3421
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3315
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3331
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3395
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3452
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3323
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned shuffle 37
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3441
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3424
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3325
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3446
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3471
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3470
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3431
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_154_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3406
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3413
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3459
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3460
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3410
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3464
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3302
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3386
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3416
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3426
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3445
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3449
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3450
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3321
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3438
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3454
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3412
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3391
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3298
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3428
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3432
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3465
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3318
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3394
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3405
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3384
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3419
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3447
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3398
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3330
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3463
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3474
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3415
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3423
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3317
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3444
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3397
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3417
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3295
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3404
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3305
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3403
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3453
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3327
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3467
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3469
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3436
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3309
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3401
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3306
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3400
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3308
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_157_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.8 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3455
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Added broadcast_157_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3429
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3314
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3326
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3382
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3310
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3399
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3414
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3299
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3297
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3392
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3329
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3312
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3435
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3439
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3448
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3383
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3458
2020-05-19 05:25:55 INFO  SparkContext:54 - Created broadcast 157 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3388
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3472
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3433
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3409
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3466
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3408
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3430
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3390
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3393
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3468
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3443
2020-05-19 05:25:55 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7375a177. The input RDD has 10 partitions.
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_152_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3300
2020-05-19 05:25:55 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Registering RDD 591 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Got job 78 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Final stage: ResultStage 79 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 78)
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 78)
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 78 (MapPartitionsRDD[591] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_155_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_158 stored as values in memory (estimated size 39.1 KB, free 364.1 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3437
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3462
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3402
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3324
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3313
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3440
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3301
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3387
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3420
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3303
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3316
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3322
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3389
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3457
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3311
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3418
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3434
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3407
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3396
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3422
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned shuffle 38
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_149_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_158_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.4 MB)
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Added broadcast_158_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_153_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3442
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3451
2020-05-19 05:25:55 INFO  SparkContext:54 - Created broadcast 158 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3319
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3320
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3304
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3307
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[591] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:55 INFO  TaskSchedulerImpl:54 - Adding task set 78.0 with 2 tasks
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 78.0 (TID 468, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 1.0 in stage 78.0 (TID 469, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 1.0 in stage 78.0 (TID 469)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 0.0 in stage 78.0 (TID 468)
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Removed broadcast_148_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:55 INFO  KafkaSourceRDD:54 - Beginning offset 3248 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:25:55 INFO  ContextCleaner:54 - Cleaned accumulator 3461
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 1.0 in stage 78.0 (TID 469). 2074 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 78.0 (TID 469) in 29 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 0.0 in stage 78.0 (TID 468). 2203 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 78.0 (TID 468) in 32 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:55 INFO  TaskSchedulerImpl:54 - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2020-05-19 05:25:55 INFO  DAGScheduler:54 - ShuffleMapStage 78 (start at NativeMethodAccessorImpl.java:0) finished in 0.040 s
2020-05-19 05:25:55 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:55 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:55 INFO  DAGScheduler:54 - waiting: Set(ResultStage 79)
2020-05-19 05:25:55 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Submitting ResultStage 79 (MapPartitionsRDD[597] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_159 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:25:55 INFO  MemoryStore:54 - Block broadcast_159_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:25:55 INFO  BlockManagerInfo:54 - Added broadcast_159_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:25:55 INFO  SparkContext:54 - Created broadcast 159 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:55 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 79 (MapPartitionsRDD[597] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:55 INFO  TaskSchedulerImpl:54 - Adding task set 79.0 with 10 tasks
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 79.0 (TID 470, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 1.0 in stage 79.0 (TID 471, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 0.0 in stage 79.0 (TID 470)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 1.0 in stage 79.0 (TID 471)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1e2421
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4335683c
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3267cb2e
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fc9442d
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/40.delta
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 1.0 in stage 79.0 (TID 471). 33265 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 2.0 in stage 79.0 (TID 472, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 79.0 (TID 471) in 112 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 2.0 in stage 79.0 (TID 472)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2659f3a4
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51878f22
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 0.0 in stage 79.0 (TID 470). 34359 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 3.0 in stage 79.0 (TID 473, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 3.0 in stage 79.0 (TID 473)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 79.0 (TID 470) in 133 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e806add
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15a99712
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 2.0 in stage 79.0 (TID 472). 34915 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 4.0 in stage 79.0 (TID 474, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 2.0 in stage 79.0 (TID 472) in 108 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 4.0 in stage 79.0 (TID 474)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@416139aa
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40cf6903
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 3.0 in stage 79.0 (TID 473). 36118 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 5.0 in stage 79.0 (TID 475, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 3.0 in stage 79.0 (TID 473) in 122 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 5.0 in stage 79.0 (TID 475)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34277ff4
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b02933
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/40.delta
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 5.0 in stage 79.0 (TID 475). 38041 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 6.0 in stage 79.0 (TID 476, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 6.0 in stage 79.0 (TID 476)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@284c70de
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f3f688
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 5.0 in stage 79.0 (TID 475) in 87 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 4.0 in stage 79.0 (TID 474). 36032 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 7.0 in stage 79.0 (TID 477, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 4.0 in stage 79.0 (TID 474) in 147 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 7.0 in stage 79.0 (TID 477)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@583df54e
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7321c6e5
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/40.delta
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:55 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 6.0 in stage 79.0 (TID 476). 38936 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 8.0 in stage 79.0 (TID 478, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 6.0 in stage 79.0 (TID 476) in 123 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 8.0 in stage 79.0 (TID 478)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a9b5958
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@778c58
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:55 INFO  Executor:54 - Finished task 7.0 in stage 79.0 (TID 477). 36299 bytes result sent to driver
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Starting task 9.0 in stage 79.0 (TID 479, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/40.delta
2020-05-19 05:25:55 INFO  TaskSetManager:54 - Finished task 7.0 in stage 79.0 (TID 477) in 162 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:55 INFO  Executor:54 - Running task 9.0 in stage 79.0 (TID 479)
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1305fb61
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:55 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:55 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:55 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@766dee92
2020-05-19 05:25:55 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:55 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 39 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:56 INFO  Executor:54 - Finished task 8.0 in stage 79.0 (TID 478). 35254 bytes result sent to driver
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Finished task 8.0 in stage 79.0 (TID 478) in 116 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 40 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/40.delta
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 40 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:56 INFO  Executor:54 - Finished task 9.0 in stage 79.0 (TID 479). 34810 bytes result sent to driver
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Finished task 9.0 in stage 79.0 (TID 479) in 108 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2020-05-19 05:25:56 INFO  DAGScheduler:54 - ResultStage 79 (start at NativeMethodAccessorImpl.java:0) finished in 0.643 s
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Job 78 finished: start at NativeMethodAccessorImpl.java:0, took 0.695518 s
2020-05-19 05:25:56 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7375a177 is committing.
-------------------------------------------
Batch: 39
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:56 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7375a177 committed.
2020-05-19 05:25:56 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Job 79 finished: start at NativeMethodAccessorImpl.java:0, took 0.000052 s
2020-05-19 05:25:56 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:54.996Z",
  "batchId" : 39,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6983240223463687,
  "processedRowsPerSecond" : 0.7418397626112759,
  "durationMs" : {
    "addBatch" : 1214,
    "getBatch" : 6,
    "getOffset" : 8,
    "queryPlanning" : 46,
    "triggerExecution" : 1348,
    "walCommit" : 71
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:51:00.000Z",
    "max" : "2018-12-28T16:51:00.000Z",
    "min" : "2018-12-28T16:51:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2832,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3248,
        "0" : 3146
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3248,
        "0" : 3147
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6983240223463687,
    "processedRowsPerSecond" : 0.7418397626112759
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:56 INFO  MicroBatchExecution:54 - Committed offsets for batch 40. Metadata OffsetSeqMetadata(1546297020000,1589865956442,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:56 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3248,"0":3147}}), end = {"department.police.service.call":{"1":3249,"0":3148}}
2020-05-19 05:25:56 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:56 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3147,3148,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3248,3249,None)
2020-05-19 05:25:56 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:56 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:56 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_160 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_160_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:25:56 INFO  BlockManagerInfo:54 - Added broadcast_160_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:56 INFO  SparkContext:54 - Created broadcast 160 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_161 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_161_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:25:56 INFO  BlockManagerInfo:54 - Added broadcast_161_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:56 INFO  SparkContext:54 - Created broadcast 161 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:56 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@75fc750e. The input RDD has 10 partitions.
2020-05-19 05:25:56 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Registering RDD 606 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Got job 80 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Final stage: ResultStage 81 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 80)
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 80)
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 80 (MapPartitionsRDD[606] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_162 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_162_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:56 INFO  BlockManagerInfo:54 - Added broadcast_162_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:56 INFO  SparkContext:54 - Created broadcast 162 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[606] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:56 INFO  TaskSchedulerImpl:54 - Adding task set 80.0 with 2 tasks
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 80.0 (TID 480, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Starting task 1.0 in stage 80.0 (TID 481, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:56 INFO  Executor:54 - Running task 1.0 in stage 80.0 (TID 481)
2020-05-19 05:25:56 INFO  Executor:54 - Running task 0.0 in stage 80.0 (TID 480)
2020-05-19 05:25:56 INFO  Executor:54 - Finished task 1.0 in stage 80.0 (TID 481). 2203 bytes result sent to driver
2020-05-19 05:25:56 INFO  Executor:54 - Finished task 0.0 in stage 80.0 (TID 480). 2203 bytes result sent to driver
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Finished task 1.0 in stage 80.0 (TID 481) in 39 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 80.0 (TID 480) in 40 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2020-05-19 05:25:56 INFO  DAGScheduler:54 - ShuffleMapStage 80 (start at NativeMethodAccessorImpl.java:0) finished in 0.046 s
2020-05-19 05:25:56 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:56 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 81)
2020-05-19 05:25:56 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Submitting ResultStage 81 (MapPartitionsRDD[612] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_163 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:25:56 INFO  MemoryStore:54 - Block broadcast_163_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:25:56 INFO  BlockManagerInfo:54 - Added broadcast_163_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:56 INFO  SparkContext:54 - Created broadcast 163 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:56 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 81 (MapPartitionsRDD[612] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:56 INFO  TaskSchedulerImpl:54 - Adding task set 81.0 with 10 tasks
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 81.0 (TID 482, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Starting task 1.0 in stage 81.0 (TID 483, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:56 INFO  Executor:54 - Running task 1.0 in stage 81.0 (TID 483)
2020-05-19 05:25:56 INFO  Executor:54 - Running task 0.0 in stage 81.0 (TID 482)
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f599d40
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b1f6a29
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@785842ee
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d3755dc
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/41.delta
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/41.delta
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:56 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:56 INFO  Executor:54 - Finished task 0.0 in stage 81.0 (TID 482). 34359 bytes result sent to driver
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Starting task 2.0 in stage 81.0 (TID 484, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:56 INFO  Executor:54 - Running task 2.0 in stage 81.0 (TID 484)
2020-05-19 05:25:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 81.0 (TID 482) in 187 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d8b102a
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:56 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:56 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:56 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62c06f26
2020-05-19 05:25:56 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:56 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 1.0 in stage 81.0 (TID 483). 33375 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 3.0 in stage 81.0 (TID 485, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 3.0 in stage 81.0 (TID 485)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 1.0 in stage 81.0 (TID 483) in 238 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1540459a
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ead31de
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 2.0 in stage 81.0 (TID 484). 35015 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 4.0 in stage 81.0 (TID 486, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 2.0 in stage 81.0 (TID 484) in 173 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 4.0 in stage 81.0 (TID 486)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ceed1c8
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a3a9e9e
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 3.0 in stage 81.0 (TID 485). 36118 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 5.0 in stage 81.0 (TID 487, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 3.0 in stage 81.0 (TID 485) in 137 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 5.0 in stage 81.0 (TID 487)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@367bd8b1
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@616399b0
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 4.0 in stage 81.0 (TID 486). 36032 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 6.0 in stage 81.0 (TID 488, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 6.0 in stage 81.0 (TID 488)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 4.0 in stage 81.0 (TID 486) in 119 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@619bf3ec
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc671b8
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 5.0 in stage 81.0 (TID 487). 38041 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 7.0 in stage 81.0 (TID 489, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 5.0 in stage 81.0 (TID 487) in 123 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 7.0 in stage 81.0 (TID 489)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@528a5b5c
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4edf7512
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 6.0 in stage 81.0 (TID 488). 38936 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 8.0 in stage 81.0 (TID 490, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 6.0 in stage 81.0 (TID 488) in 145 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 8.0 in stage 81.0 (TID 490)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2956092
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31775769
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 7.0 in stage 81.0 (TID 489). 36299 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Starting task 9.0 in stage 81.0 (TID 491, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:57 INFO  Executor:54 - Running task 9.0 in stage 81.0 (TID 491)
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 7.0 in stage 81.0 (TID 489) in 156 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50b64ca0
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:57 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:57 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:57 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@313a1dcd
2020-05-19 05:25:57 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 40 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3551
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3520
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3486
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3493
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3542
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3547
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3490
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3555
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3512
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3473
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3500
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3530
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3550
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3509
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3523
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3549
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3514
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3521
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3480
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned shuffle 39
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3502
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3540
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3511
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3546
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3557
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3478
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3554
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3481
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3483
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3529
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3516
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3541
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3495
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3556
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3501
2020-05-19 05:25:57 INFO  BlockManagerInfo:54 - Removed broadcast_157_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3498
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3497
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3561
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3534
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3548
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3532
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3477
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3485
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3545
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3475
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3539
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3518
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3526
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3503
2020-05-19 05:25:57 INFO  BlockManagerInfo:54 - Removed broadcast_158_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3543
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3517
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3488
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3515
2020-05-19 05:25:57 INFO  BlockManagerInfo:54 - Removed broadcast_162_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3513
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3499
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3531
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3536
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3479
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3538
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3527
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3491
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3487
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3553
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3494
2020-05-19 05:25:57 INFO  BlockManagerInfo:54 - Removed broadcast_159_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3559
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3505
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3560
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3489
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3504
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3525
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3552
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3484
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3537
2020-05-19 05:25:57 INFO  BlockManagerInfo:54 - Removed broadcast_156_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3558
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3533
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3506
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3510
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3563
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3535
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3508
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3544
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3522
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3496
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3482
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3519
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3476
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3507
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3528
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3524
2020-05-19 05:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 3492
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 8.0 in stage 81.0 (TID 490). 35297 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 8.0 in stage 81.0 (TID 490) in 182 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Committed version 41 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/41.delta
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:57 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:57 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 41 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:57 INFO  Executor:54 - Finished task 9.0 in stage 81.0 (TID 491). 34853 bytes result sent to driver
2020-05-19 05:25:57 INFO  TaskSetManager:54 - Finished task 9.0 in stage 81.0 (TID 491) in 226 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2020-05-19 05:25:57 INFO  DAGScheduler:54 - ResultStage 81 (start at NativeMethodAccessorImpl.java:0) finished in 0.877 s
2020-05-19 05:25:57 INFO  DAGScheduler:54 - Job 80 finished: start at NativeMethodAccessorImpl.java:0, took 0.929007 s
2020-05-19 05:25:57 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@75fc750e is committing.
-------------------------------------------
Batch: 40
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:57 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@75fc750e committed.
2020-05-19 05:25:57 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:57 INFO  DAGScheduler:54 - Job 81 finished: start at NativeMethodAccessorImpl.java:0, took 0.000043 s
2020-05-19 05:25:57 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:56.434Z",
  "batchId" : 40,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3908205841446455,
  "processedRowsPerSecond" : 1.3458950201884252,
  "durationMs" : {
    "addBatch" : 1387,
    "getBatch" : 4,
    "getOffset" : 8,
    "queryPlanning" : 34,
    "triggerExecution" : 1486,
    "walCommit" : 51
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:50:30.000Z",
    "max" : "2018-12-28T16:51:00.000Z",
    "min" : "2018-12-28T16:50:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2834,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3248,
        "0" : 3147
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3249,
        "0" : 3148
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3908205841446455,
    "processedRowsPerSecond" : 1.3458950201884252
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:58 INFO  MicroBatchExecution:54 - Committed offsets for batch 41. Metadata OffsetSeqMetadata(1546297020000,1589865957970,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:58 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3249,"0":3148}}), end = {"department.police.service.call":{"1":3250,"0":3148}}
2020-05-19 05:25:58 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:58 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3148,3148,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3249,3250,None)
2020-05-19 05:25:58 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:58 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:58 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_164 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_164_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:25:58 INFO  BlockManagerInfo:54 - Added broadcast_164_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:58 INFO  SparkContext:54 - Created broadcast 164 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_165 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_165_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:25:58 INFO  BlockManagerInfo:54 - Added broadcast_165_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:58 INFO  SparkContext:54 - Created broadcast 165 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:58 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@72b157af. The input RDD has 10 partitions.
2020-05-19 05:25:58 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Registering RDD 621 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Got job 82 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Final stage: ResultStage 83 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 82)
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 82)
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 82 (MapPartitionsRDD[621] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_166 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_166_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:25:58 INFO  BlockManagerInfo:54 - Added broadcast_166_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:58 INFO  SparkContext:54 - Created broadcast 166 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[621] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:25:58 INFO  TaskSchedulerImpl:54 - Adding task set 82.0 with 2 tasks
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 0.0 in stage 82.0 (TID 492, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 1.0 in stage 82.0 (TID 493, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 0.0 in stage 82.0 (TID 492)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 1.0 in stage 82.0 (TID 493)
2020-05-19 05:25:58 INFO  KafkaSourceRDD:54 - Beginning offset 3148 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 0.0 in stage 82.0 (TID 492). 2117 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 82.0 (TID 492) in 27 ms on localhost (executor driver) (1/2)
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 1.0 in stage 82.0 (TID 493). 2203 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 1.0 in stage 82.0 (TID 493) in 33 ms on localhost (executor driver) (2/2)
2020-05-19 05:25:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2020-05-19 05:25:58 INFO  DAGScheduler:54 - ShuffleMapStage 82 (start at NativeMethodAccessorImpl.java:0) finished in 0.038 s
2020-05-19 05:25:58 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:25:58 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:25:58 INFO  DAGScheduler:54 - waiting: Set(ResultStage 83)
2020-05-19 05:25:58 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Submitting ResultStage 83 (MapPartitionsRDD[627] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_167 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:25:58 INFO  MemoryStore:54 - Block broadcast_167_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:25:58 INFO  BlockManagerInfo:54 - Added broadcast_167_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:25:58 INFO  SparkContext:54 - Created broadcast 167 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 83 (MapPartitionsRDD[627] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:25:58 INFO  TaskSchedulerImpl:54 - Adding task set 83.0 with 10 tasks
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 0.0 in stage 83.0 (TID 494, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 1.0 in stage 83.0 (TID 495, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 0.0 in stage 83.0 (TID 494)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 1.0 in stage 83.0 (TID 495)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@744d190
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@446c95d6
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc17a8d
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75f79ba9
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/42.delta
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 0.0 in stage 83.0 (TID 494). 34359 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 2.0 in stage 83.0 (TID 496, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 2.0 in stage 83.0 (TID 496)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 83.0 (TID 494) in 133 ms on localhost (executor driver) (1/10)
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 1.0 in stage 83.0 (TID 495). 33472 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 3.0 in stage 83.0 (TID 497, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 3.0 in stage 83.0 (TID 497)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 1.0 in stage 83.0 (TID 495) in 136 ms on localhost (executor driver) (2/10)
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74603671
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d6e9ed1
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28768541
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18a44e2e
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 3.0 in stage 83.0 (TID 497). 36118 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 4.0 in stage 83.0 (TID 498, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 3.0 in stage 83.0 (TID 497) in 111 ms on localhost (executor driver) (3/10)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 4.0 in stage 83.0 (TID 498)
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 2.0 in stage 83.0 (TID 496). 35015 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 5.0 in stage 83.0 (TID 499, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 5.0 in stage 83.0 (TID 499)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 2.0 in stage 83.0 (TID 496) in 123 ms on localhost (executor driver) (4/10)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e96822c
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@80fab89
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66e91c73
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bdc47d6
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 5.0 in stage 83.0 (TID 499). 38041 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 6.0 in stage 83.0 (TID 500, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 6.0 in stage 83.0 (TID 500)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f846b58
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 5.0 in stage 83.0 (TID 499) in 115 ms on localhost (executor driver) (5/10)
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74fce10
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 4.0 in stage 83.0 (TID 498). 36032 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 7.0 in stage 83.0 (TID 501, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 7.0 in stage 83.0 (TID 501)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 4.0 in stage 83.0 (TID 498) in 133 ms on localhost (executor driver) (6/10)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@953a9a8
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32f72d4
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 6.0 in stage 83.0 (TID 500). 38936 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 8.0 in stage 83.0 (TID 502, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 8.0 in stage 83.0 (TID 502)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 6.0 in stage 83.0 (TID 500) in 125 ms on localhost (executor driver) (7/10)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b90bb42
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@677b921e
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 7.0 in stage 83.0 (TID 501). 36299 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Starting task 9.0 in stage 83.0 (TID 503, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 7.0 in stage 83.0 (TID 501) in 119 ms on localhost (executor driver) (8/10)
2020-05-19 05:25:58 INFO  Executor:54 - Running task 9.0 in stage 83.0 (TID 503)
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38b15afc
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:58 INFO  StateStore:54 - Env is not null
2020-05-19 05:25:58 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:25:58 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f72a6f0
2020-05-19 05:25:58 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 41 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:25:58 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Committed version 42 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/42.delta
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:25:58 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 9.0 in stage 83.0 (TID 503). 34810 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 9.0 in stage 83.0 (TID 503) in 130 ms on localhost (executor driver) (9/10)
2020-05-19 05:25:58 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 42 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:25:58 INFO  Executor:54 - Finished task 8.0 in stage 83.0 (TID 502). 35254 bytes result sent to driver
2020-05-19 05:25:58 INFO  TaskSetManager:54 - Finished task 8.0 in stage 83.0 (TID 502) in 153 ms on localhost (executor driver) (10/10)
2020-05-19 05:25:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2020-05-19 05:25:58 INFO  DAGScheduler:54 - ResultStage 83 (start at NativeMethodAccessorImpl.java:0) finished in 0.638 s
2020-05-19 05:25:58 INFO  DAGScheduler:54 - Job 82 finished: start at NativeMethodAccessorImpl.java:0, took 0.682603 s
2020-05-19 05:25:58 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@72b157af is committing.
-------------------------------------------
Batch: 41
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:25:59 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@72b157af committed.
2020-05-19 05:25:59 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Job 83 finished: start at NativeMethodAccessorImpl.java:0, took 0.000040 s
2020-05-19 05:25:59 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:57.968Z",
  "batchId" : 41,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.651890482398957,
  "processedRowsPerSecond" : 0.7751937984496123,
  "durationMs" : {
    "addBatch" : 1157,
    "getBatch" : 7,
    "getOffset" : 2,
    "queryPlanning" : 62,
    "triggerExecution" : 1290,
    "walCommit" : 61
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:49:00.000Z",
    "max" : "2018-12-28T16:49:00.000Z",
    "min" : "2018-12-28T16:49:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2835,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3249,
        "0" : 3148
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3250,
        "0" : 3148
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.651890482398957,
    "processedRowsPerSecond" : 0.7751937984496123
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:25:59 INFO  MicroBatchExecution:54 - Committed offsets for batch 42. Metadata OffsetSeqMetadata(1546297020000,1589865959305,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:25:59 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3250,"0":3148}}), end = {"department.police.service.call":{"1":3250,"0":3149}}
2020-05-19 05:25:59 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:25:59 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3148,3149,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3250,3250,None)
2020-05-19 05:25:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:59 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:25:59 INFO  MemoryStore:54 - Block broadcast_168 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:25:59 INFO  MemoryStore:54 - Block broadcast_168_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:25:59 INFO  BlockManagerInfo:54 - Added broadcast_168_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:59 INFO  SparkContext:54 - Created broadcast 168 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:59 INFO  MemoryStore:54 - Block broadcast_169 stored as values in memory (estimated size 281.8 KB, free 363.7 MB)
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3665
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3706
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3704
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3735
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3586
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3636
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3699
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3606
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3655
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3689
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3713
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3585
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3628
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3601
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3611
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3580
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3578
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3614
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3737
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3738
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3634
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3681
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned shuffle 40
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3732
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3694
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3702
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3712
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3625
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3630
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3703
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3710
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3618
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3687
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3734
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3590
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3591
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3660
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3620
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3668
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3588
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3682
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3673
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3644
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3654
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3567
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3573
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3731
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3645
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3701
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3642
2020-05-19 05:25:59 INFO  MemoryStore:54 - Block broadcast_169_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
2020-05-19 05:25:59 INFO  BlockManagerInfo:54 - Removed broadcast_164_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:59 INFO  BlockManagerInfo:54 - Added broadcast_169_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3714
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3721
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3709
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3572
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3579
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3584
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3594
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3641
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3726
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3570
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3612
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3613
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3697
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3711
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3663
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3705
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3624
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3679
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3674
2020-05-19 05:25:59 INFO  SparkContext:54 - Created broadcast 169 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:59 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7d95f027. The input RDD has 10 partitions.
2020-05-19 05:25:59 INFO  BlockManagerInfo:54 - Removed broadcast_166_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3667
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3728
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3649
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3676
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3730
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3640
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3717
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3678
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3720
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3725
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3635
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3664
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3602
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3581
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3672
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3722
2020-05-19 05:25:59 INFO  BlockManagerInfo:54 - Removed broadcast_165_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3575
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3566
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3643
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3598
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3653
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3648
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3631
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3562
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3607
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3603
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3700
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3708
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3707
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3597
2020-05-19 05:25:59 INFO  ContextCleaner:54 - Cleaned accumulator 3657
2020-05-19 05:25:59 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Registering RDD 636 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Got job 84 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Final stage: ResultStage 85 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 84)
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 84)
2020-05-19 05:25:59 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 84 (MapPartitionsRDD[636] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:00 INFO  MemoryStore:54 - Block broadcast_170 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Removed broadcast_163_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3568
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3629
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3595
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned shuffle 41
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3609
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3593
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3695
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3564
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3724
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3650
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3582
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3569
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3652
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3729
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3637
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3718
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3615
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3693
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3646
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3608
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3736
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3632
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3574
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3647
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3715
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3599
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3675
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3605
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3622
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3739
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3639
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3633
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3600
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3662
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3691
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3690
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3627
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3604
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3684
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3589
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Removed broadcast_161_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:00 INFO  MemoryStore:54 - Block broadcast_170_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.6 MB)
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3596
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3670
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3616
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3577
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3680
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3626
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3587
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3696
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3619
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3716
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3685
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3686
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Added broadcast_170_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Removed broadcast_167_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:00 INFO  SparkContext:54 - Created broadcast 170 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:00 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[636] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:00 INFO  TaskSchedulerImpl:54 - Adding task set 84.0 with 2 tasks
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3623
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3576
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3658
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3610
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3651
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3583
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3659
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3719
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3677
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3692
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3683
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3666
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3688
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3671
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3565
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3723
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3733
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3656
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3621
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3592
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3727
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3698
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3617
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3741
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3669
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3571
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 84.0 (TID 504, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 84.0 (TID 505, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 0.0 in stage 84.0 (TID 504)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 1.0 in stage 84.0 (TID 505)
2020-05-19 05:26:00 INFO  KafkaSourceRDD:54 - Beginning offset 3250 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Removed broadcast_160_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3638
2020-05-19 05:26:00 INFO  ContextCleaner:54 - Cleaned accumulator 3661
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 1.0 in stage 84.0 (TID 505). 2074 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 84.0 (TID 505) in 22 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 0.0 in stage 84.0 (TID 504). 2203 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 84.0 (TID 504) in 39 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2020-05-19 05:26:00 INFO  DAGScheduler:54 - ShuffleMapStage 84 (start at NativeMethodAccessorImpl.java:0) finished in 0.053 s
2020-05-19 05:26:00 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:00 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:00 INFO  DAGScheduler:54 - waiting: Set(ResultStage 85)
2020-05-19 05:26:00 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:00 INFO  DAGScheduler:54 - Submitting ResultStage 85 (MapPartitionsRDD[642] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:00 INFO  MemoryStore:54 - Block broadcast_171 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:26:00 INFO  MemoryStore:54 - Block broadcast_171_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:26:00 INFO  BlockManagerInfo:54 - Added broadcast_171_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:00 INFO  SparkContext:54 - Created broadcast 171 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:00 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 85 (MapPartitionsRDD[642] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:00 INFO  TaskSchedulerImpl:54 - Adding task set 85.0 with 10 tasks
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 85.0 (TID 506, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 85.0 (TID 507, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 1.0 in stage 85.0 (TID 507)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 0.0 in stage 85.0 (TID 506)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69aaed8a
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24590229
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42fdcfe9
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d207a2
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/43.delta
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 1.0 in stage 85.0 (TID 507). 33577 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 85.0 (TID 508, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 2.0 in stage 85.0 (TID 508)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 85.0 (TID 507) in 135 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@521d07a6
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76d654fc
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 0.0 in stage 85.0 (TID 506). 34359 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 3.0 in stage 85.0 (TID 509, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 85.0 (TID 506) in 164 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 3.0 in stage 85.0 (TID 509)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@da98efa
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3079acdd
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/43.delta
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 3.0 in stage 85.0 (TID 509). 36118 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 4.0 in stage 85.0 (TID 510, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 4.0 in stage 85.0 (TID 510)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 3.0 in stage 85.0 (TID 509) in 85 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93b255d
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@719bb94d
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 2.0 in stage 85.0 (TID 508). 35015 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 5.0 in stage 85.0 (TID 511, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 85.0 (TID 508) in 170 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 5.0 in stage 85.0 (TID 511)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65081c70
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ff965df
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 4.0 in stage 85.0 (TID 510). 36032 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 6.0 in stage 85.0 (TID 512, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 6.0 in stage 85.0 (TID 512)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1277c16d
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 4.0 in stage 85.0 (TID 510) in 134 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22a70408
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 5.0 in stage 85.0 (TID 511). 38041 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 7.0 in stage 85.0 (TID 513, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 7.0 in stage 85.0 (TID 513)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 5.0 in stage 85.0 (TID 511) in 106 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aa3ba46
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23ee43a0
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 6.0 in stage 85.0 (TID 512). 38936 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 8.0 in stage 85.0 (TID 514, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 8.0 in stage 85.0 (TID 514)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 6.0 in stage 85.0 (TID 512) in 158 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c52e3e7
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38843afe
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 7.0 in stage 85.0 (TID 513). 36299 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Starting task 9.0 in stage 85.0 (TID 515, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 7.0 in stage 85.0 (TID 513) in 146 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:00 INFO  Executor:54 - Running task 9.0 in stage 85.0 (TID 515)
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a3bc641
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:00 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:00 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:00 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c97fd22
2020-05-19 05:26:00 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 42 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Committed version 43 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/43.delta
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:00 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 8.0 in stage 85.0 (TID 514). 35254 bytes result sent to driver
2020-05-19 05:26:00 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 43 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 8.0 in stage 85.0 (TID 514) in 146 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:00 INFO  Executor:54 - Finished task 9.0 in stage 85.0 (TID 515). 34810 bytes result sent to driver
2020-05-19 05:26:00 INFO  TaskSetManager:54 - Finished task 9.0 in stage 85.0 (TID 515) in 128 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2020-05-19 05:26:00 INFO  DAGScheduler:54 - ResultStage 85 (start at NativeMethodAccessorImpl.java:0) finished in 0.688 s
2020-05-19 05:26:00 INFO  DAGScheduler:54 - Job 84 finished: start at NativeMethodAccessorImpl.java:0, took 0.746517 s
2020-05-19 05:26:00 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7d95f027 is committing.
-------------------------------------------
Batch: 42
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:00 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7d95f027 committed.
2020-05-19 05:26:00 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:00 INFO  DAGScheduler:54 - Job 85 finished: start at NativeMethodAccessorImpl.java:0, took 0.000051 s
2020-05-19 05:26:01 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:25:59.302Z",
  "batchId" : 42,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.7496251874062968,
  "processedRowsPerSecond" : 0.5889281507656066,
  "durationMs" : {
    "addBatch" : 1422,
    "getBatch" : 6,
    "getOffset" : 3,
    "queryPlanning" : 129,
    "triggerExecution" : 1698,
    "walCommit" : 135
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:49:00.000Z",
    "max" : "2018-12-28T16:49:00.000Z",
    "min" : "2018-12-28T16:49:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2836,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3250,
        "0" : 3148
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3250,
        "0" : 3149
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.7496251874062968,
    "processedRowsPerSecond" : 0.5889281507656066
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:01 INFO  MicroBatchExecution:54 - Committed offsets for batch 43. Metadata OffsetSeqMetadata(1546297020000,1589865961173,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:01 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3250,"0":3149}}), end = {"department.police.service.call":{"1":3251,"0":3150}}
2020-05-19 05:26:01 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:01 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3149,3150,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3250,3251,None)
2020-05-19 05:26:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:01 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_172 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_172_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:01 INFO  BlockManagerInfo:54 - Added broadcast_172_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:01 INFO  SparkContext:54 - Created broadcast 172 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_173 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_173_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:01 INFO  BlockManagerInfo:54 - Added broadcast_173_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:01 INFO  SparkContext:54 - Created broadcast 173 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:01 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5003e738. The input RDD has 10 partitions.
2020-05-19 05:26:01 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Registering RDD 651 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Got job 86 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Final stage: ResultStage 87 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 86)
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 86)
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 86 (MapPartitionsRDD[651] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_174 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_174_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:01 INFO  BlockManagerInfo:54 - Added broadcast_174_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:01 INFO  SparkContext:54 - Created broadcast 174 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[651] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:01 INFO  TaskSchedulerImpl:54 - Adding task set 86.0 with 2 tasks
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 86.0 (TID 516, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 86.0 (TID 517, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:01 INFO  Executor:54 - Running task 0.0 in stage 86.0 (TID 516)
2020-05-19 05:26:01 INFO  Executor:54 - Running task 1.0 in stage 86.0 (TID 517)
2020-05-19 05:26:01 INFO  Executor:54 - Finished task 1.0 in stage 86.0 (TID 517). 2203 bytes result sent to driver
2020-05-19 05:26:01 INFO  Executor:54 - Finished task 0.0 in stage 86.0 (TID 516). 2203 bytes result sent to driver
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Finished task 1.0 in stage 86.0 (TID 517) in 42 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 86.0 (TID 516) in 44 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2020-05-19 05:26:01 INFO  DAGScheduler:54 - ShuffleMapStage 86 (start at NativeMethodAccessorImpl.java:0) finished in 0.050 s
2020-05-19 05:26:01 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:01 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:01 INFO  DAGScheduler:54 - waiting: Set(ResultStage 87)
2020-05-19 05:26:01 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Submitting ResultStage 87 (MapPartitionsRDD[657] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_175 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:01 INFO  MemoryStore:54 - Block broadcast_175_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:01 INFO  BlockManagerInfo:54 - Added broadcast_175_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:01 INFO  SparkContext:54 - Created broadcast 175 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:01 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 87 (MapPartitionsRDD[657] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:01 INFO  TaskSchedulerImpl:54 - Adding task set 87.0 with 10 tasks
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 87.0 (TID 518, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 87.0 (TID 519, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:01 INFO  Executor:54 - Running task 0.0 in stage 87.0 (TID 518)
2020-05-19 05:26:01 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:01 INFO  Executor:54 - Running task 1.0 in stage 87.0 (TID 519)
2020-05-19 05:26:01 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:01 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75f9ca88
2020-05-19 05:26:01 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:01 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:01 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:01 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:01 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38839e94
2020-05-19 05:26:01 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:01 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:01 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:01 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9915bf6
2020-05-19 05:26:01 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:01 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:01 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:01 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:01 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d84aab8
2020-05-19 05:26:01 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:01 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:01 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:26:01 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:01 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:01 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:01 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 0.0 in stage 87.0 (TID 518). 34359 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 87.0 (TID 520, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 87.0 (TID 518) in 144 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 2.0 in stage 87.0 (TID 520)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f801d6
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 1.0 in stage 87.0 (TID 519). 33577 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 3.0 in stage 87.0 (TID 521, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 3.0 in stage 87.0 (TID 521)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 87.0 (TID 519) in 174 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@295a5543
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65bd8d14
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64c9b331
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 3.0 in stage 87.0 (TID 521). 36118 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 4.0 in stage 87.0 (TID 522, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 4.0 in stage 87.0 (TID 522)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 3.0 in stage 87.0 (TID 521) in 115 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ad811e
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aaa728f
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 2.0 in stage 87.0 (TID 520). 35015 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 5.0 in stage 87.0 (TID 523, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 5.0 in stage 87.0 (TID 523)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 87.0 (TID 520) in 184 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33271264
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@587af722
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 4.0 in stage 87.0 (TID 522). 36032 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 6.0 in stage 87.0 (TID 524, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 6.0 in stage 87.0 (TID 524)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 4.0 in stage 87.0 (TID 522) in 100 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@669ae5c8
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12df0768
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 5.0 in stage 87.0 (TID 523). 38041 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 7.0 in stage 87.0 (TID 525, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 5.0 in stage 87.0 (TID 523) in 168 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 7.0 in stage 87.0 (TID 525)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9b6cc01
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e2b5dd
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 6.0 in stage 87.0 (TID 524). 38936 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 8.0 in stage 87.0 (TID 526, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 8.0 in stage 87.0 (TID 526)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 6.0 in stage 87.0 (TID 524) in 140 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@977fcaa
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@280ce47
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 7.0 in stage 87.0 (TID 525). 36299 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Starting task 9.0 in stage 87.0 (TID 527, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 7.0 in stage 87.0 (TID 525) in 110 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:02 INFO  Executor:54 - Running task 9.0 in stage 87.0 (TID 527)
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234f91c4
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:02 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:02 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:02 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20e060c0
2020-05-19 05:26:02 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 43 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 8.0 in stage 87.0 (TID 526). 35254 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 8.0 in stage 87.0 (TID 526) in 134 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Committed version 44 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/44.delta
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:02 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3823
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3798
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3802
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3812
2020-05-19 05:26:02 INFO  BlockManagerInfo:54 - Removed broadcast_169_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3793
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3810
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3743
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3751
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3781
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3786
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3805
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3808
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3764
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3819
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3796
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3807
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3765
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3753
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3766
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3754
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3815
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3758
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3761
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3811
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3776
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3774
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3768
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3763
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3822
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3789
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3792
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3769
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3825
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3814
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3750
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3797
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3804
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3824
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3749
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3778
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3777
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3772
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3782
2020-05-19 05:26:02 INFO  BlockManagerInfo:54 - Removed broadcast_170_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3783
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3809
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3755
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3801
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3742
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3759
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3818
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3803
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3785
2020-05-19 05:26:02 INFO  BlockManagerInfo:54 - Removed broadcast_174_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3752
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3744
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3747
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3800
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3740
2020-05-19 05:26:02 INFO  BlockManagerInfo:54 - Removed broadcast_171_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3762
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3827
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3791
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3756
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3806
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3794
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3799
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3767
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3745
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3775
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3770
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3817
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3773
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3788
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3746
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3779
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3828
2020-05-19 05:26:02 INFO  BlockManagerInfo:54 - Removed broadcast_168_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3784
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3820
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3780
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3816
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3813
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3821
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned shuffle 42
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3771
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3757
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3787
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3748
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3826
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3760
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3790
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3830
2020-05-19 05:26:02 INFO  ContextCleaner:54 - Cleaned accumulator 3795
2020-05-19 05:26:02 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 44 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:02 INFO  Executor:54 - Finished task 9.0 in stage 87.0 (TID 527). 34853 bytes result sent to driver
2020-05-19 05:26:02 INFO  TaskSetManager:54 - Finished task 9.0 in stage 87.0 (TID 527) in 152 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2020-05-19 05:26:02 INFO  DAGScheduler:54 - ResultStage 87 (start at NativeMethodAccessorImpl.java:0) finished in 0.757 s
2020-05-19 05:26:02 INFO  DAGScheduler:54 - Job 86 finished: start at NativeMethodAccessorImpl.java:0, took 0.811605 s
2020-05-19 05:26:02 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5003e738 is committing.
-------------------------------------------
Batch: 43
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:02 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5003e738 committed.
2020-05-19 05:26:02 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:02 INFO  DAGScheduler:54 - Job 87 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:26:02 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:01.171Z",
  "batchId" : 43,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0700909577314073,
  "processedRowsPerSecond" : 1.146788990825688,
  "durationMs" : {
    "addBatch" : 1437,
    "getBatch" : 12,
    "getOffset" : 2,
    "queryPlanning" : 137,
    "triggerExecution" : 1744,
    "walCommit" : 156
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:49:00.000Z",
    "max" : "2018-12-28T16:49:00.000Z",
    "min" : "2018-12-28T16:49:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2836,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3250,
        "0" : 3149
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3251,
        "0" : 3150
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0700909577314073,
    "processedRowsPerSecond" : 1.146788990825688
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:03 INFO  MicroBatchExecution:54 - Committed offsets for batch 44. Metadata OffsetSeqMetadata(1546297020000,1589865963004,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:03 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3251,"0":3150}}), end = {"department.police.service.call":{"1":3252,"0":3151}}
2020-05-19 05:26:03 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:03 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3150,3151,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3251,3252,None)
2020-05-19 05:26:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:03 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_176 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_176_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:26:03 INFO  BlockManagerInfo:54 - Added broadcast_176_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:03 INFO  SparkContext:54 - Created broadcast 176 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_177 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_177_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:26:03 INFO  BlockManagerInfo:54 - Added broadcast_177_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:03 INFO  SparkContext:54 - Created broadcast 177 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:03 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@602ec422. The input RDD has 10 partitions.
2020-05-19 05:26:03 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Registering RDD 666 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Got job 88 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Final stage: ResultStage 89 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 88)
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 88)
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 88 (MapPartitionsRDD[666] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_178 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_178_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:03 INFO  BlockManagerInfo:54 - Added broadcast_178_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:03 INFO  SparkContext:54 - Created broadcast 178 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[666] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:03 INFO  TaskSchedulerImpl:54 - Adding task set 88.0 with 2 tasks
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 88.0 (TID 528, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 1.0 in stage 88.0 (TID 529, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 0.0 in stage 88.0 (TID 528)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 1.0 in stage 88.0 (TID 529)
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 1.0 in stage 88.0 (TID 529). 2203 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 1.0 in stage 88.0 (TID 529) in 15 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 0.0 in stage 88.0 (TID 528). 2203 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 88.0 (TID 528) in 20 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2020-05-19 05:26:03 INFO  DAGScheduler:54 - ShuffleMapStage 88 (start at NativeMethodAccessorImpl.java:0) finished in 0.031 s
2020-05-19 05:26:03 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:03 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:03 INFO  DAGScheduler:54 - waiting: Set(ResultStage 89)
2020-05-19 05:26:03 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Submitting ResultStage 89 (MapPartitionsRDD[672] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_179 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:03 INFO  MemoryStore:54 - Block broadcast_179_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:26:03 INFO  BlockManagerInfo:54 - Added broadcast_179_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:03 INFO  SparkContext:54 - Created broadcast 179 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:03 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 89 (MapPartitionsRDD[672] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:03 INFO  TaskSchedulerImpl:54 - Adding task set 89.0 with 10 tasks
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 89.0 (TID 530, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 1.0 in stage 89.0 (TID 531, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 1.0 in stage 89.0 (TID 531)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 0.0 in stage 89.0 (TID 530)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3adea93
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5307ab17
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fcdd4b2
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f269471
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 1.0 in stage 89.0 (TID 531). 33577 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 2.0 in stage 89.0 (TID 532, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 1.0 in stage 89.0 (TID 531) in 120 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 2.0 in stage 89.0 (TID 532)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30e6d875
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29d65e60
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 0.0 in stage 89.0 (TID 530). 34359 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 3.0 in stage 89.0 (TID 533, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 3.0 in stage 89.0 (TID 533)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 89.0 (TID 530) in 159 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@97e72d8
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4264f406
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/45.delta
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 3.0 in stage 89.0 (TID 533). 36118 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 4.0 in stage 89.0 (TID 534, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 4.0 in stage 89.0 (TID 534)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 3.0 in stage 89.0 (TID 533) in 76 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54c2f74f
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3960670c
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 2.0 in stage 89.0 (TID 532). 35015 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 5.0 in stage 89.0 (TID 535, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 5.0 in stage 89.0 (TID 535)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 2.0 in stage 89.0 (TID 532) in 130 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22f126a5
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48a83565
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/45.delta
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 4.0 in stage 89.0 (TID 534). 36032 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 6.0 in stage 89.0 (TID 536, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 6.0 in stage 89.0 (TID 536)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 4.0 in stage 89.0 (TID 534) in 108 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ed50221
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6697196
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 5.0 in stage 89.0 (TID 535). 38041 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 7.0 in stage 89.0 (TID 537, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 7.0 in stage 89.0 (TID 537)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 5.0 in stage 89.0 (TID 535) in 98 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12566876
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@652b4122
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/45.delta
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:03 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 7.0 in stage 89.0 (TID 537). 36299 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 8.0 in stage 89.0 (TID 538, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 8.0 in stage 89.0 (TID 538)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 7.0 in stage 89.0 (TID 537) in 108 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23423674
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234ff3de
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:03 INFO  Executor:54 - Finished task 6.0 in stage 89.0 (TID 536). 38936 bytes result sent to driver
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Starting task 9.0 in stage 89.0 (TID 539, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:03 INFO  Executor:54 - Running task 9.0 in stage 89.0 (TID 539)
2020-05-19 05:26:03 INFO  TaskSetManager:54 - Finished task 6.0 in stage 89.0 (TID 536) in 144 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10cfa8a6
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:03 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:03 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:03 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38c73783
2020-05-19 05:26:03 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:03 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 44 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/45.delta
2020-05-19 05:26:04 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:04 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:04 INFO  HDFSBackedStateStoreProvider:54 - Committed version 45 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/45.delta
2020-05-19 05:26:04 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:04 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:04 INFO  Executor:54 - Finished task 9.0 in stage 89.0 (TID 539). 34810 bytes result sent to driver
2020-05-19 05:26:04 INFO  TaskSetManager:54 - Finished task 9.0 in stage 89.0 (TID 539) in 130 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:04 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 45 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:04 INFO  Executor:54 - Finished task 8.0 in stage 89.0 (TID 538). 35352 bytes result sent to driver
2020-05-19 05:26:04 INFO  TaskSetManager:54 - Finished task 8.0 in stage 89.0 (TID 538) in 178 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2020-05-19 05:26:04 INFO  DAGScheduler:54 - ResultStage 89 (start at NativeMethodAccessorImpl.java:0) finished in 0.639 s
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Job 88 finished: start at NativeMethodAccessorImpl.java:0, took 0.675449 s
2020-05-19 05:26:04 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@602ec422 is committing.
-------------------------------------------
Batch: 44
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:04 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@602ec422 committed.
2020-05-19 05:26:04 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Job 89 finished: start at NativeMethodAccessorImpl.java:0, took 0.000099 s
2020-05-19 05:26:04 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:03.001Z",
  "batchId" : 44,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.0928961748633879,
  "processedRowsPerSecond" : 1.524390243902439,
  "durationMs" : {
    "addBatch" : 1135,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 70,
    "triggerExecution" : 1312,
    "walCommit" : 98
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:48:30.000Z",
    "max" : "2018-12-28T16:49:00.000Z",
    "min" : "2018-12-28T16:48:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2837,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709565
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3251,
        "0" : 3150
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3252,
        "0" : 3151
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.0928961748633879,
    "processedRowsPerSecond" : 1.524390243902439
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:04 INFO  MicroBatchExecution:54 - Committed offsets for batch 45. Metadata OffsetSeqMetadata(1546297020000,1589865964379,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:04 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3252,"0":3151}}), end = {"department.police.service.call":{"1":3253,"0":3152}}
2020-05-19 05:26:04 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:04 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3151,3152,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3252,3253,None)
2020-05-19 05:26:04 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:04 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:04 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_180 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_180_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:26:04 INFO  BlockManagerInfo:54 - Added broadcast_180_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:04 INFO  SparkContext:54 - Created broadcast 180 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_181 stored as values in memory (estimated size 281.8 KB, free 363.7 MB)
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_181_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
2020-05-19 05:26:04 INFO  BlockManagerInfo:54 - Added broadcast_181_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.0 MB)
2020-05-19 05:26:04 INFO  SparkContext:54 - Created broadcast 181 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:04 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@73679639. The input RDD has 10 partitions.
2020-05-19 05:26:04 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Registering RDD 681 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Got job 90 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Final stage: ResultStage 91 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 90)
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 90)
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 90 (MapPartitionsRDD[681] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_182 stored as values in memory (estimated size 39.1 KB, free 363.6 MB)
2020-05-19 05:26:04 INFO  MemoryStore:54 - Block broadcast_182_piece0 stored as bytes in memory (estimated size 15.8 KB, free 363.6 MB)
2020-05-19 05:26:04 INFO  BlockManagerInfo:54 - Added broadcast_182_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.0 MB)
2020-05-19 05:26:04 INFO  SparkContext:54 - Created broadcast 182 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:04 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[681] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:04 INFO  TaskSchedulerImpl:54 - Adding task set 90.0 with 2 tasks
2020-05-19 05:26:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 90.0 (TID 540, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:04 INFO  TaskSetManager:54 - Starting task 1.0 in stage 90.0 (TID 541, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:04 INFO  Executor:54 - Running task 0.0 in stage 90.0 (TID 540)
2020-05-19 05:26:04 INFO  Executor:54 - Running task 1.0 in stage 90.0 (TID 541)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3831
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3851
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3901
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3939
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3846
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3951
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3848
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3954
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3944
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3962
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3965
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned shuffle 44
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3928
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3931
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3988
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3850
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3933
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3867
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3978
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3920
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3934
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3854
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3834
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3869
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3899
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3832
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3923
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3874
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3861
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3865
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_175_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.0 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3877
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3893
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3863
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3882
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3895
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3907
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3986
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3964
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3845
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3881
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4002
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3984
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3853
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3967
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3932
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3886
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3884
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3992
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3900
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_172_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3947
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3936
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3885
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3937
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3918
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3871
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3930
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3935
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3873
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3972
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3924
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3859
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4000
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3916
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3890
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_173_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3887
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3860
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_178_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3927
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3910
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3838
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3970
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3982
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3922
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3883
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3894
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3855
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3837
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3990
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3966
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3987
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_177_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3991
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3840
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3870
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3958
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4006
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3835
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3921
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3898
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3829
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3904
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4005
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3841
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4008
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3911
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3906
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3889
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3836
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3942
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3888
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3979
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3908
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3875
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3925
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3844
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3997
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3977
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4001
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3833
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3993
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3929
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3957
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3892
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3940
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3842
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3876
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3943
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3959
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3948
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3969
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3989
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3976
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3945
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3847
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3952
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3880
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3849
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3983
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3868
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4003
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3857
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 4004
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3968
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3963
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3913
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3996
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3878
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3905
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 1.0 in stage 90.0 (TID 541). 2246 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 1.0 in stage 90.0 (TID 541) in 123 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 0.0 in stage 90.0 (TID 540). 2246 bytes result sent to driver
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned shuffle 43
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3896
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3866
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3980
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3897
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3949
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3975
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3985
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3915
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3858
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 90.0 (TID 540) in 127 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2020-05-19 05:26:05 INFO  DAGScheduler:54 - ShuffleMapStage 90 (start at NativeMethodAccessorImpl.java:0) finished in 0.141 s
2020-05-19 05:26:05 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:05 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:05 INFO  DAGScheduler:54 - waiting: Set(ResultStage 91)
2020-05-19 05:26:05 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:05 INFO  DAGScheduler:54 - Submitting ResultStage 91 (MapPartitionsRDD[687] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:05 INFO  MemoryStore:54 - Block broadcast_183 stored as values in memory (estimated size 54.1 KB, free 364.6 MB)
2020-05-19 05:26:05 INFO  MemoryStore:54 - Block broadcast_183_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.6 MB)
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Added broadcast_183_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_179_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3995
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3879
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3941
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3912
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3955
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3903
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3862
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3971
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3961
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3914
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3926
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3839
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3994
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3852
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3856
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3973
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3891
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3998
2020-05-19 05:26:05 INFO  SparkContext:54 - Created broadcast 183 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:05 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 91 (MapPartitionsRDD[687] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:05 INFO  TaskSchedulerImpl:54 - Adding task set 91.0 with 10 tasks
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3981
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3953
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 91.0 (TID 542, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 1.0 in stage 91.0 (TID 543, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 0.0 in stage 91.0 (TID 542)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 1.0 in stage 91.0 (TID 543)
2020-05-19 05:26:05 INFO  BlockManagerInfo:54 - Removed broadcast_176_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3864
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3843
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3902
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3960
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3974
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3872
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3938
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3950
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3956
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3999
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3919
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3909
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3917
2020-05-19 05:26:05 INFO  ContextCleaner:54 - Cleaned accumulator 3946
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7351bc5e
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f1677e8
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e5d6486
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61da1b4c
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/46.delta
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 0.0 in stage 91.0 (TID 542). 34469 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 2.0 in stage 91.0 (TID 544, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 91.0 (TID 542) in 128 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 2.0 in stage 91.0 (TID 544)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab64f37
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb0dfec
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 1.0 in stage 91.0 (TID 543). 33577 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 3.0 in stage 91.0 (TID 545, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 3.0 in stage 91.0 (TID 545)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 1.0 in stage 91.0 (TID 543) in 156 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7173387e
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b49b3df
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 2.0 in stage 91.0 (TID 544). 35015 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 4.0 in stage 91.0 (TID 546, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 4.0 in stage 91.0 (TID 546)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 2.0 in stage 91.0 (TID 544) in 127 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f70bbd5
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3be719c7
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 3.0 in stage 91.0 (TID 545). 36118 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 5.0 in stage 91.0 (TID 547, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 5.0 in stage 91.0 (TID 547)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 3.0 in stage 91.0 (TID 545) in 120 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@213df1d2
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cd7737a
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 4.0 in stage 91.0 (TID 546). 36032 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 6.0 in stage 91.0 (TID 548, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 6.0 in stage 91.0 (TID 548)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 4.0 in stage 91.0 (TID 546) in 122 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54c059b3
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24766883
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 5.0 in stage 91.0 (TID 547). 38041 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 7.0 in stage 91.0 (TID 549, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 5.0 in stage 91.0 (TID 547) in 138 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 7.0 in stage 91.0 (TID 549)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50dde62
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c32dccd
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 6.0 in stage 91.0 (TID 548). 38936 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 8.0 in stage 91.0 (TID 550, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 8.0 in stage 91.0 (TID 550)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 6.0 in stage 91.0 (TID 548) in 117 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5804616d
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5071cf2a
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 7.0 in stage 91.0 (TID 549). 36299 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Starting task 9.0 in stage 91.0 (TID 551, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:05 INFO  Executor:54 - Running task 9.0 in stage 91.0 (TID 551)
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 7.0 in stage 91.0 (TID 549) in 110 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3560aca7
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:05 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:05 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:05 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b83fcd0
2020-05-19 05:26:05 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 45 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Committed version 46 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/46.delta
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:05 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 8.0 in stage 91.0 (TID 550). 35352 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 8.0 in stage 91.0 (TID 550) in 115 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:05 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 46 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:05 INFO  Executor:54 - Finished task 9.0 in stage 91.0 (TID 551). 34810 bytes result sent to driver
2020-05-19 05:26:05 INFO  TaskSetManager:54 - Finished task 9.0 in stage 91.0 (TID 551) in 102 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2020-05-19 05:26:05 INFO  DAGScheduler:54 - ResultStage 91 (start at NativeMethodAccessorImpl.java:0) finished in 0.632 s
2020-05-19 05:26:05 INFO  DAGScheduler:54 - Job 90 finished: start at NativeMethodAccessorImpl.java:0, took 0.777911 s
2020-05-19 05:26:05 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@73679639 is committing.
-------------------------------------------
Batch: 45
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:05 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@73679639 committed.
2020-05-19 05:26:05 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:05 INFO  DAGScheduler:54 - Job 91 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:26:05 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:04.376Z",
  "batchId" : 45,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.4545454545454546,
  "processedRowsPerSecond" : 1.3568521031207599,
  "durationMs" : {
    "addBatch" : 1307,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 95,
    "triggerExecution" : 1474,
    "walCommit" : 63
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:48:00.000Z",
    "max" : "2018-12-28T16:48:00.000Z",
    "min" : "2018-12-28T16:48:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2838,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3252,
        "0" : 3151
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3152
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.4545454545454546,
    "processedRowsPerSecond" : 1.3568521031207599
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:06 INFO  MicroBatchExecution:54 - Committed offsets for batch 46. Metadata OffsetSeqMetadata(1546297020000,1589865965922,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:06 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3253,"0":3152}}), end = {"department.police.service.call":{"1":3253,"0":3153}}
2020-05-19 05:26:06 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:06 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3152,3153,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3253,3253,None)
2020-05-19 05:26:06 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:06 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:06 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_184 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_184_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:06 INFO  BlockManagerInfo:54 - Added broadcast_184_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:06 INFO  SparkContext:54 - Created broadcast 184 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_185 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_185_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:06 INFO  BlockManagerInfo:54 - Added broadcast_185_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:06 INFO  SparkContext:54 - Created broadcast 185 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:06 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@20a72c15. The input RDD has 10 partitions.
2020-05-19 05:26:06 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Registering RDD 696 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Got job 92 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Final stage: ResultStage 93 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 92)
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 92)
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 92 (MapPartitionsRDD[696] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_186 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_186_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:06 INFO  BlockManagerInfo:54 - Added broadcast_186_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:06 INFO  SparkContext:54 - Created broadcast 186 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[696] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:06 INFO  TaskSchedulerImpl:54 - Adding task set 92.0 with 2 tasks
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 92.0 (TID 552, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 1.0 in stage 92.0 (TID 553, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 0.0 in stage 92.0 (TID 552)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 1.0 in stage 92.0 (TID 553)
2020-05-19 05:26:06 INFO  KafkaSourceRDD:54 - Beginning offset 3253 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 1.0 in stage 92.0 (TID 553). 2074 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 1.0 in stage 92.0 (TID 553) in 12 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 0.0 in stage 92.0 (TID 552). 2203 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 92.0 (TID 552) in 32 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2020-05-19 05:26:06 INFO  DAGScheduler:54 - ShuffleMapStage 92 (start at NativeMethodAccessorImpl.java:0) finished in 0.046 s
2020-05-19 05:26:06 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:06 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:06 INFO  DAGScheduler:54 - waiting: Set(ResultStage 93)
2020-05-19 05:26:06 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Submitting ResultStage 93 (MapPartitionsRDD[702] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_187 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:06 INFO  MemoryStore:54 - Block broadcast_187_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:06 INFO  BlockManagerInfo:54 - Added broadcast_187_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:06 INFO  SparkContext:54 - Created broadcast 187 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 93 (MapPartitionsRDD[702] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:06 INFO  TaskSchedulerImpl:54 - Adding task set 93.0 with 10 tasks
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 93.0 (TID 554, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 1.0 in stage 93.0 (TID 555, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 0.0 in stage 93.0 (TID 554)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 1.0 in stage 93.0 (TID 555)
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a284def
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28ddb416
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7845c964
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d46aa3
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/47.delta
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 1.0 in stage 93.0 (TID 555). 33577 bytes result sent to driver
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 2.0 in stage 93.0 (TID 556, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 0.0 in stage 93.0 (TID 554). 34469 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 3.0 in stage 93.0 (TID 557, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 1.0 in stage 93.0 (TID 555) in 80 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 2.0 in stage 93.0 (TID 556)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 93.0 (TID 554) in 81 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 3.0 in stage 93.0 (TID 557)
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67e2573f
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5ec721
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f0d2f3c
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27020649
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/47.delta
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 2.0 in stage 93.0 (TID 556). 35015 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 4.0 in stage 93.0 (TID 558, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 4.0 in stage 93.0 (TID 558)
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 2.0 in stage 93.0 (TID 556) in 102 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 3.0 in stage 93.0 (TID 557). 36118 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 5.0 in stage 93.0 (TID 559, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 3.0 in stage 93.0 (TID 557) in 107 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 5.0 in stage 93.0 (TID 559)
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d2f657e
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d6f8303
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@623953a2
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d4d695
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 4.0 in stage 93.0 (TID 558). 36032 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 6.0 in stage 93.0 (TID 560, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 6.0 in stage 93.0 (TID 560)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 4.0 in stage 93.0 (TID 558) in 131 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 5.0 in stage 93.0 (TID 559). 38041 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 7.0 in stage 93.0 (TID 561, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 7.0 in stage 93.0 (TID 561)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 5.0 in stage 93.0 (TID 559) in 126 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58981b16
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c1bebf0
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@485aedec
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fa78b4b
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 7.0 in stage 93.0 (TID 561). 36299 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 8.0 in stage 93.0 (TID 562, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 8.0 in stage 93.0 (TID 562)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 7.0 in stage 93.0 (TID 561) in 140 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 6.0 in stage 93.0 (TID 560). 38936 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Starting task 9.0 in stage 93.0 (TID 563, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:06 INFO  Executor:54 - Running task 9.0 in stage 93.0 (TID 563)
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 6.0 in stage 93.0 (TID 560) in 154 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea2eace
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1c433
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23b25a2d
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:06 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:06 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:06 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f2f5205
2020-05-19 05:26:06 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 46 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:06 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/47.delta
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Committed version 47 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/47.delta
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:06 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 9.0 in stage 93.0 (TID 563). 34810 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 9.0 in stage 93.0 (TID 563) in 151 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:06 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 47 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:06 INFO  Executor:54 - Finished task 8.0 in stage 93.0 (TID 562). 35352 bytes result sent to driver
2020-05-19 05:26:06 INFO  TaskSetManager:54 - Finished task 8.0 in stage 93.0 (TID 562) in 172 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2020-05-19 05:26:06 INFO  DAGScheduler:54 - ResultStage 93 (start at NativeMethodAccessorImpl.java:0) finished in 0.624 s
2020-05-19 05:26:06 INFO  DAGScheduler:54 - Job 92 finished: start at NativeMethodAccessorImpl.java:0, took 0.674836 s
2020-05-19 05:26:06 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@20a72c15 is committing.
-------------------------------------------
Batch: 46
-------------------------------------------
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4156
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4072
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4166
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4010
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4042
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_183_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4146
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4178
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_181_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4060
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4145
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4167
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4033
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4163
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4094
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4069
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4150
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4168
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4138
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4153
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4180
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4013
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4046
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4054
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4171
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4095
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4152
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4076
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4159
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4050
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4032
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4162
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4077
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4143
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4058
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4092
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4007
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4029
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4133
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4012
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4019
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4136
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4021
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4028
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4040
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4047
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4039
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4009
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4044
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4170
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4080
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4149
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_187_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4027
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4165
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4083
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4090
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4091
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4079
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4052
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4157
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4137
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4085
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4064
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4169
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4045
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4148
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_180_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4067
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned shuffle 45
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4089
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4155
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4035
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4059
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4062
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4160
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4158
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4175
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4071
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4051
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4043
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4020
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4022
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4024
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4025
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4139
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4017
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4075
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4038
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4011
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4151
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4154
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4068
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4181
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4082
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4147
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4088
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4023
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4037
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4179
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4078
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4141
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4016
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4097
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4041
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4036
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4074
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4065
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4135
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4172
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4030
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4015
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4081
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4140
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4018
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4066
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4134
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4144
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4048
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4061
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4173
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_186_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4182
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4056
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4084
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4063
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4034
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4026
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4177
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4161
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4073
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4057
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4164
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4087
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4031
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4053
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4086
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4049
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4142
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4014
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4093
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4174
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4070
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Removed broadcast_182_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4055
2020-05-19 05:26:07 INFO  ContextCleaner:54 - Cleaned accumulator 4176
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:07 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@20a72c15 committed.
2020-05-19 05:26:07 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Job 93 finished: start at NativeMethodAccessorImpl.java:0, took 0.000052 s
2020-05-19 05:26:07 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:05.919Z",
  "batchId" : 46,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6480881399870383,
  "processedRowsPerSecond" : 0.7336757153338225,
  "durationMs" : {
    "addBatch" : 1149,
    "getBatch" : 7,
    "getOffset" : 2,
    "queryPlanning" : 116,
    "triggerExecution" : 1363,
    "walCommit" : 88
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:48:00.000Z",
    "max" : "2018-12-28T16:48:00.000Z",
    "min" : "2018-12-28T16:48:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2838,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3152
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3153
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6480881399870383,
    "processedRowsPerSecond" : 0.7336757153338225
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:07 INFO  MicroBatchExecution:54 - Committed offsets for batch 47. Metadata OffsetSeqMetadata(1546297020000,1589865967374,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:07 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3253,"0":3153}}), end = {"department.police.service.call":{"1":3253,"0":3155}}
2020-05-19 05:26:07 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:07 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3153,3155,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3253,3253,None)
2020-05-19 05:26:07 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:07 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:07 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_188 stored as values in memory (estimated size 281.8 KB, free 364.8 MB)
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_188_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.8 MB)
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Added broadcast_188_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:07 INFO  SparkContext:54 - Created broadcast 188 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_189 stored as values in memory (estimated size 281.8 KB, free 364.5 MB)
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_189_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.5 MB)
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Added broadcast_189_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  SparkContext:54 - Created broadcast 189 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:07 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3570134d. The input RDD has 10 partitions.
2020-05-19 05:26:07 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Registering RDD 711 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Got job 94 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Final stage: ResultStage 95 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 94)
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 94)
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 94 (MapPartitionsRDD[711] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_190 stored as values in memory (estimated size 39.1 KB, free 364.4 MB)
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_190_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.4 MB)
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Added broadcast_190_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  SparkContext:54 - Created broadcast 190 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[711] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:07 INFO  TaskSchedulerImpl:54 - Adding task set 94.0 with 2 tasks
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 94.0 (TID 564, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 1.0 in stage 94.0 (TID 565, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:07 INFO  Executor:54 - Running task 0.0 in stage 94.0 (TID 564)
2020-05-19 05:26:07 INFO  KafkaSourceRDD:54 - Beginning offset 3253 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:07 INFO  Executor:54 - Running task 1.0 in stage 94.0 (TID 565)
2020-05-19 05:26:07 INFO  Executor:54 - Finished task 1.0 in stage 94.0 (TID 565). 2203 bytes result sent to driver
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Finished task 1.0 in stage 94.0 (TID 565) in 20 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:07 INFO  Executor:54 - Finished task 0.0 in stage 94.0 (TID 564). 2074 bytes result sent to driver
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 94.0 (TID 564) in 23 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2020-05-19 05:26:07 INFO  DAGScheduler:54 - ShuffleMapStage 94 (start at NativeMethodAccessorImpl.java:0) finished in 0.037 s
2020-05-19 05:26:07 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:07 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:07 INFO  DAGScheduler:54 - waiting: Set(ResultStage 95)
2020-05-19 05:26:07 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Submitting ResultStage 95 (MapPartitionsRDD[717] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_191 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:07 INFO  MemoryStore:54 - Block broadcast_191_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:26:07 INFO  BlockManagerInfo:54 - Added broadcast_191_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:07 INFO  SparkContext:54 - Created broadcast 191 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:07 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 95 (MapPartitionsRDD[717] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:07 INFO  TaskSchedulerImpl:54 - Adding task set 95.0 with 10 tasks
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 95.0 (TID 566, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 1.0 in stage 95.0 (TID 567, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:07 INFO  Executor:54 - Running task 0.0 in stage 95.0 (TID 566)
2020-05-19 05:26:07 INFO  Executor:54 - Running task 1.0 in stage 95.0 (TID 567)
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5749c652
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd6ffbb
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@558f717e
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b645508
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/48.delta
2020-05-19 05:26:07 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:07 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/48.delta
2020-05-19 05:26:07 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:07 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:07 INFO  Executor:54 - Finished task 0.0 in stage 95.0 (TID 566). 34469 bytes result sent to driver
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 2.0 in stage 95.0 (TID 568, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:07 INFO  Executor:54 - Running task 2.0 in stage 95.0 (TID 568)
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 95.0 (TID 566) in 116 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d61c92d
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4be808ce
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  Executor:54 - Finished task 1.0 in stage 95.0 (TID 567). 33577 bytes result sent to driver
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Starting task 3.0 in stage 95.0 (TID 569, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:07 INFO  TaskSetManager:54 - Finished task 1.0 in stage 95.0 (TID 567) in 129 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:07 INFO  Executor:54 - Running task 3.0 in stage 95.0 (TID 569)
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5404ce60
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:07 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:07 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:07 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dd431bb
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:07 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:07 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/48.delta
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 3.0 in stage 95.0 (TID 569). 36118 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 4.0 in stage 95.0 (TID 570, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 4.0 in stage 95.0 (TID 570)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 3.0 in stage 95.0 (TID 569) in 150 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76a2c0d7
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dfa7a0d
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 2.0 in stage 95.0 (TID 568). 35015 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 5.0 in stage 95.0 (TID 571, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 5.0 in stage 95.0 (TID 571)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 2.0 in stage 95.0 (TID 568) in 174 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@369f92fb
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3011ef9f
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/48.delta
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 4.0 in stage 95.0 (TID 570). 36032 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 6.0 in stage 95.0 (TID 572, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 6.0 in stage 95.0 (TID 572)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 4.0 in stage 95.0 (TID 570) in 111 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aead8ce
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@726f6686
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 5.0 in stage 95.0 (TID 571). 38041 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 7.0 in stage 95.0 (TID 573, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 7.0 in stage 95.0 (TID 573)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 5.0 in stage 95.0 (TID 571) in 148 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 6.0 in stage 95.0 (TID 572). 38936 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 8.0 in stage 95.0 (TID 574, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 8.0 in stage 95.0 (TID 574)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 6.0 in stage 95.0 (TID 572) in 54 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e0f6cbb
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@524b57c0
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42b9a041
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4391bec2
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 7.0 in stage 95.0 (TID 573). 36299 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Starting task 9.0 in stage 95.0 (TID 575, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 8.0 in stage 95.0 (TID 574). 35352 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 7.0 in stage 95.0 (TID 573) in 130 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 8.0 in stage 95.0 (TID 574) in 124 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:08 INFO  Executor:54 - Running task 9.0 in stage 95.0 (TID 575)
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68293657
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:08 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:08 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:08 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7394636d
2020-05-19 05:26:08 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 47 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:08 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Committed version 48 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/48.delta
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:08 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:08 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 48 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:08 INFO  Executor:54 - Finished task 9.0 in stage 95.0 (TID 575). 34810 bytes result sent to driver
2020-05-19 05:26:08 INFO  TaskSetManager:54 - Finished task 9.0 in stage 95.0 (TID 575) in 69 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2020-05-19 05:26:08 INFO  DAGScheduler:54 - ResultStage 95 (start at NativeMethodAccessorImpl.java:0) finished in 0.645 s
2020-05-19 05:26:08 INFO  DAGScheduler:54 - Job 94 finished: start at NativeMethodAccessorImpl.java:0, took 0.690506 s
2020-05-19 05:26:08 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3570134d is committing.
-------------------------------------------
Batch: 47
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:08 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3570134d committed.
2020-05-19 05:26:08 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:08 INFO  DAGScheduler:54 - Job 95 finished: start at NativeMethodAccessorImpl.java:0, took 0.000040 s
2020-05-19 05:26:08 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:07.370Z",
  "batchId" : 47,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3783597518952446,
  "processedRowsPerSecond" : 1.567398119122257,
  "durationMs" : {
    "addBatch" : 1113,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 63,
    "triggerExecution" : 1276,
    "walCommit" : 90
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:46:30.000Z",
    "max" : "2018-12-28T16:47:00.000Z",
    "min" : "2018-12-28T16:46:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2838,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3153
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3155
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3783597518952446,
    "processedRowsPerSecond" : 1.567398119122257
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:08 INFO  MicroBatchExecution:54 - Committed offsets for batch 48. Metadata OffsetSeqMetadata(1546297020000,1589865968739,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:08 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3253,"0":3155}}), end = {"department.police.service.call":{"1":3253,"0":3156}}
2020-05-19 05:26:08 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:08 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3155,3156,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3253,3253,None)
2020-05-19 05:26:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:08 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:08 INFO  MemoryStore:54 - Block broadcast_192 stored as values in memory (estimated size 281.8 KB, free 364.1 MB)
2020-05-19 05:26:08 INFO  MemoryStore:54 - Block broadcast_192_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:26:08 INFO  BlockManagerInfo:54 - Added broadcast_192_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:08 INFO  SparkContext:54 - Created broadcast 192 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_193 stored as values in memory (estimated size 281.8 KB, free 363.8 MB)
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_193_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Added broadcast_193_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  SparkContext:54 - Created broadcast 193 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:09 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6a970644. The input RDD has 10 partitions.
2020-05-19 05:26:09 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Registering RDD 726 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Got job 96 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Final stage: ResultStage 97 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 96)
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 96)
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 96 (MapPartitionsRDD[726] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_194 stored as values in memory (estimated size 39.1 KB, free 363.7 MB)
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_194_piece0 stored as bytes in memory (estimated size 15.8 KB, free 363.7 MB)
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Added broadcast_194_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.0 MB)
2020-05-19 05:26:09 INFO  SparkContext:54 - Created broadcast 194 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[726] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:09 INFO  TaskSchedulerImpl:54 - Adding task set 96.0 with 2 tasks
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 96.0 (TID 576, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 1.0 in stage 96.0 (TID 577, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 0.0 in stage 96.0 (TID 576)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 1.0 in stage 96.0 (TID 577)
2020-05-19 05:26:09 INFO  KafkaSourceRDD:54 - Beginning offset 3253 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 1.0 in stage 96.0 (TID 577). 2203 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 1.0 in stage 96.0 (TID 577) in 26 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 0.0 in stage 96.0 (TID 576). 2074 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 0.0 in stage 96.0 (TID 576) in 36 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2020-05-19 05:26:09 INFO  DAGScheduler:54 - ShuffleMapStage 96 (start at NativeMethodAccessorImpl.java:0) finished in 0.057 s
2020-05-19 05:26:09 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:09 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:09 INFO  DAGScheduler:54 - waiting: Set(ResultStage 97)
2020-05-19 05:26:09 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Submitting ResultStage 97 (MapPartitionsRDD[732] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_195 stored as values in memory (estimated size 54.1 KB, free 363.6 MB)
2020-05-19 05:26:09 INFO  MemoryStore:54 - Block broadcast_195_piece0 stored as bytes in memory (estimated size 19.1 KB, free 363.6 MB)
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Added broadcast_195_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.0 MB)
2020-05-19 05:26:09 INFO  SparkContext:54 - Created broadcast 195 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 97 (MapPartitionsRDD[732] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:09 INFO  TaskSchedulerImpl:54 - Adding task set 97.0 with 10 tasks
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 97.0 (TID 578, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 1.0 in stage 97.0 (TID 579, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 0.0 in stage 97.0 (TID 578)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  Executor:54 - Running task 1.0 in stage 97.0 (TID 579)
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c1a788
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e4056e6
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a37e342
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dc744a4
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/49.delta
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 0.0 in stage 97.0 (TID 578). 34512 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 2.0 in stage 97.0 (TID 580, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 2.0 in stage 97.0 (TID 580)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 0.0 in stage 97.0 (TID 578) in 137 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ca83724
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79ffb446
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4189
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4268
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4217
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4203
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4224
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4275
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4262
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4185
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4184
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4225
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4132
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4252
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4194
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4113
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4251
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4111
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4221
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4205
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4230
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4236
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4261
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4098
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4131
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4190
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4125
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4240
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4266
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4270
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4228
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4273
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4101
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4257
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_191_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.0 MB)
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4227
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4255
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_190_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_189_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4250
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4107
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4183
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4211
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4200
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4218
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4127
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4195
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4267
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4201
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4188
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4110
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4247
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4129
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4103
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4220
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned shuffle 46
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4235
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4122
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4233
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4241
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4245
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4212
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4116
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4215
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4105
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4121
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4117
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4271
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4100
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4198
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4242
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4102
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned shuffle 47
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4193
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_188_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_194_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4239
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4210
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4112
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4226
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4243
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4106
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4219
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4237
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4229
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4244
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_185_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4264
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4207
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4259
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4249
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4119
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4128
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4186
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4109
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4123
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4187
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4231
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4209
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4223
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4222
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4115
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4202
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4104
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4238
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4254
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4204
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4099
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4246
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4253
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4206
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4114
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4096
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4191
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4214
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4256
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4124
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4263
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4196
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4232
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4234
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4120
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4126
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4269
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4130
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4208
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4216
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4199
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4265
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4258
2020-05-19 05:26:09 INFO  BlockManagerInfo:54 - Removed broadcast_184_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4192
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4108
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4248
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4260
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4272
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4118
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4213
2020-05-19 05:26:09 INFO  ContextCleaner:54 - Cleaned accumulator 4197
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 1.0 in stage 97.0 (TID 579). 33620 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 3.0 in stage 97.0 (TID 581, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 3.0 in stage 97.0 (TID 581)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 1.0 in stage 97.0 (TID 579) in 182 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71560e91
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/49.delta
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ae5d06c
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 2.0 in stage 97.0 (TID 580). 35015 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 4.0 in stage 97.0 (TID 582, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 4.0 in stage 97.0 (TID 582)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 2.0 in stage 97.0 (TID 580) in 124 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a73c9f1
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d425a38
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 3.0 in stage 97.0 (TID 581). 36216 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 5.0 in stage 97.0 (TID 583, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 5.0 in stage 97.0 (TID 583)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 3.0 in stage 97.0 (TID 581) in 104 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5415a072
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cc84b50
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/49.delta
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 4.0 in stage 97.0 (TID 582). 36032 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 6.0 in stage 97.0 (TID 584, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 4.0 in stage 97.0 (TID 582) in 98 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 6.0 in stage 97.0 (TID 584)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d51218e
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2301e755
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 5.0 in stage 97.0 (TID 583). 38041 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 7.0 in stage 97.0 (TID 585, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 7.0 in stage 97.0 (TID 585)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 5.0 in stage 97.0 (TID 583) in 124 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13ab6499
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@737c1107
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 6.0 in stage 97.0 (TID 584). 38936 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 8.0 in stage 97.0 (TID 586, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 6.0 in stage 97.0 (TID 584) in 120 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 8.0 in stage 97.0 (TID 586)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26963efd
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21e58f91
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/49.delta
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 7.0 in stage 97.0 (TID 585). 36299 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Starting task 9.0 in stage 97.0 (TID 587, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:09 INFO  Executor:54 - Running task 9.0 in stage 97.0 (TID 587)
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 7.0 in stage 97.0 (TID 585) in 120 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ed422fc
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:09 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:09 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:09 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8152b29
2020-05-19 05:26:09 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 48 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Committed version 49 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/49.delta
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:09 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 8.0 in stage 97.0 (TID 586). 35352 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 8.0 in stage 97.0 (TID 586) in 125 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:09 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 49 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:09 INFO  Executor:54 - Finished task 9.0 in stage 97.0 (TID 587). 34810 bytes result sent to driver
2020-05-19 05:26:09 INFO  TaskSetManager:54 - Finished task 9.0 in stage 97.0 (TID 587) in 101 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2020-05-19 05:26:09 INFO  DAGScheduler:54 - ResultStage 97 (start at NativeMethodAccessorImpl.java:0) finished in 0.631 s
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Job 96 finished: start at NativeMethodAccessorImpl.java:0, took 0.695509 s
2020-05-19 05:26:09 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6a970644 is committing.
-------------------------------------------
Batch: 48
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:09 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6a970644 committed.
2020-05-19 05:26:09 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:09 INFO  DAGScheduler:54 - Job 97 finished: start at NativeMethodAccessorImpl.java:0, took 0.000039 s
2020-05-19 05:26:09 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:08.733Z",
  "batchId" : 48,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.7336757153338225,
  "processedRowsPerSecond" : 0.8045052292839903,
  "durationMs" : {
    "addBatch" : 1110,
    "getBatch" : 4,
    "getOffset" : 6,
    "queryPlanning" : 51,
    "triggerExecution" : 1243,
    "walCommit" : 72
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:46:00.000Z",
    "max" : "2018-12-28T16:46:00.000Z",
    "min" : "2018-12-28T16:46:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2839,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3155
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3156
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.7336757153338225,
    "processedRowsPerSecond" : 0.8045052292839903
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:10 INFO  MicroBatchExecution:54 - Committed offsets for batch 49. Metadata OffsetSeqMetadata(1546297020000,1589865970118,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:10 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3253,"0":3156}}), end = {"department.police.service.call":{"1":3253,"0":3157}}
2020-05-19 05:26:10 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:10 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3156,3157,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3253,3253,None)
2020-05-19 05:26:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:10 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_196 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_196_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:26:10 INFO  BlockManagerInfo:54 - Added broadcast_196_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:10 INFO  SparkContext:54 - Created broadcast 196 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_197 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_197_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:26:10 INFO  BlockManagerInfo:54 - Added broadcast_197_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:10 INFO  SparkContext:54 - Created broadcast 197 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:10 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2e046019. The input RDD has 10 partitions.
2020-05-19 05:26:10 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Registering RDD 741 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Got job 98 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Final stage: ResultStage 99 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 98)
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 98)
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 98 (MapPartitionsRDD[741] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_198 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_198_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:10 INFO  BlockManagerInfo:54 - Added broadcast_198_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:10 INFO  SparkContext:54 - Created broadcast 198 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[741] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:10 INFO  TaskSchedulerImpl:54 - Adding task set 98.0 with 2 tasks
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 98.0 (TID 588, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 1.0 in stage 98.0 (TID 589, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 0.0 in stage 98.0 (TID 588)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 1.0 in stage 98.0 (TID 589)
2020-05-19 05:26:10 INFO  KafkaSourceRDD:54 - Beginning offset 3253 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 0.0 in stage 98.0 (TID 588). 2074 bytes result sent to driver
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 1.0 in stage 98.0 (TID 589). 2203 bytes result sent to driver
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 98.0 (TID 588) in 33 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 1.0 in stage 98.0 (TID 589) in 35 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:10 INFO  TaskSchedulerImpl:54 - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2020-05-19 05:26:10 INFO  DAGScheduler:54 - ShuffleMapStage 98 (start at NativeMethodAccessorImpl.java:0) finished in 0.043 s
2020-05-19 05:26:10 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:10 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:10 INFO  DAGScheduler:54 - waiting: Set(ResultStage 99)
2020-05-19 05:26:10 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Submitting ResultStage 99 (MapPartitionsRDD[747] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_199 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:10 INFO  MemoryStore:54 - Block broadcast_199_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:26:10 INFO  BlockManagerInfo:54 - Added broadcast_199_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:10 INFO  SparkContext:54 - Created broadcast 199 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:10 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 99 (MapPartitionsRDD[747] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:10 INFO  TaskSchedulerImpl:54 - Adding task set 99.0 with 10 tasks
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 99.0 (TID 590, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 1.0 in stage 99.0 (TID 591, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 0.0 in stage 99.0 (TID 590)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 1.0 in stage 99.0 (TID 591)
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@291701be
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64f52757
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f52553a
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14bc4dcf
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/50.delta
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/50.delta
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 0.0 in stage 99.0 (TID 590). 34469 bytes result sent to driver
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 2.0 in stage 99.0 (TID 592, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 2.0 in stage 99.0 (TID 592)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 99.0 (TID 590) in 108 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 1.0 in stage 99.0 (TID 591). 33577 bytes result sent to driver
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b1a8a05
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 3.0 in stage 99.0 (TID 593, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 3.0 in stage 99.0 (TID 593)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 1.0 in stage 99.0 (TID 591) in 115 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@133ecd37
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72601c18
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f469832
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/50.delta
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/50.delta
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 2.0 in stage 99.0 (TID 592). 35015 bytes result sent to driver
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 4.0 in stage 99.0 (TID 594, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 4.0 in stage 99.0 (TID 594)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 2.0 in stage 99.0 (TID 592) in 123 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e3b77d2
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9e29131
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 3.0 in stage 99.0 (TID 593). 36216 bytes result sent to driver
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 5.0 in stage 99.0 (TID 595, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 5.0 in stage 99.0 (TID 595)
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Finished task 3.0 in stage 99.0 (TID 593) in 132 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5311e1f9
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:10 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:10 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:10 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6827653e
2020-05-19 05:26:10 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:10 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/50.delta
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/50.delta
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:10 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:10 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:10 INFO  Executor:54 - Finished task 4.0 in stage 99.0 (TID 594). 36032 bytes result sent to driver
2020-05-19 05:26:10 INFO  TaskSetManager:54 - Starting task 6.0 in stage 99.0 (TID 596, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:10 INFO  Executor:54 - Running task 6.0 in stage 99.0 (TID 596)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 4.0 in stage 99.0 (TID 594) in 108 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@513a73b2
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@168a3f79
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 5.0 in stage 99.0 (TID 595). 38041 bytes result sent to driver
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 7.0 in stage 99.0 (TID 597, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 7.0 in stage 99.0 (TID 597)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 5.0 in stage 99.0 (TID 595) in 111 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae7353b
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41e043c6
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/50.delta
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/50.delta
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 6.0 in stage 99.0 (TID 596). 38936 bytes result sent to driver
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 8.0 in stage 99.0 (TID 598, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 6.0 in stage 99.0 (TID 596) in 110 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 7.0 in stage 99.0 (TID 597). 36299 bytes result sent to driver
2020-05-19 05:26:11 INFO  Executor:54 - Running task 8.0 in stage 99.0 (TID 598)
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 9.0 in stage 99.0 (TID 599, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 9.0 in stage 99.0 (TID 599)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 7.0 in stage 99.0 (TID 597) in 100 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ec2cf8d
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@332556bf
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dc406ce
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7473734
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 49 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/50.delta
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Committed version 50 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/50.delta
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:11 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 8.0 in stage 99.0 (TID 598). 35352 bytes result sent to driver
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 8.0 in stage 99.0 (TID 598) in 114 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 50 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 9.0 in stage 99.0 (TID 599). 34810 bytes result sent to driver
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 9.0 in stage 99.0 (TID 599) in 112 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2020-05-19 05:26:11 INFO  DAGScheduler:54 - ResultStage 99 (start at NativeMethodAccessorImpl.java:0) finished in 0.577 s
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Job 98 finished: start at NativeMethodAccessorImpl.java:0, took 0.636977 s
2020-05-19 05:26:11 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2e046019 is committing.
-------------------------------------------
Batch: 49
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:11 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2e046019 committed.
2020-05-19 05:26:11 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Job 99 finished: start at NativeMethodAccessorImpl.java:0, took 0.000041 s
2020-05-19 05:26:11 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:10.115Z",
  "batchId" : 49,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.7235890014471781,
  "processedRowsPerSecond" : 0.8071025020177562,
  "durationMs" : {
    "addBatch" : 1108,
    "getBatch" : 8,
    "getOffset" : 3,
    "queryPlanning" : 71,
    "triggerExecution" : 1239,
    "walCommit" : 48
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:46:00.000Z",
    "max" : "2018-12-28T16:46:00.000Z",
    "min" : "2018-12-28T16:46:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2839,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3156
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3157
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.7235890014471781,
    "processedRowsPerSecond" : 0.8071025020177562
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:11 INFO  MicroBatchExecution:54 - Committed offsets for batch 50. Metadata OffsetSeqMetadata(1546297020000,1589865971446,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:11 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3253,"0":3157}}), end = {"department.police.service.call":{"1":3254,"0":3158}}
2020-05-19 05:26:11 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:11 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3157,3158,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3253,3254,None)
2020-05-19 05:26:11 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:11 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:11 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4291
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4342
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4388
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4353
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4347
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4397
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4387
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4290
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4438
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4299
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4375
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4419
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4425
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4317
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4336
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4348
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4281
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4435
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4430
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4315
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_198_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4443
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4433
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4434
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4400
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4410
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4345
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4378
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4382
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4362
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4289
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4303
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4356
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4448
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4428
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4398
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4332
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4441
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4330
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4368
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4415
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4453
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4380
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4374
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4445
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4354
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4320
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4327
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4392
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4363
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4372
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_192_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4355
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4422
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4427
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4394
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4389
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4426
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4437
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4450
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_199_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4379
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4322
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4297
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4337
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4318
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4402
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4360
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4321
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4390
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4340
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4351
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4300
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4373
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4325
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4284
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4301
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4350
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4310
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4274
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4408
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4334
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4324
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4358
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4305
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4396
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4376
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4418
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4279
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4294
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4319
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4306
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4296
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4339
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4366
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4386
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4414
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4403
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4429
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4335
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4346
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4312
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4283
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4314
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4287
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4313
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4423
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4440
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4352
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4393
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4277
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4405
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4292
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4333
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4395
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4308
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4293
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4391
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4278
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4451
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4371
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4377
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4359
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4341
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4444
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4343
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4282
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4406
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4369
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4329
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4385
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4432
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4384
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4357
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4280
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4401
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4298
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4364
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4288
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4311
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4276
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4420
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4285
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4286
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4309
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4417
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4442
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_193_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4421
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4323
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4447
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4344
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4399
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4367
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4370
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4439
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4413
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4307
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4411
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4302
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4381
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4328
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4365
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4304
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4331
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4424
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4295
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4407
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_196_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_197_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4349
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4449
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4404
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned shuffle 49
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4431
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4361
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Removed broadcast_195_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4416
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4383
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4326
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4316
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4436
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4409
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned shuffle 48
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4338
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4412
2020-05-19 05:26:11 INFO  ContextCleaner:54 - Cleaned accumulator 4446
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_200 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_200_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Added broadcast_200_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  SparkContext:54 - Created broadcast 200 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_201 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_201_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Added broadcast_201_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  SparkContext:54 - Created broadcast 201 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:11 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a761719. The input RDD has 10 partitions.
2020-05-19 05:26:11 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Registering RDD 756 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Got job 100 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Final stage: ResultStage 101 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 100)
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 100)
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 100 (MapPartitionsRDD[756] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_202 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_202_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Added broadcast_202_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  SparkContext:54 - Created broadcast 202 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[756] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:11 INFO  TaskSchedulerImpl:54 - Adding task set 100.0 with 2 tasks
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 100.0 (TID 600, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 1.0 in stage 100.0 (TID 601, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 0.0 in stage 100.0 (TID 600)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 1.0 in stage 100.0 (TID 601)
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 1.0 in stage 100.0 (TID 601). 2203 bytes result sent to driver
2020-05-19 05:26:11 INFO  Executor:54 - Finished task 0.0 in stage 100.0 (TID 600). 2203 bytes result sent to driver
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 1.0 in stage 100.0 (TID 601) in 38 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Finished task 0.0 in stage 100.0 (TID 600) in 39 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2020-05-19 05:26:11 INFO  DAGScheduler:54 - ShuffleMapStage 100 (start at NativeMethodAccessorImpl.java:0) finished in 0.048 s
2020-05-19 05:26:11 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:11 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:11 INFO  DAGScheduler:54 - waiting: Set(ResultStage 101)
2020-05-19 05:26:11 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Submitting ResultStage 101 (MapPartitionsRDD[762] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_203 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:26:11 INFO  MemoryStore:54 - Block broadcast_203_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:26:11 INFO  BlockManagerInfo:54 - Added broadcast_203_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:11 INFO  SparkContext:54 - Created broadcast 203 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:11 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 101 (MapPartitionsRDD[762] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:11 INFO  TaskSchedulerImpl:54 - Adding task set 101.0 with 10 tasks
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 101.0 (TID 602, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:11 INFO  TaskSetManager:54 - Starting task 1.0 in stage 101.0 (TID 603, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 0.0 in stage 101.0 (TID 602)
2020-05-19 05:26:11 INFO  Executor:54 - Running task 1.0 in stage 101.0 (TID 603)
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a8046db
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2392ba4c
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d82e3ae
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:11 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:11 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:11 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42bd754a
2020-05-19 05:26:11 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:11 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 0.0 in stage 101.0 (TID 602). 34469 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 2.0 in stage 101.0 (TID 604, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 101.0 (TID 602) in 111 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 2.0 in stage 101.0 (TID 604)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@360e2594
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4032691c
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 1.0 in stage 101.0 (TID 603). 33577 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 3.0 in stage 101.0 (TID 605, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 1.0 in stage 101.0 (TID 603) in 165 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 3.0 in stage 101.0 (TID 605)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e6ebbb
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a1634c
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 3.0 in stage 101.0 (TID 605). 36216 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 4.0 in stage 101.0 (TID 606, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 4.0 in stage 101.0 (TID 606)
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 3.0 in stage 101.0 (TID 605) in 102 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 2.0 in stage 101.0 (TID 604). 35015 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 5.0 in stage 101.0 (TID 607, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 2.0 in stage 101.0 (TID 604) in 161 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 5.0 in stage 101.0 (TID 607)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ba98e01
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@304559a9
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55ba37cd
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5413f6a
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 5.0 in stage 101.0 (TID 607). 38041 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 6.0 in stage 101.0 (TID 608, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 6.0 in stage 101.0 (TID 608)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 5.0 in stage 101.0 (TID 607) in 114 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77f463e2
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37f6e726
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 4.0 in stage 101.0 (TID 606). 36032 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 7.0 in stage 101.0 (TID 609, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 7.0 in stage 101.0 (TID 609)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 4.0 in stage 101.0 (TID 606) in 127 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a2f8858
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18400725
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 7.0 in stage 101.0 (TID 609). 36299 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 8.0 in stage 101.0 (TID 610, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 8.0 in stage 101.0 (TID 610)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 7.0 in stage 101.0 (TID 609) in 79 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@774fe48f
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d41ba77
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 6.0 in stage 101.0 (TID 608). 38936 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Starting task 9.0 in stage 101.0 (TID 611, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:12 INFO  Executor:54 - Running task 9.0 in stage 101.0 (TID 611)
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 6.0 in stage 101.0 (TID 608) in 100 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a03d780
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:12 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:12 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:12 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ecba19
2020-05-19 05:26:12 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 50 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Committed version 51 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/51.delta
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:12 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 8.0 in stage 101.0 (TID 610). 35352 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 8.0 in stage 101.0 (TID 610) in 113 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:12 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 51 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:12 INFO  Executor:54 - Finished task 9.0 in stage 101.0 (TID 611). 34810 bytes result sent to driver
2020-05-19 05:26:12 INFO  TaskSetManager:54 - Finished task 9.0 in stage 101.0 (TID 611) in 141 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:12 INFO  TaskSchedulerImpl:54 - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2020-05-19 05:26:12 INFO  DAGScheduler:54 - ResultStage 101 (start at NativeMethodAccessorImpl.java:0) finished in 0.627 s
2020-05-19 05:26:12 INFO  DAGScheduler:54 - Job 100 finished: start at NativeMethodAccessorImpl.java:0, took 0.681314 s
2020-05-19 05:26:12 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a761719 is committing.
-------------------------------------------
Batch: 50
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:12 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5a761719 committed.
2020-05-19 05:26:12 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:12 INFO  DAGScheduler:54 - Job 101 finished: start at NativeMethodAccessorImpl.java:0, took 0.000051 s
2020-05-19 05:26:12 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:11.442Z",
  "batchId" : 50,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.5071590052750565,
  "processedRowsPerSecond" : 1.4992503748125936,
  "durationMs" : {
    "addBatch" : 1195,
    "getBatch" : 5,
    "getOffset" : 3,
    "queryPlanning" : 74,
    "triggerExecution" : 1334,
    "walCommit" : 56
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:45:00.000Z",
    "max" : "2018-12-28T16:45:00.000Z",
    "min" : "2018-12-28T16:45:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2839,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3253,
        "0" : 3157
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3254,
        "0" : 3158
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.5071590052750565,
    "processedRowsPerSecond" : 1.4992503748125936
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:12 INFO  MicroBatchExecution:54 - Committed offsets for batch 51. Metadata OffsetSeqMetadata(1546297020000,1589865972880,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:12 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3254,"0":3158}}), end = {"department.police.service.call":{"1":3255,"0":3158}}
2020-05-19 05:26:12 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:12 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3158,3158,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3254,3255,None)
2020-05-19 05:26:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:13 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_204 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_204_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Added broadcast_204_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  SparkContext:54 - Created broadcast 204 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_205 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_205_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Added broadcast_205_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  SparkContext:54 - Created broadcast 205 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:13 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71f0c0ac. The input RDD has 10 partitions.
2020-05-19 05:26:13 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Registering RDD 771 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Got job 102 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Final stage: ResultStage 103 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 102)
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 102)
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 102 (MapPartitionsRDD[771] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_206 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_206_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Added broadcast_206_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  SparkContext:54 - Created broadcast 206 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[771] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:13 INFO  TaskSchedulerImpl:54 - Adding task set 102.0 with 2 tasks
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 102.0 (TID 612, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 1.0 in stage 102.0 (TID 613, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 0.0 in stage 102.0 (TID 612)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 1.0 in stage 102.0 (TID 613)
2020-05-19 05:26:13 INFO  KafkaSourceRDD:54 - Beginning offset 3158 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 1.0 in stage 102.0 (TID 613). 2074 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 1.0 in stage 102.0 (TID 613) in 16 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 0.0 in stage 102.0 (TID 612). 2203 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 102.0 (TID 612) in 30 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2020-05-19 05:26:13 INFO  DAGScheduler:54 - ShuffleMapStage 102 (start at NativeMethodAccessorImpl.java:0) finished in 0.037 s
2020-05-19 05:26:13 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:13 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:13 INFO  DAGScheduler:54 - waiting: Set(ResultStage 103)
2020-05-19 05:26:13 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Submitting ResultStage 103 (MapPartitionsRDD[777] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_207 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:13 INFO  MemoryStore:54 - Block broadcast_207_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Added broadcast_207_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  SparkContext:54 - Created broadcast 207 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:13 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 103 (MapPartitionsRDD[777] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:13 INFO  TaskSchedulerImpl:54 - Adding task set 103.0 with 10 tasks
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 103.0 (TID 614, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 1.0 in stage 103.0 (TID 615, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 0.0 in stage 103.0 (TID 614)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  Executor:54 - Running task 1.0 in stage 103.0 (TID 615)
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eb95e57
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c4d56ae
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@197f188f
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e90038d
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/52.delta
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/52.delta
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 1.0 in stage 103.0 (TID 615). 33577 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 2.0 in stage 103.0 (TID 616, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 2.0 in stage 103.0 (TID 616)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 1.0 in stage 103.0 (TID 615) in 132 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49a7c3c1
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d6adffb
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 0.0 in stage 103.0 (TID 614). 34566 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 3.0 in stage 103.0 (TID 617, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 3.0 in stage 103.0 (TID 617)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 103.0 (TID 614) in 179 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5017d0a4
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e6b34c4
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/52.delta
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/52.delta
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 2.0 in stage 103.0 (TID 616). 35015 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 4.0 in stage 103.0 (TID 618, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 2.0 in stage 103.0 (TID 616) in 115 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 4.0 in stage 103.0 (TID 618)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@614b3469
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b768dd
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/52.delta
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 3.0 in stage 103.0 (TID 617). 36216 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 5.0 in stage 103.0 (TID 619, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 3.0 in stage 103.0 (TID 617) in 108 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 5.0 in stage 103.0 (TID 619)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fa8b60
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65128a5c
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 4.0 in stage 103.0 (TID 618). 36032 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 6.0 in stage 103.0 (TID 620, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 6.0 in stage 103.0 (TID 620)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 4.0 in stage 103.0 (TID 618) in 88 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a4d539
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4516
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4510
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4525
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4523
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4496
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4457
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4521
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4461
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4467
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4534
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4458
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4493
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4473
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4513
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4537
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4501
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4472
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4469
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4499
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4492
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4494
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4502
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4459
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4476
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4456
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4463
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4532
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4486
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4512
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4506
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4529
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4503
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4520
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4533
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4466
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Removed broadcast_203_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d4f2405
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/52.delta
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4515
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Removed broadcast_202_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Removed broadcast_200_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4517
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4518
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4540
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4485
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4471
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4524
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4480
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4462
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4536
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4528
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4474
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4464
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4488
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4454
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned shuffle 50
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4511
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4527
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4475
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4505
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4489
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4468
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4498
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4478
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4465
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4504
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4487
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4531
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4477
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4452
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4507
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4495
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4530
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Removed broadcast_201_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4460
2020-05-19 05:26:13 INFO  BlockManagerInfo:54 - Removed broadcast_206_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4481
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4484
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4508
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4538
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4497
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4509
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4539
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4519
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4535
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4482
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4490
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4526
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4483
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4500
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4522
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4479
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4455
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4514
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4542
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4491
2020-05-19 05:26:13 INFO  ContextCleaner:54 - Cleaned accumulator 4470
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/52.delta
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:13 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 5.0 in stage 103.0 (TID 619). 38084 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 7.0 in stage 103.0 (TID 621, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 7.0 in stage 103.0 (TID 621)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 5.0 in stage 103.0 (TID 619) in 178 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2da2fd1f
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a34f13d
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:13 INFO  Executor:54 - Finished task 6.0 in stage 103.0 (TID 620). 38979 bytes result sent to driver
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Starting task 8.0 in stage 103.0 (TID 622, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:13 INFO  TaskSetManager:54 - Finished task 6.0 in stage 103.0 (TID 620) in 152 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:13 INFO  Executor:54 - Running task 8.0 in stage 103.0 (TID 622)
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@636b047a
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:13 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:13 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:13 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40cae634
2020-05-19 05:26:13 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:13 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/52.delta
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/52.delta
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:14 INFO  Executor:54 - Finished task 7.0 in stage 103.0 (TID 621). 36299 bytes result sent to driver
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Starting task 9.0 in stage 103.0 (TID 623, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Finished task 7.0 in stage 103.0 (TID 621) in 86 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:14 INFO  Executor:54 - Running task 9.0 in stage 103.0 (TID 623)
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24290a6f
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39f96228
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 51 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:14 INFO  Executor:54 - Finished task 8.0 in stage 103.0 (TID 622). 35352 bytes result sent to driver
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Finished task 8.0 in stage 103.0 (TID 622) in 91 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 52 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/52.delta
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 52 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:14 INFO  Executor:54 - Finished task 9.0 in stage 103.0 (TID 623). 34810 bytes result sent to driver
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Finished task 9.0 in stage 103.0 (TID 623) in 66 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2020-05-19 05:26:14 INFO  DAGScheduler:54 - ResultStage 103 (start at NativeMethodAccessorImpl.java:0) finished in 0.616 s
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Job 102 finished: start at NativeMethodAccessorImpl.java:0, took 0.657495 s
2020-05-19 05:26:14 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71f0c0ac is committing.
-------------------------------------------
Batch: 51
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:14 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71f0c0ac committed.
2020-05-19 05:26:14 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Job 103 finished: start at NativeMethodAccessorImpl.java:0, took 0.000053 s
2020-05-19 05:26:14 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:12.874Z",
  "batchId" : 51,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6983240223463687,
  "processedRowsPerSecond" : 0.6901311249137336,
  "durationMs" : {
    "addBatch" : 1255,
    "getBatch" : 5,
    "getOffset" : 6,
    "queryPlanning" : 85,
    "triggerExecution" : 1449,
    "walCommit" : 98
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:45:00.000Z",
    "max" : "2018-12-28T16:45:00.000Z",
    "min" : "2018-12-28T16:45:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2840,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3254,
        "0" : 3158
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3255,
        "0" : 3158
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6983240223463687,
    "processedRowsPerSecond" : 0.6901311249137336
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:14 INFO  MicroBatchExecution:54 - Committed offsets for batch 52. Metadata OffsetSeqMetadata(1546297020000,1589865974467,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:14 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3255,"0":3158}}), end = {"department.police.service.call":{"1":3256,"0":3159}}
2020-05-19 05:26:14 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:14 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3158,3159,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3255,3256,None)
2020-05-19 05:26:14 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:14 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:14 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_208 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_208_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:26:14 INFO  BlockManagerInfo:54 - Added broadcast_208_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:14 INFO  SparkContext:54 - Created broadcast 208 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_209 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_209_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:26:14 INFO  BlockManagerInfo:54 - Added broadcast_209_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:14 INFO  SparkContext:54 - Created broadcast 209 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:14 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2fa38d7f. The input RDD has 10 partitions.
2020-05-19 05:26:14 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Registering RDD 786 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Got job 104 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Final stage: ResultStage 105 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 104)
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 104)
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 104 (MapPartitionsRDD[786] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_210 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_210_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:14 INFO  BlockManagerInfo:54 - Added broadcast_210_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:14 INFO  SparkContext:54 - Created broadcast 210 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[786] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:14 INFO  TaskSchedulerImpl:54 - Adding task set 104.0 with 2 tasks
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 104.0 (TID 624, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 104.0 (TID 625, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:14 INFO  Executor:54 - Running task 0.0 in stage 104.0 (TID 624)
2020-05-19 05:26:14 INFO  Executor:54 - Running task 1.0 in stage 104.0 (TID 625)
2020-05-19 05:26:14 INFO  Executor:54 - Finished task 0.0 in stage 104.0 (TID 624). 2203 bytes result sent to driver
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 104.0 (TID 624) in 22 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:14 INFO  Executor:54 - Finished task 1.0 in stage 104.0 (TID 625). 2203 bytes result sent to driver
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Finished task 1.0 in stage 104.0 (TID 625) in 28 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2020-05-19 05:26:14 INFO  DAGScheduler:54 - ShuffleMapStage 104 (start at NativeMethodAccessorImpl.java:0) finished in 0.036 s
2020-05-19 05:26:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:14 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 105)
2020-05-19 05:26:14 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Submitting ResultStage 105 (MapPartitionsRDD[792] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_211 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:14 INFO  MemoryStore:54 - Block broadcast_211_piece0 stored as bytes in memory (estimated size 19.0 KB, free 364.3 MB)
2020-05-19 05:26:14 INFO  BlockManagerInfo:54 - Added broadcast_211_piece0 in memory on 234cbc3ca30b:38543 (size: 19.0 KB, free: 366.1 MB)
2020-05-19 05:26:14 INFO  SparkContext:54 - Created broadcast 211 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:14 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 105 (MapPartitionsRDD[792] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:14 INFO  TaskSchedulerImpl:54 - Adding task set 105.0 with 10 tasks
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 105.0 (TID 626, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 105.0 (TID 627, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:14 INFO  Executor:54 - Running task 1.0 in stage 105.0 (TID 627)
2020-05-19 05:26:14 INFO  Executor:54 - Running task 0.0 in stage 105.0 (TID 626)
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b51a908
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@609d5a87
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@724d0a40
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:14 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:14 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e32a7a2
2020-05-19 05:26:14 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/53.delta
2020-05-19 05:26:14 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/53.delta
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:14 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 0.0 in stage 105.0 (TID 626). 34566 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 2.0 in stage 105.0 (TID 628, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 2.0 in stage 105.0 (TID 628)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 105.0 (TID 626) in 86 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23feab55
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57921de4
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 1.0 in stage 105.0 (TID 627). 33577 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 3.0 in stage 105.0 (TID 629, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 3.0 in stage 105.0 (TID 629)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 1.0 in stage 105.0 (TID 627) in 121 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@754fa12b
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dbcf4ee
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 2.0 in stage 105.0 (TID 628). 35122 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 4.0 in stage 105.0 (TID 630, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 4.0 in stage 105.0 (TID 630)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 2.0 in stage 105.0 (TID 628) in 167 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@699e12f4
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c950733
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 3.0 in stage 105.0 (TID 629). 36216 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 5.0 in stage 105.0 (TID 631, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 3.0 in stage 105.0 (TID 629) in 145 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 5.0 in stage 105.0 (TID 631)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d0cb7b7
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f01c17c
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 5.0 in stage 105.0 (TID 631). 38041 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 6.0 in stage 105.0 (TID 632, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 5.0 in stage 105.0 (TID 631) in 146 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 6.0 in stage 105.0 (TID 632)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74c32d8a
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 4.0 in stage 105.0 (TID 630). 36032 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 7.0 in stage 105.0 (TID 633, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 4.0 in stage 105.0 (TID 630) in 172 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 7.0 in stage 105.0 (TID 633)
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b757d0b
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@684ec902
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@750d4ad
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 6.0 in stage 105.0 (TID 632). 38936 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 8.0 in stage 105.0 (TID 634, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 6.0 in stage 105.0 (TID 632) in 110 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 8.0 in stage 105.0 (TID 634)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ecd32a
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bdc0705
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 7.0 in stage 105.0 (TID 633). 36299 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Starting task 9.0 in stage 105.0 (TID 635, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:15 INFO  Executor:54 - Running task 9.0 in stage 105.0 (TID 635)
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 7.0 in stage 105.0 (TID 633) in 125 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4824722d
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:15 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:15 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:15 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4683055f
2020-05-19 05:26:15 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 52 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Committed version 53 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/53.delta
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:15 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 8.0 in stage 105.0 (TID 634). 35352 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 8.0 in stage 105.0 (TID 634) in 129 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:15 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 53 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:15 INFO  Executor:54 - Finished task 9.0 in stage 105.0 (TID 635). 34810 bytes result sent to driver
2020-05-19 05:26:15 INFO  TaskSetManager:54 - Finished task 9.0 in stage 105.0 (TID 635) in 110 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2020-05-19 05:26:15 INFO  DAGScheduler:54 - ResultStage 105 (start at NativeMethodAccessorImpl.java:0) finished in 0.655 s
2020-05-19 05:26:15 INFO  DAGScheduler:54 - Job 104 finished: start at NativeMethodAccessorImpl.java:0, took 0.699262 s
2020-05-19 05:26:15 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2fa38d7f is committing.
-------------------------------------------
Batch: 52
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:15 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2fa38d7f committed.
2020-05-19 05:26:15 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:15 INFO  DAGScheduler:54 - Job 105 finished: start at NativeMethodAccessorImpl.java:0, took 0.000040 s
2020-05-19 05:26:15 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:14.448Z",
  "batchId" : 52,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.2706480304955527,
  "processedRowsPerSecond" : 1.461988304093567,
  "durationMs" : {
    "addBatch" : 1206,
    "getBatch" : 4,
    "getOffset" : 19,
    "queryPlanning" : 64,
    "triggerExecution" : 1368,
    "walCommit" : 74
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:44:00.000Z",
    "max" : "2018-12-28T16:44:00.000Z",
    "min" : "2018-12-28T16:44:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2841,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3255,
        "0" : 3158
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3256,
        "0" : 3159
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.2706480304955527,
    "processedRowsPerSecond" : 1.461988304093567
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:15 INFO  MicroBatchExecution:54 - Committed offsets for batch 53. Metadata OffsetSeqMetadata(1546297020000,1589865975899,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:15 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3256,"0":3159}}), end = {"department.police.service.call":{"1":3256,"0":3160}}
2020-05-19 05:26:15 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:15 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3159,3160,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3256,3256,None)
2020-05-19 05:26:16 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:16 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:16 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_212 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_212_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Added broadcast_212_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:16 INFO  SparkContext:54 - Created broadcast 212 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4663
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4559
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4654
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4672
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4713
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4610
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4659
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4701
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4676
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4617
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4665
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4625
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4640
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4704
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4700
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4564
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4583
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4711
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4669
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4643
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4696
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4566
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_204_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4613
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4621
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4567
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4562
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4554
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4645
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4595
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4706
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4657
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4708
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4693
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4649
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4606
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4690
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4560
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4555
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_209_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4716
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4587
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4635
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4675
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4639
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4597
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4637
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4689
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4622
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4601
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4579
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4565
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4655
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4575
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4600
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4685
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4547
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4710
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4550
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4570
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4576
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4614
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4650
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4552
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4630
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_211_piece0 on 234cbc3ca30b:38543 in memory (size: 19.0 KB, free: 366.1 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4667
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4574
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4578
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4705
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4694
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4545
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4590
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4603
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4692
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4548
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4683
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4611
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4615
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned shuffle 52
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4558
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4557
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4602
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4636
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4586
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4596
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4717
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4680
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4718
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4651
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4541
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4544
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4681
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4604
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4670
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4563
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4607
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4634
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4684
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4709
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4582
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4715
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4580
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4619
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4632
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4691
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4589
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4627
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4585
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4697
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4581
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4620
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4624
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4571
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4626
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4568
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4609
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4569
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_208_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4608
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4628
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4599
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4652
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4688
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4698
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4623
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4618
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4695
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4553
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4543
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4666
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4679
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4616
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4546
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4551
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4720
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4658
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4653
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4573
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4703
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned shuffle 51
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4702
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4577
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4591
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4646
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4592
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4699
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4633
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4594
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4662
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4584
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4707
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4593
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4712
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4572
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4561
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4631
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4605
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4556
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4660
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4686
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4714
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4661
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4644
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4674
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4549
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4656
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4687
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_210_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4598
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4682
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4588
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4647
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_205_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4641
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Removed broadcast_207_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4648
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4673
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4638
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4677
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4642
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4612
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4678
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4664
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4668
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4671
2020-05-19 05:26:16 INFO  ContextCleaner:54 - Cleaned accumulator 4629
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_213 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_213_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Added broadcast_213_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  SparkContext:54 - Created broadcast 213 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:16 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1ec5d040. The input RDD has 10 partitions.
2020-05-19 05:26:16 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Registering RDD 801 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Got job 106 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Final stage: ResultStage 107 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 106)
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 106)
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 106 (MapPartitionsRDD[801] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_214 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_214_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Added broadcast_214_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  SparkContext:54 - Created broadcast 214 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[801] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:16 INFO  TaskSchedulerImpl:54 - Adding task set 106.0 with 2 tasks
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 106.0 (TID 636, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 1.0 in stage 106.0 (TID 637, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 1.0 in stage 106.0 (TID 637)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 0.0 in stage 106.0 (TID 636)
2020-05-19 05:26:16 INFO  KafkaSourceRDD:54 - Beginning offset 3256 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 1.0 in stage 106.0 (TID 637). 2074 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 1.0 in stage 106.0 (TID 637) in 14 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 0.0 in stage 106.0 (TID 636). 2203 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 106.0 (TID 636) in 25 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2020-05-19 05:26:16 INFO  DAGScheduler:54 - ShuffleMapStage 106 (start at NativeMethodAccessorImpl.java:0) finished in 0.031 s
2020-05-19 05:26:16 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:16 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:16 INFO  DAGScheduler:54 - waiting: Set(ResultStage 107)
2020-05-19 05:26:16 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Submitting ResultStage 107 (MapPartitionsRDD[807] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_215 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:26:16 INFO  MemoryStore:54 - Block broadcast_215_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:26:16 INFO  BlockManagerInfo:54 - Added broadcast_215_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:16 INFO  SparkContext:54 - Created broadcast 215 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:16 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 107 (MapPartitionsRDD[807] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:16 INFO  TaskSchedulerImpl:54 - Adding task set 107.0 with 10 tasks
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 107.0 (TID 638, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 1.0 in stage 107.0 (TID 639, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 1.0 in stage 107.0 (TID 639)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 0.0 in stage 107.0 (TID 638)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26761976
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a909039
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bf83c38
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e7cee87
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 0.0 in stage 107.0 (TID 638). 34566 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 2.0 in stage 107.0 (TID 640, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 2.0 in stage 107.0 (TID 640)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 107.0 (TID 638) in 129 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31fbc993
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f7c9d76
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 1.0 in stage 107.0 (TID 639). 33577 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 3.0 in stage 107.0 (TID 641, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 1.0 in stage 107.0 (TID 639) in 152 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 3.0 in stage 107.0 (TID 641)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45155bce
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21677172
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/54.delta
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 2.0 in stage 107.0 (TID 640). 35122 bytes result sent to driver
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 4.0 in stage 107.0 (TID 642, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 2.0 in stage 107.0 (TID 640) in 115 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 4.0 in stage 107.0 (TID 642)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b32898
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a4e71a6
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 3.0 in stage 107.0 (TID 641). 36216 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 5.0 in stage 107.0 (TID 643, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 3.0 in stage 107.0 (TID 641) in 114 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 5.0 in stage 107.0 (TID 643)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3070f4d7
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@424a22a1
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/54.delta
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 4.0 in stage 107.0 (TID 642). 36032 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 6.0 in stage 107.0 (TID 644, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 6.0 in stage 107.0 (TID 644)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 4.0 in stage 107.0 (TID 642) in 93 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68348af1
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6109f4e1
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 5.0 in stage 107.0 (TID 643). 38143 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 7.0 in stage 107.0 (TID 645, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 7.0 in stage 107.0 (TID 645)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 5.0 in stage 107.0 (TID 643) in 121 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28db5833
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cd70a3
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/54.delta
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:16 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 6.0 in stage 107.0 (TID 644). 38936 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 6.0 in stage 107.0 (TID 644) in 167 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 8.0 in stage 107.0 (TID 646, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 8.0 in stage 107.0 (TID 646)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f57fb17
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bd213c0
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:16 INFO  Executor:54 - Finished task 7.0 in stage 107.0 (TID 645). 36299 bytes result sent to driver
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Starting task 9.0 in stage 107.0 (TID 647, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:16 INFO  Executor:54 - Running task 9.0 in stage 107.0 (TID 647)
2020-05-19 05:26:16 INFO  TaskSetManager:54 - Finished task 7.0 in stage 107.0 (TID 645) in 142 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@110f07a8
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:16 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:16 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:16 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ca048d
2020-05-19 05:26:16 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:16 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 53 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/54.delta
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 54 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/54.delta
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 9.0 in stage 107.0 (TID 647). 34810 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 9.0 in stage 107.0 (TID 647) in 130 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 54 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 8.0 in stage 107.0 (TID 646). 35352 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 8.0 in stage 107.0 (TID 646) in 180 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2020-05-19 05:26:17 INFO  DAGScheduler:54 - ResultStage 107 (start at NativeMethodAccessorImpl.java:0) finished in 0.688 s
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Job 106 finished: start at NativeMethodAccessorImpl.java:0, took 0.725054 s
2020-05-19 05:26:17 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1ec5d040 is committing.
-------------------------------------------
Batch: 53
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:17 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1ec5d040 committed.
2020-05-19 05:26:17 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Job 107 finished: start at NativeMethodAccessorImpl.java:0, took 0.000048 s
2020-05-19 05:26:17 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:15.890Z",
  "batchId" : 53,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6934812760055479,
  "processedRowsPerSecond" : 0.7027406886858749,
  "durationMs" : {
    "addBatch" : 1252,
    "getBatch" : 4,
    "getOffset" : 9,
    "queryPlanning" : 70,
    "triggerExecution" : 1423,
    "walCommit" : 87
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:42:00.000Z",
    "max" : "2018-12-28T16:42:00.000Z",
    "min" : "2018-12-28T16:42:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2842,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3256,
        "0" : 3159
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3256,
        "0" : 3160
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6934812760055479,
    "processedRowsPerSecond" : 0.7027406886858749
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:17 INFO  MicroBatchExecution:54 - Committed offsets for batch 54. Metadata OffsetSeqMetadata(1546297020000,1589865977415,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:17 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3256,"0":3160}}), end = {"department.police.service.call":{"1":3257,"0":3161}}
2020-05-19 05:26:17 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:17 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3160,3161,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3256,3257,None)
2020-05-19 05:26:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_216 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_216_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:17 INFO  BlockManagerInfo:54 - Added broadcast_216_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:17 INFO  SparkContext:54 - Created broadcast 216 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_217 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_217_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:17 INFO  BlockManagerInfo:54 - Added broadcast_217_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:17 INFO  SparkContext:54 - Created broadcast 217 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:17 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@23867d01. The input RDD has 10 partitions.
2020-05-19 05:26:17 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Registering RDD 816 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Got job 108 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Final stage: ResultStage 109 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 108)
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 108)
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 108 (MapPartitionsRDD[816] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_218 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_218_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:17 INFO  BlockManagerInfo:54 - Added broadcast_218_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:17 INFO  SparkContext:54 - Created broadcast 218 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[816] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:17 INFO  TaskSchedulerImpl:54 - Adding task set 108.0 with 2 tasks
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 108.0 (TID 648, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 108.0 (TID 649, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 0.0 in stage 108.0 (TID 648)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 1.0 in stage 108.0 (TID 649)
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 0.0 in stage 108.0 (TID 648). 2203 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 108.0 (TID 648) in 31 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 1.0 in stage 108.0 (TID 649). 2203 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 108.0 (TID 649) in 36 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2020-05-19 05:26:17 INFO  DAGScheduler:54 - ShuffleMapStage 108 (start at NativeMethodAccessorImpl.java:0) finished in 0.042 s
2020-05-19 05:26:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:17 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 109)
2020-05-19 05:26:17 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Submitting ResultStage 109 (MapPartitionsRDD[822] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_219 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:17 INFO  MemoryStore:54 - Block broadcast_219_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:17 INFO  BlockManagerInfo:54 - Added broadcast_219_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:17 INFO  SparkContext:54 - Created broadcast 219 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:17 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 109 (MapPartitionsRDD[822] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:17 INFO  TaskSchedulerImpl:54 - Adding task set 109.0 with 10 tasks
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 109.0 (TID 650, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 109.0 (TID 651, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 0.0 in stage 109.0 (TID 650)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 1.0 in stage 109.0 (TID 651)
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aca86cc
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aab4528
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16a72f92
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@994a074
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks out of 2 blocks
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/55.delta
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/55.delta
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:17 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 0.0 in stage 109.0 (TID 650). 34566 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 2.0 in stage 109.0 (TID 652, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 2.0 in stage 109.0 (TID 652)
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 109.0 (TID 650) in 78 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ce95282
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66074e30
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:17 INFO  Executor:54 - Finished task 1.0 in stage 109.0 (TID 651). 33577 bytes result sent to driver
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Starting task 3.0 in stage 109.0 (TID 653, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:17 INFO  Executor:54 - Running task 3.0 in stage 109.0 (TID 653)
2020-05-19 05:26:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 109.0 (TID 651) in 95 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@176e9f61
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:17 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:17 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:17 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d6b481e
2020-05-19 05:26:17 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/55.delta
2020-05-19 05:26:17 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/55.delta
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 3.0 in stage 109.0 (TID 653). 36216 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 4.0 in stage 109.0 (TID 654, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 4.0 in stage 109.0 (TID 654)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 3.0 in stage 109.0 (TID 653) in 115 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 2.0 in stage 109.0 (TID 652). 35122 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 5.0 in stage 109.0 (TID 655, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 2.0 in stage 109.0 (TID 652) in 137 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 5.0 in stage 109.0 (TID 655)
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@677fc01c
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5018695f
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76d09aea
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a811db
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/55.delta
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/55.delta
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 5.0 in stage 109.0 (TID 655). 38143 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 6.0 in stage 109.0 (TID 656, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 6.0 in stage 109.0 (TID 656)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 5.0 in stage 109.0 (TID 655) in 125 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@da7a7ac
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e6a348f
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 4.0 in stage 109.0 (TID 654). 36032 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 7.0 in stage 109.0 (TID 657, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 4.0 in stage 109.0 (TID 654) in 142 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 7.0 in stage 109.0 (TID 657)
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56ce5867
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c047ce6
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/55.delta
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/55.delta
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 6.0 in stage 109.0 (TID 656). 38936 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 8.0 in stage 109.0 (TID 658, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 8.0 in stage 109.0 (TID 658)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 6.0 in stage 109.0 (TID 656) in 182 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d2f0301
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b0a594
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 7.0 in stage 109.0 (TID 657). 36299 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Starting task 9.0 in stage 109.0 (TID 659, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:18 INFO  Executor:54 - Running task 9.0 in stage 109.0 (TID 659)
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 7.0 in stage 109.0 (TID 657) in 190 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dc72b4
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:18 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:18 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:18 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aa4f1e8
2020-05-19 05:26:18 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 54 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/55.delta
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Committed version 55 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/55.delta
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4746
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4801
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4730
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4779
2020-05-19 05:26:18 INFO  BlockManagerInfo:54 - Removed broadcast_213_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4767
2020-05-19 05:26:18 INFO  BlockManagerInfo:54 - Removed broadcast_212_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4772
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4768
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4800
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4752
2020-05-19 05:26:18 INFO  BlockManagerInfo:54 - Removed broadcast_218_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4765
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4762
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4742
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4741
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4763
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4774
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4761
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4759
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4796
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4738
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4760
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4766
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4740
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4787
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4793
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4755
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4771
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4788
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4743
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4807
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4782
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4805
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4733
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4802
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned shuffle 53
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4719
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4809
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4753
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4776
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4798
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4790
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4775
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4744
2020-05-19 05:26:18 INFO  BlockManagerInfo:54 - Removed broadcast_214_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4751
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4750
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4795
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4756
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4797
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4726
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4745
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4734
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4786
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4732
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4728
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4757
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4777
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4781
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4792
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4764
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4723
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4806
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4778
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4758
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4791
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4799
2020-05-19 05:26:18 INFO  BlockManagerInfo:54 - Removed broadcast_215_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4736
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4789
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4773
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4724
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4785
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4722
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4794
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4748
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4770
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4737
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4754
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4769
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4804
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4783
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4780
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4727
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4721
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4784
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4731
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4725
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4739
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4729
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4749
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4803
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4747
2020-05-19 05:26:18 INFO  ContextCleaner:54 - Cleaned accumulator 4735
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:18 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 8.0 in stage 109.0 (TID 658). 35395 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 8.0 in stage 109.0 (TID 658) in 184 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:18 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 55 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:18 INFO  Executor:54 - Finished task 9.0 in stage 109.0 (TID 659). 34853 bytes result sent to driver
2020-05-19 05:26:18 INFO  TaskSetManager:54 - Finished task 9.0 in stage 109.0 (TID 659) in 172 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2020-05-19 05:26:18 INFO  DAGScheduler:54 - ResultStage 109 (start at NativeMethodAccessorImpl.java:0) finished in 0.713 s
2020-05-19 05:26:18 INFO  DAGScheduler:54 - Job 108 finished: start at NativeMethodAccessorImpl.java:0, took 0.761216 s
2020-05-19 05:26:18 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@23867d01 is committing.
-------------------------------------------
Batch: 54
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:18 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@23867d01 committed.
2020-05-19 05:26:18 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:18 INFO  DAGScheduler:54 - Job 109 finished: start at NativeMethodAccessorImpl.java:0, took 0.000043 s
2020-05-19 05:26:18 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:17.412Z",
  "batchId" : 54,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.314060446780552,
  "processedRowsPerSecond" : 1.3908205841446455,
  "durationMs" : {
    "addBatch" : 1326,
    "getBatch" : 3,
    "getOffset" : 2,
    "queryPlanning" : 61,
    "triggerExecution" : 1437,
    "walCommit" : 44
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:42:00.000Z",
    "max" : "2018-12-28T16:42:00.000Z",
    "min" : "2018-12-28T16:42:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2842,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3256,
        "0" : 3160
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3257,
        "0" : 3161
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.314060446780552,
    "processedRowsPerSecond" : 1.3908205841446455
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:19 INFO  MicroBatchExecution:54 - Committed offsets for batch 55. Metadata OffsetSeqMetadata(1546297020000,1589865978971,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:19 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3257,"0":3161}}), end = {"department.police.service.call":{"1":3257,"0":3162}}
2020-05-19 05:26:19 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:19 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3161,3162,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3257,3257,None)
2020-05-19 05:26:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:19 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_220 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_220_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:26:19 INFO  BlockManagerInfo:54 - Added broadcast_220_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:19 INFO  SparkContext:54 - Created broadcast 220 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_221 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_221_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:26:19 INFO  BlockManagerInfo:54 - Added broadcast_221_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:19 INFO  SparkContext:54 - Created broadcast 221 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:19 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7be9f203. The input RDD has 10 partitions.
2020-05-19 05:26:19 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Registering RDD 831 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Got job 110 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Final stage: ResultStage 111 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 110)
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 110)
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 110 (MapPartitionsRDD[831] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_222 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_222_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:19 INFO  BlockManagerInfo:54 - Added broadcast_222_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:19 INFO  SparkContext:54 - Created broadcast 222 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[831] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:19 INFO  TaskSchedulerImpl:54 - Adding task set 110.0 with 2 tasks
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 110.0 (TID 660, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 110.0 (TID 661, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 0.0 in stage 110.0 (TID 660)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 1.0 in stage 110.0 (TID 661)
2020-05-19 05:26:19 INFO  KafkaSourceRDD:54 - Beginning offset 3257 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 1.0 in stage 110.0 (TID 661). 2074 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 110.0 (TID 661) in 36 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 0.0 in stage 110.0 (TID 660). 2203 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 110.0 (TID 660) in 42 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2020-05-19 05:26:19 INFO  DAGScheduler:54 - ShuffleMapStage 110 (start at NativeMethodAccessorImpl.java:0) finished in 0.048 s
2020-05-19 05:26:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:19 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 111)
2020-05-19 05:26:19 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Submitting ResultStage 111 (MapPartitionsRDD[837] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_223 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:19 INFO  MemoryStore:54 - Block broadcast_223_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:26:19 INFO  BlockManagerInfo:54 - Added broadcast_223_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:19 INFO  SparkContext:54 - Created broadcast 223 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:19 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 111 (MapPartitionsRDD[837] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:19 INFO  TaskSchedulerImpl:54 - Adding task set 111.0 with 10 tasks
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 111.0 (TID 662, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 111.0 (TID 663, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 1.0 in stage 111.0 (TID 663)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 0.0 in stage 111.0 (TID 662)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@728bf96
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a1298f1
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61203b24
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5252bbb6
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 0.0 in stage 111.0 (TID 662). 34566 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 2.0 in stage 111.0 (TID 664, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 111.0 (TID 662) in 125 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 2.0 in stage 111.0 (TID 664)
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 1.0 in stage 111.0 (TID 663). 33577 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 3.0 in stage 111.0 (TID 665, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 3.0 in stage 111.0 (TID 665)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 111.0 (TID 663) in 128 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e84af45
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a7e3f66
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76730dd2
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2235b700
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/56.delta
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 2.0 in stage 111.0 (TID 664). 35122 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 4.0 in stage 111.0 (TID 666, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 4.0 in stage 111.0 (TID 666)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 2.0 in stage 111.0 (TID 664) in 102 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@439c5b34
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 3.0 in stage 111.0 (TID 665). 36216 bytes result sent to driver
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36c17ead
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 5.0 in stage 111.0 (TID 667, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 3.0 in stage 111.0 (TID 665) in 105 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 5.0 in stage 111.0 (TID 667)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@653127a0
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d051a98
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 4.0 in stage 111.0 (TID 666). 36032 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 6.0 in stage 111.0 (TID 668, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 4.0 in stage 111.0 (TID 666) in 80 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 6.0 in stage 111.0 (TID 668)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28c57ab
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dcb5774
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 5.0 in stage 111.0 (TID 667). 38143 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 7.0 in stage 111.0 (TID 669, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 5.0 in stage 111.0 (TID 667) in 109 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 7.0 in stage 111.0 (TID 669)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a87bfda
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4be9288b
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 6.0 in stage 111.0 (TID 668). 38936 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 8.0 in stage 111.0 (TID 670, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 8.0 in stage 111.0 (TID 670)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 6.0 in stage 111.0 (TID 668) in 156 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ba330a
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b7c7a6
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 7.0 in stage 111.0 (TID 669). 36299 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Starting task 9.0 in stage 111.0 (TID 671, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 7.0 in stage 111.0 (TID 669) in 167 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:19 INFO  Executor:54 - Running task 9.0 in stage 111.0 (TID 671)
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ec72e24
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:19 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:19 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:19 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d29ded6
2020-05-19 05:26:19 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 55 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:19 INFO  Executor:54 - Finished task 8.0 in stage 111.0 (TID 670). 35352 bytes result sent to driver
2020-05-19 05:26:19 INFO  TaskSetManager:54 - Finished task 8.0 in stage 111.0 (TID 670) in 86 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:19 INFO  HDFSBackedStateStoreProvider:54 - Committed version 56 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/56.delta
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:19 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 56 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:20 INFO  Executor:54 - Finished task 9.0 in stage 111.0 (TID 671). 34810 bytes result sent to driver
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Finished task 9.0 in stage 111.0 (TID 671) in 95 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2020-05-19 05:26:20 INFO  DAGScheduler:54 - ResultStage 111 (start at NativeMethodAccessorImpl.java:0) finished in 0.610 s
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Job 110 finished: start at NativeMethodAccessorImpl.java:0, took 0.663082 s
2020-05-19 05:26:20 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7be9f203 is committing.
-------------------------------------------
Batch: 55
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:20 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@7be9f203 committed.
2020-05-19 05:26:20 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Job 111 finished: start at NativeMethodAccessorImpl.java:0, took 0.000044 s
2020-05-19 05:26:20 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:18.966Z",
  "batchId" : 55,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.6435006435006435,
  "processedRowsPerSecond" : 0.7980845969672786,
  "durationMs" : {
    "addBatch" : 1047,
    "getBatch" : 4,
    "getOffset" : 5,
    "queryPlanning" : 71,
    "triggerExecution" : 1253,
    "walCommit" : 124
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:41:00.000Z",
    "max" : "2018-12-28T16:41:00.000Z",
    "min" : "2018-12-28T16:41:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2842,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3257,
        "0" : 3161
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3257,
        "0" : 3162
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.6435006435006435,
    "processedRowsPerSecond" : 0.7980845969672786
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:20 INFO  MicroBatchExecution:54 - Committed offsets for batch 56. Metadata OffsetSeqMetadata(1546297020000,1589865980294,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:20 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3257,"0":3162}}), end = {"department.police.service.call":{"1":3258,"0":3162}}
2020-05-19 05:26:20 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:20 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3162,3162,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3257,3258,None)
2020-05-19 05:26:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_224 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_224_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Added broadcast_224_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:20 INFO  SparkContext:54 - Created broadcast 224 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_225 stored as values in memory (estimated size 281.8 KB, free 363.7 MB)
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_225_piece0 stored as bytes in memory (estimated size 24.1 KB, free 363.7 MB)
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Added broadcast_225_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.0 MB)
2020-05-19 05:26:20 INFO  SparkContext:54 - Created broadcast 225 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:20 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@583ebaa1. The input RDD has 10 partitions.
2020-05-19 05:26:20 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Registering RDD 846 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Got job 112 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Final stage: ResultStage 113 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 112)
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 112)
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 112 (MapPartitionsRDD[846] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_226 stored as values in memory (estimated size 39.1 KB, free 363.6 MB)
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_226_piece0 stored as bytes in memory (estimated size 15.8 KB, free 363.6 MB)
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Added broadcast_226_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.0 MB)
2020-05-19 05:26:20 INFO  SparkContext:54 - Created broadcast 226 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[846] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:20 INFO  TaskSchedulerImpl:54 - Adding task set 112.0 with 2 tasks
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 112.0 (TID 672, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 112.0 (TID 673, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 0.0 in stage 112.0 (TID 672)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 1.0 in stage 112.0 (TID 673)
2020-05-19 05:26:20 INFO  KafkaSourceRDD:54 - Beginning offset 3162 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:26:20 INFO  Executor:54 - Finished task 0.0 in stage 112.0 (TID 672). 2074 bytes result sent to driver
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 112.0 (TID 672) in 32 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:20 INFO  Executor:54 - Finished task 1.0 in stage 112.0 (TID 673). 2246 bytes result sent to driver
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Finished task 1.0 in stage 112.0 (TID 673) in 40 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2020-05-19 05:26:20 INFO  DAGScheduler:54 - ShuffleMapStage 112 (start at NativeMethodAccessorImpl.java:0) finished in 0.049 s
2020-05-19 05:26:20 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:20 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 113)
2020-05-19 05:26:20 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Submitting ResultStage 113 (MapPartitionsRDD[852] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_227 stored as values in memory (estimated size 54.1 KB, free 363.6 MB)
2020-05-19 05:26:20 INFO  MemoryStore:54 - Block broadcast_227_piece0 stored as bytes in memory (estimated size 19.1 KB, free 363.5 MB)
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Added broadcast_227_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.0 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4956
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4959
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4981
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4982
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4875
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4909
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4935
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4857
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4901
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4894
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4902
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4932
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_222_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.0 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4814
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4880
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4960
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4884
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4915
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4951
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4969
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4830
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4848
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4892
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4849
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4873
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4826
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4815
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4879
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4822
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4816
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4939
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4904
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4820
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4910
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4860
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4866
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4888
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4974
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4874
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4921
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4872
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4839
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4903
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4984
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4842
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4881
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4979
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4867
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4828
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4863
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4934
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4854
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4831
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4870
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4862
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4973
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4832
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4965
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4922
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4955
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4886
2020-05-19 05:26:20 INFO  SparkContext:54 - Created broadcast 227 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:20 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 113 (MapPartitionsRDD[852] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:20 INFO  TaskSchedulerImpl:54 - Adding task set 113.0 with 10 tasks
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_221_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.0 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4937
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4851
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4968
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4808
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 113.0 (TID 674, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 113.0 (TID 675, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 0.0 in stage 113.0 (TID 674)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 1.0 in stage 113.0 (TID 675)
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@662f8e6e
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4840
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4883
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4858
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4896
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4898
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4885
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4893
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4823
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4827
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4835
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4946
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4933
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4944
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4877
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4821
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4843
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4914
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4963
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19ca4b88
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_217_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d61fd82
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4941
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4962
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4895
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4908
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4817
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4940
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4818
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4869
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4964
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4936
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4855
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4925
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4850
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4864
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4861
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4945
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4948
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4824
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4825
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4810
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4891
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4905
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4952
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4859
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4916
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4882
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50713669
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned shuffle 55
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4983
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4841
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4897
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_223_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4926
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4833
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4865
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4985
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4837
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4856
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4967
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_216_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4942
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4912
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4899
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4949
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4845
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4907
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4928
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4919
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4961
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4887
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4868
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4950
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4846
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4987
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4819
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4978
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4943
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4966
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4844
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4871
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4829
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4975
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4954
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4811
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4938
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4834
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4930
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4958
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4927
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4813
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4917
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4913
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4931
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4947
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4812
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned shuffle 54
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4878
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4920
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4836
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4957
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4972
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_220_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4970
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4890
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4876
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4918
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4906
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4900
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4953
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4971
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4853
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4923
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4929
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4980
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4847
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4889
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4911
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4976
2020-05-19 05:26:20 INFO  BlockManagerInfo:54 - Removed broadcast_219_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4924
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4977
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4838
2020-05-19 05:26:20 INFO  ContextCleaner:54 - Cleaned accumulator 4852
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/57.delta
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/57.delta
2020-05-19 05:26:20 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:20 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:20 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:20 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:20 INFO  Executor:54 - Finished task 1.0 in stage 113.0 (TID 675). 33577 bytes result sent to driver
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 2.0 in stage 113.0 (TID 676, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 2.0 in stage 113.0 (TID 676)
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Finished task 1.0 in stage 113.0 (TID 675) in 95 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a618efe
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44ed5da7
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:20 INFO  Executor:54 - Finished task 0.0 in stage 113.0 (TID 674). 34566 bytes result sent to driver
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Starting task 3.0 in stage 113.0 (TID 677, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:20 INFO  Executor:54 - Running task 3.0 in stage 113.0 (TID 677)
2020-05-19 05:26:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 113.0 (TID 674) in 112 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f31b20a
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:20 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:20 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:20 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fef5a4d
2020-05-19 05:26:20 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:20 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 2.0 in stage 113.0 (TID 676). 35122 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 4.0 in stage 113.0 (TID 678, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 4.0 in stage 113.0 (TID 678)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 2.0 in stage 113.0 (TID 676) in 85 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@255e3106
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3825808f
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 3.0 in stage 113.0 (TID 677). 36216 bytes result sent to driver
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 5.0 in stage 113.0 (TID 679, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 3.0 in stage 113.0 (TID 677) in 78 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 5.0 in stage 113.0 (TID 679)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 6 ms
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4219c3ba
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4898ce9
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/57.delta
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 4.0 in stage 113.0 (TID 678). 36032 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 6.0 in stage 113.0 (TID 680, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 6.0 in stage 113.0 (TID 680)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 4.0 in stage 113.0 (TID 678) in 148 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3592eabd
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e144e56
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 5.0 in stage 113.0 (TID 679). 38143 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 7.0 in stage 113.0 (TID 681, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 7.0 in stage 113.0 (TID 681)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 5.0 in stage 113.0 (TID 679) in 152 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fa741f1
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48c259bc
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 7.0 in stage 113.0 (TID 681). 36299 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 8.0 in stage 113.0 (TID 682, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 7.0 in stage 113.0 (TID 681) in 81 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 8.0 in stage 113.0 (TID 682)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f0cd9ff
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 6.0 in stage 113.0 (TID 680). 38936 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Starting task 9.0 in stage 113.0 (TID 683, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 6.0 in stage 113.0 (TID 680) in 102 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:21 INFO  Executor:54 - Running task 9.0 in stage 113.0 (TID 683)
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ef5ae44
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@457db73d
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:21 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:21 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:21 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@624ae413
2020-05-19 05:26:21 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 56 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Committed version 57 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/57.delta
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:21 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 9.0 in stage 113.0 (TID 683). 34810 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 9.0 in stage 113.0 (TID 683) in 130 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:21 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 57 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:21 INFO  Executor:54 - Finished task 8.0 in stage 113.0 (TID 682). 35352 bytes result sent to driver
2020-05-19 05:26:21 INFO  TaskSetManager:54 - Finished task 8.0 in stage 113.0 (TID 682) in 171 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:21 INFO  TaskSchedulerImpl:54 - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2020-05-19 05:26:21 INFO  DAGScheduler:54 - ResultStage 113 (start at NativeMethodAccessorImpl.java:0) finished in 0.641 s
2020-05-19 05:26:21 INFO  DAGScheduler:54 - Job 112 finished: start at NativeMethodAccessorImpl.java:0, took 0.699726 s
2020-05-19 05:26:21 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@583ebaa1 is committing.
-------------------------------------------
Batch: 56
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:21 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@583ebaa1 committed.
2020-05-19 05:26:21 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:21 INFO  DAGScheduler:54 - Job 113 finished: start at NativeMethodAccessorImpl.java:0, took 0.000047 s
2020-05-19 05:26:21 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:20.290Z",
  "batchId" : 56,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.755287009063444,
  "processedRowsPerSecond" : 0.702247191011236,
  "durationMs" : {
    "addBatch" : 1201,
    "getBatch" : 19,
    "getOffset" : 4,
    "queryPlanning" : 94,
    "triggerExecution" : 1424,
    "walCommit" : 105
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:41:00.000Z",
    "max" : "2018-12-28T16:41:00.000Z",
    "min" : "2018-12-28T16:41:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2842,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3257,
        "0" : 3162
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3258,
        "0" : 3162
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.755287009063444,
    "processedRowsPerSecond" : 0.702247191011236
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:21 INFO  MicroBatchExecution:54 - Committed offsets for batch 57. Metadata OffsetSeqMetadata(1546297020000,1589865981805,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:21 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3258,"0":3162}}), end = {"department.police.service.call":{"1":3259,"0":3163}}
2020-05-19 05:26:21 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:21 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3162,3163,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3258,3259,None)
2020-05-19 05:26:21 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:21 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:21 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_228 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_228_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:22 INFO  BlockManagerInfo:54 - Added broadcast_228_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:22 INFO  SparkContext:54 - Created broadcast 228 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_229 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_229_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:22 INFO  BlockManagerInfo:54 - Added broadcast_229_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:22 INFO  SparkContext:54 - Created broadcast 229 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:22 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5c32cf10. The input RDD has 10 partitions.
2020-05-19 05:26:22 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Registering RDD 861 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Got job 114 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Final stage: ResultStage 115 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 114)
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 114)
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 114 (MapPartitionsRDD[861] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_230 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_230_piece0 stored as bytes in memory (estimated size 15.7 KB, free 364.3 MB)
2020-05-19 05:26:22 INFO  BlockManagerInfo:54 - Added broadcast_230_piece0 in memory on 234cbc3ca30b:38543 (size: 15.7 KB, free: 366.1 MB)
2020-05-19 05:26:22 INFO  SparkContext:54 - Created broadcast 230 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[861] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:22 INFO  TaskSchedulerImpl:54 - Adding task set 114.0 with 2 tasks
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 114.0 (TID 684, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 1.0 in stage 114.0 (TID 685, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 0.0 in stage 114.0 (TID 684)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 1.0 in stage 114.0 (TID 685)
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 0.0 in stage 114.0 (TID 684). 2203 bytes result sent to driver
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 1.0 in stage 114.0 (TID 685). 2203 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 114.0 (TID 684) in 28 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 1.0 in stage 114.0 (TID 685) in 27 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2020-05-19 05:26:22 INFO  DAGScheduler:54 - ShuffleMapStage 114 (start at NativeMethodAccessorImpl.java:0) finished in 0.035 s
2020-05-19 05:26:22 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:22 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 115)
2020-05-19 05:26:22 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Submitting ResultStage 115 (MapPartitionsRDD[867] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_231 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:22 INFO  MemoryStore:54 - Block broadcast_231_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:22 INFO  BlockManagerInfo:54 - Added broadcast_231_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:22 INFO  SparkContext:54 - Created broadcast 231 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 115 (MapPartitionsRDD[867] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:22 INFO  TaskSchedulerImpl:54 - Adding task set 115.0 with 10 tasks
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 115.0 (TID 686, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 1.0 in stage 115.0 (TID 687, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 1.0 in stage 115.0 (TID 687)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 0.0 in stage 115.0 (TID 686)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1196d1d7
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12a0ec29
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41dc4c94
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eb01fab
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 1.0 in stage 115.0 (TID 687). 33577 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 2.0 in stage 115.0 (TID 688, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 2.0 in stage 115.0 (TID 688)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 1.0 in stage 115.0 (TID 687) in 101 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bbfe66
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21123c68
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 0.0 in stage 115.0 (TID 686). 34566 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 3.0 in stage 115.0 (TID 689, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 3.0 in stage 115.0 (TID 689)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 115.0 (TID 686) in 110 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@226d2db8
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44646768
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/58.delta
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 3.0 in stage 115.0 (TID 689). 36216 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 4.0 in stage 115.0 (TID 690, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 4.0 in stage 115.0 (TID 690)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 3.0 in stage 115.0 (TID 689) in 88 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a214ead
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f6e7d51
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 2.0 in stage 115.0 (TID 688). 35122 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 5.0 in stage 115.0 (TID 691, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 5.0 in stage 115.0 (TID 691)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 2.0 in stage 115.0 (TID 688) in 117 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@194e7839
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26e18ee5
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 4.0 in stage 115.0 (TID 690). 36032 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 6.0 in stage 115.0 (TID 692, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 6.0 in stage 115.0 (TID 692)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 4.0 in stage 115.0 (TID 690) in 121 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dd92d4a
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c7bcd7b
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 5.0 in stage 115.0 (TID 691). 38143 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 7.0 in stage 115.0 (TID 693, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 7.0 in stage 115.0 (TID 693)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 5.0 in stage 115.0 (TID 691) in 132 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612afa9a
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d9238e8
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 6.0 in stage 115.0 (TID 692). 38936 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 8.0 in stage 115.0 (TID 694, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 6.0 in stage 115.0 (TID 692) in 195 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 8.0 in stage 115.0 (TID 694)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11657b21
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@182b348e
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 7.0 in stage 115.0 (TID 693). 36410 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Starting task 9.0 in stage 115.0 (TID 695, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 7.0 in stage 115.0 (TID 693) in 173 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:22 INFO  Executor:54 - Running task 9.0 in stage 115.0 (TID 695)
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21794274
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:22 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:22 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:22 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4badf289
2020-05-19 05:26:22 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 57 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Committed version 58 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/58.delta
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:22 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 8.0 in stage 115.0 (TID 694). 35352 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 8.0 in stage 115.0 (TID 694) in 137 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:22 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 58 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:22 INFO  Executor:54 - Finished task 9.0 in stage 115.0 (TID 695). 34904 bytes result sent to driver
2020-05-19 05:26:22 INFO  TaskSetManager:54 - Finished task 9.0 in stage 115.0 (TID 695) in 136 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2020-05-19 05:26:22 INFO  DAGScheduler:54 - ResultStage 115 (start at NativeMethodAccessorImpl.java:0) finished in 0.665 s
2020-05-19 05:26:22 INFO  DAGScheduler:54 - Job 114 finished: start at NativeMethodAccessorImpl.java:0, took 0.705641 s
2020-05-19 05:26:22 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5c32cf10 is committing.
-------------------------------------------
Batch: 57
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:23 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5c32cf10 committed.
2020-05-19 05:26:23 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Job 115 finished: start at NativeMethodAccessorImpl.java:0, took 0.000037 s
2020-05-19 05:26:23 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:21.802Z",
  "batchId" : 57,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.3227513227513228,
  "processedRowsPerSecond" : 1.5325670498084292,
  "durationMs" : {
    "addBatch" : 1156,
    "getBatch" : 4,
    "getOffset" : 3,
    "queryPlanning" : 43,
    "triggerExecution" : 1305,
    "walCommit" : 98
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:41:00.000Z",
    "max" : "2018-12-28T16:41:00.000Z",
    "min" : "2018-12-28T16:41:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2844,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3258,
        "0" : 3162
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3259,
        "0" : 3163
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.3227513227513228,
    "processedRowsPerSecond" : 1.5325670498084292
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:23 INFO  MicroBatchExecution:54 - Committed offsets for batch 58. Metadata OffsetSeqMetadata(1546297020000,1589865983187,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:23 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3259,"0":3163}}), end = {"department.police.service.call":{"1":3260,"0":3163}}
2020-05-19 05:26:23 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:23 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3163,3163,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3259,3260,None)
2020-05-19 05:26:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4996
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5097
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5083
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5147
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5122
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5066
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5035
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4993
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5013
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5114
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5111
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5027
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5150
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5098
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5119
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5156
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5012
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5034
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5151
2020-05-19 05:26:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:23 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5138
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5096
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5007
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5050
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5025
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5140
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5100
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5041
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5026
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5062
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5060
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4998
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5112
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5094
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5004
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5055
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5058
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5074
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5002
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5146
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5104
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5089
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5161
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4994
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5105
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4991
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5135
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5125
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5130
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_227_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5137
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5000
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5084
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4986
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5123
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5110
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5016
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5075
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5148
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5132
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5109
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5163
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_226_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5131
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_224_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5028
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5056
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5023
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5032
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5043
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5061
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5005
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5001
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5077
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5046
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5057
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5129
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5149
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned shuffle 56
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5143
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5120
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4999
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5069
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5126
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5037
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5040
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5124
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5047
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5099
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5101
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5145
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5003
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_230_piece0 on 234cbc3ca30b:38543 in memory (size: 15.7 KB, free: 366.1 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5042
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5068
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5039
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4989
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5073
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5095
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5036
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5102
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5063
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5054
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5160
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5019
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5106
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5014
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5048
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5064
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5045
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5072
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5159
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5024
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5087
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5065
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5116
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5127
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5157
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5086
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5093
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5051
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5117
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5133
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5155
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5165
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_228_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5121
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5080
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5092
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5052
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5018
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5078
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5107
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5008
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4997
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5154
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5038
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5090
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5029
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4990
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5082
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5071
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5033
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5091
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5141
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5152
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5017
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5103
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5134
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5158
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5115
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5142
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5128
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5021
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5010
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5118
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5070
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5053
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4988
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_229_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4992
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5044
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5136
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5067
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5081
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5049
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5006
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5020
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5144
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5059
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5076
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 4995
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5079
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5011
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5113
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5031
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_225_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Removed broadcast_231_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned shuffle 57
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5015
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5108
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5030
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5022
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5085
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5139
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5153
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5162
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5088
2020-05-19 05:26:23 INFO  ContextCleaner:54 - Cleaned accumulator 5009
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_232 stored as values in memory (estimated size 281.8 KB, free 365.4 MB)
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_232_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.4 MB)
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Added broadcast_232_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  SparkContext:54 - Created broadcast 232 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_233 stored as values in memory (estimated size 281.8 KB, free 365.1 MB)
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_233_piece0 stored as bytes in memory (estimated size 24.1 KB, free 365.1 MB)
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Added broadcast_233_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  SparkContext:54 - Created broadcast 233 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:23 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@a8b1232. The input RDD has 10 partitions.
2020-05-19 05:26:23 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Registering RDD 876 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Got job 116 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Final stage: ResultStage 117 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 116)
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 116)
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 116 (MapPartitionsRDD[876] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_234 stored as values in memory (estimated size 39.1 KB, free 365.0 MB)
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_234_piece0 stored as bytes in memory (estimated size 15.8 KB, free 365.0 MB)
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Added broadcast_234_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  SparkContext:54 - Created broadcast 234 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[876] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:23 INFO  TaskSchedulerImpl:54 - Adding task set 116.0 with 2 tasks
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 116.0 (TID 696, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 1.0 in stage 116.0 (TID 697, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 1.0 in stage 116.0 (TID 697)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 0.0 in stage 116.0 (TID 696)
2020-05-19 05:26:23 INFO  KafkaSourceRDD:54 - Beginning offset 3163 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 1.0 in stage 116.0 (TID 697). 2074 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 1.0 in stage 116.0 (TID 697) in 9 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 0.0 in stage 116.0 (TID 696). 2203 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 116.0 (TID 696) in 25 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2020-05-19 05:26:23 INFO  DAGScheduler:54 - ShuffleMapStage 116 (start at NativeMethodAccessorImpl.java:0) finished in 0.031 s
2020-05-19 05:26:23 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:23 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:23 INFO  DAGScheduler:54 - waiting: Set(ResultStage 117)
2020-05-19 05:26:23 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Submitting ResultStage 117 (MapPartitionsRDD[882] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_235 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:26:23 INFO  MemoryStore:54 - Block broadcast_235_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:26:23 INFO  BlockManagerInfo:54 - Added broadcast_235_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:23 INFO  SparkContext:54 - Created broadcast 235 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:23 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 117 (MapPartitionsRDD[882] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:23 INFO  TaskSchedulerImpl:54 - Adding task set 117.0 with 10 tasks
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 117.0 (TID 698, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 1.0 in stage 117.0 (TID 699, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 1.0 in stage 117.0 (TID 699)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c3f4f06
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5083699
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:23 INFO  Executor:54 - Running task 0.0 in stage 117.0 (TID 698)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51e0862c
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@549a5f9
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/59.delta
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/59.delta
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 1.0 in stage 117.0 (TID 699). 33577 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 2.0 in stage 117.0 (TID 700, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 1.0 in stage 117.0 (TID 699) in 162 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 2.0 in stage 117.0 (TID 700)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cab723f
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56375f9e
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 0.0 in stage 117.0 (TID 698). 34566 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 3.0 in stage 117.0 (TID 701, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 117.0 (TID 698) in 198 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 3.0 in stage 117.0 (TID 701)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bc39867
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77e7ebf8
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/59.delta
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/59.delta
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 2.0 in stage 117.0 (TID 700). 35122 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 4.0 in stage 117.0 (TID 702, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 2.0 in stage 117.0 (TID 700) in 116 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 4.0 in stage 117.0 (TID 702)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15321f6d
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61bf59a2
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 3.0 in stage 117.0 (TID 701). 36216 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 5.0 in stage 117.0 (TID 703, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 3.0 in stage 117.0 (TID 701) in 112 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 5.0 in stage 117.0 (TID 703)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7435cbe7
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24327f98
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/59.delta
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:23 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:23 INFO  Executor:54 - Finished task 4.0 in stage 117.0 (TID 702). 36032 bytes result sent to driver
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Starting task 6.0 in stage 117.0 (TID 704, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:23 INFO  Executor:54 - Running task 6.0 in stage 117.0 (TID 704)
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  TaskSetManager:54 - Finished task 4.0 in stage 117.0 (TID 702) in 117 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d163f3b
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:23 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:23 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:23 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@169be6ac
2020-05-19 05:26:23 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:23 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/59.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 5.0 in stage 117.0 (TID 703). 38143 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 7.0 in stage 117.0 (TID 705, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 7.0 in stage 117.0 (TID 705)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 5.0 in stage 117.0 (TID 703) in 137 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c798148
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17f2c8a1
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/59.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/59.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 6.0 in stage 117.0 (TID 704). 38936 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 8.0 in stage 117.0 (TID 706, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 8.0 in stage 117.0 (TID 706)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 6.0 in stage 117.0 (TID 704) in 146 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@373df5d
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd011a9
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 7.0 in stage 117.0 (TID 705). 36410 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 9.0 in stage 117.0 (TID 707, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 9.0 in stage 117.0 (TID 707)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 7.0 in stage 117.0 (TID 705) in 119 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26d1df6f
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@256e07e7
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 58 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/59.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 59 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/59.delta
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 8.0 in stage 117.0 (TID 706). 35352 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 8.0 in stage 117.0 (TID 706) in 112 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 59 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 9.0 in stage 117.0 (TID 707). 34904 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 9.0 in stage 117.0 (TID 707) in 106 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:24 INFO  TaskSchedulerImpl:54 - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2020-05-19 05:26:24 INFO  DAGScheduler:54 - ResultStage 117 (start at NativeMethodAccessorImpl.java:0) finished in 0.666 s
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Job 116 finished: start at NativeMethodAccessorImpl.java:0, took 0.701310 s
2020-05-19 05:26:24 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@a8b1232 is committing.
-------------------------------------------
Batch: 58
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:24 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@a8b1232 committed.
2020-05-19 05:26:24 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Job 117 finished: start at NativeMethodAccessorImpl.java:0, took 0.000045 s
2020-05-19 05:26:24 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:23.181Z",
  "batchId" : 58,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.7251631617113851,
  "processedRowsPerSecond" : 0.8130081300813008,
  "durationMs" : {
    "addBatch" : 1092,
    "getBatch" : 4,
    "getOffset" : 6,
    "queryPlanning" : 42,
    "triggerExecution" : 1230,
    "walCommit" : 86
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:41:00.000Z",
    "max" : "2018-12-28T16:41:00.000Z",
    "min" : "2018-12-28T16:41:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2844,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3259,
        "0" : 3163
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3260,
        "0" : 3163
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.7251631617113851,
    "processedRowsPerSecond" : 0.8130081300813008
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:24 INFO  MicroBatchExecution:54 - Committed offsets for batch 59. Metadata OffsetSeqMetadata(1546297020000,1589865984538,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:24 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3260,"0":3163}}), end = {"department.police.service.call":{"1":3261,"0":3164}}
2020-05-19 05:26:24 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:24 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3163,3164,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3260,3261,None)
2020-05-19 05:26:24 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:24 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:24 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_236 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_236_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:24 INFO  BlockManagerInfo:54 - Added broadcast_236_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:24 INFO  SparkContext:54 - Created broadcast 236 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_237 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_237_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:24 INFO  BlockManagerInfo:54 - Added broadcast_237_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:24 INFO  SparkContext:54 - Created broadcast 237 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:24 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@60f4c410. The input RDD has 10 partitions.
2020-05-19 05:26:24 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Registering RDD 891 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Got job 118 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Final stage: ResultStage 119 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 118)
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 118)
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 118 (MapPartitionsRDD[891] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_238 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_238_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:24 INFO  BlockManagerInfo:54 - Added broadcast_238_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:24 INFO  SparkContext:54 - Created broadcast 238 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[891] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:24 INFO  TaskSchedulerImpl:54 - Adding task set 118.0 with 2 tasks
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 118.0 (TID 708, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 1.0 in stage 118.0 (TID 709, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 0.0 in stage 118.0 (TID 708)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 1.0 in stage 118.0 (TID 709)
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 0.0 in stage 118.0 (TID 708). 2203 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 0.0 in stage 118.0 (TID 708) in 23 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 1.0 in stage 118.0 (TID 709). 2203 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 1.0 in stage 118.0 (TID 709) in 26 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:24 INFO  TaskSchedulerImpl:54 - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2020-05-19 05:26:24 INFO  DAGScheduler:54 - ShuffleMapStage 118 (start at NativeMethodAccessorImpl.java:0) finished in 0.030 s
2020-05-19 05:26:24 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:24 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:24 INFO  DAGScheduler:54 - waiting: Set(ResultStage 119)
2020-05-19 05:26:24 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Submitting ResultStage 119 (MapPartitionsRDD[897] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_239 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:24 INFO  MemoryStore:54 - Block broadcast_239_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:24 INFO  BlockManagerInfo:54 - Added broadcast_239_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:24 INFO  SparkContext:54 - Created broadcast 239 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:24 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 119 (MapPartitionsRDD[897] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:24 INFO  TaskSchedulerImpl:54 - Adding task set 119.0 with 10 tasks
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 119.0 (TID 710, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 1.0 in stage 119.0 (TID 711, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 1.0 in stage 119.0 (TID 711)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 0.0 in stage 119.0 (TID 710)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7901fe66
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e743c7d
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57967252
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77bf000e
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/60.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/60.delta
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:24 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 1.0 in stage 119.0 (TID 711). 33577 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 2.0 in stage 119.0 (TID 712, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 2.0 in stage 119.0 (TID 712)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 1.0 in stage 119.0 (TID 711) in 112 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a524abf
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6347d8b5
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:24 INFO  Executor:54 - Finished task 0.0 in stage 119.0 (TID 710). 34664 bytes result sent to driver
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Starting task 3.0 in stage 119.0 (TID 713, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:24 INFO  TaskSetManager:54 - Finished task 0.0 in stage 119.0 (TID 710) in 130 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:24 INFO  Executor:54 - Running task 3.0 in stage 119.0 (TID 713)
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@beb1f44
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:24 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:24 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:24 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a06147f
2020-05-19 05:26:24 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:24 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:24 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/60.delta
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 3.0 in stage 119.0 (TID 713). 36319 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 4.0 in stage 119.0 (TID 714, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 3.0 in stage 119.0 (TID 713) in 112 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:25 INFO  Executor:54 - Running task 4.0 in stage 119.0 (TID 714)
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33497b86
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fdafe23
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 2.0 in stage 119.0 (TID 712). 35122 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 5.0 in stage 119.0 (TID 715, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 2.0 in stage 119.0 (TID 712) in 166 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:25 INFO  Executor:54 - Running task 5.0 in stage 119.0 (TID 715)
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48f64637
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e2d3c68
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 4.0 in stage 119.0 (TID 714). 36075 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 6.0 in stage 119.0 (TID 716, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  Executor:54 - Running task 6.0 in stage 119.0 (TID 716)
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 4.0 in stage 119.0 (TID 714) in 188 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5236
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5218
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5222
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5202
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d9ceeee
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  BlockManagerInfo:54 - Removed broadcast_232_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5221
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5239
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5175
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5229
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5241
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5204
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5224
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5181
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5235
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5211
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5251
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5254
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5252
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5167
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5231
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5250
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34076886
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5168
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5226
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5223
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5244
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:25 INFO  BlockManagerInfo:54 - Removed broadcast_235_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5228
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5200
2020-05-19 05:26:25 INFO  BlockManagerInfo:54 - Removed broadcast_234_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5192
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5166
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5203
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5189
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5195
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5170
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5242
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5208
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5164
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5185
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5212
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5169
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5174
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5232
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5188
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5209
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5247
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5249
2020-05-19 05:26:25 INFO  BlockManagerInfo:54 - Removed broadcast_238_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5191
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5196
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5190
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5246
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5216
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5187
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5186
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5178
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5197
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5213
2020-05-19 05:26:25 INFO  BlockManagerInfo:54 - Removed broadcast_233_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5240
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5193
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 5.0 in stage 119.0 (TID 715). 38186 bytes result sent to driver
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned shuffle 58
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 7.0 in stage 119.0 (TID 717, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5171
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 5.0 in stage 119.0 (TID 715) in 172 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5245
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5194
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5227
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5230
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5177
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5219
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5172
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5180
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5210
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5205
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5237
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5182
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5183
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5176
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5243
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5173
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5215
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5206
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5179
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5220
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5217
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5234
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5238
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5198
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5207
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5233
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5214
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5225
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5201
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5199
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5248
2020-05-19 05:26:25 INFO  ContextCleaner:54 - Cleaned accumulator 5184
2020-05-19 05:26:25 INFO  Executor:54 - Running task 7.0 in stage 119.0 (TID 717)
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@593950c
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b14a7d2
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 7.0 in stage 119.0 (TID 717). 36410 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 8.0 in stage 119.0 (TID 718, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  Executor:54 - Running task 8.0 in stage 119.0 (TID 718)
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 7.0 in stage 119.0 (TID 717) in 109 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ff9606f
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5599062
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 6.0 in stage 119.0 (TID 716). 38936 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Starting task 9.0 in stage 119.0 (TID 719, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 6.0 in stage 119.0 (TID 716) in 147 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:25 INFO  Executor:54 - Running task 9.0 in stage 119.0 (TID 719)
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77e6be99
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:25 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:25 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:25 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a35228e
2020-05-19 05:26:25 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 59 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 8.0 in stage 119.0 (TID 718). 35352 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 8.0 in stage 119.0 (TID 718) in 102 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Committed version 60 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/60.delta
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:25 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:25 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 60 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:25 INFO  Executor:54 - Finished task 9.0 in stage 119.0 (TID 719). 34904 bytes result sent to driver
2020-05-19 05:26:25 INFO  TaskSetManager:54 - Finished task 9.0 in stage 119.0 (TID 719) in 124 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2020-05-19 05:26:25 INFO  DAGScheduler:54 - ResultStage 119 (start at NativeMethodAccessorImpl.java:0) finished in 0.708 s
2020-05-19 05:26:25 INFO  DAGScheduler:54 - Job 118 finished: start at NativeMethodAccessorImpl.java:0, took 0.742143 s
2020-05-19 05:26:25 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@60f4c410 is committing.
-------------------------------------------
Batch: 59
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:25 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@60f4c410 committed.
2020-05-19 05:26:25 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:25 INFO  DAGScheduler:54 - Job 119 finished: start at NativeMethodAccessorImpl.java:0, took 0.000041 s
2020-05-19 05:26:25 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:24.534Z",
  "batchId" : 59,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.4781966001478197,
  "processedRowsPerSecond" : 1.6025641025641026,
  "durationMs" : {
    "addBatch" : 1125,
    "getBatch" : 4,
    "getOffset" : 4,
    "queryPlanning" : 41,
    "triggerExecution" : 1248,
    "walCommit" : 74
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:40:30.000Z",
    "max" : "2018-12-28T16:41:00.000Z",
    "min" : "2018-12-28T16:40:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2846,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3260,
        "0" : 3163
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3261,
        "0" : 3164
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.4781966001478197,
    "processedRowsPerSecond" : 1.6025641025641026
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:25 INFO  MicroBatchExecution:54 - Committed offsets for batch 60. Metadata OffsetSeqMetadata(1546297020000,1589865985820,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:25 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3261,"0":3164}}), end = {"department.police.service.call":{"1":3261,"0":3165}}
2020-05-19 05:26:25 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:25 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3164,3165,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3261,3261,None)
2020-05-19 05:26:25 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:25 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:26 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_240 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_240_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.7 MB)
2020-05-19 05:26:26 INFO  BlockManagerInfo:54 - Added broadcast_240_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:26 INFO  SparkContext:54 - Created broadcast 240 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_241 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_241_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.4 MB)
2020-05-19 05:26:26 INFO  BlockManagerInfo:54 - Added broadcast_241_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:26 INFO  SparkContext:54 - Created broadcast 241 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:26 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@16f9f3da. The input RDD has 10 partitions.
2020-05-19 05:26:26 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Registering RDD 906 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Got job 120 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Final stage: ResultStage 121 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 120)
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 120)
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 120 (MapPartitionsRDD[906] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_242 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_242_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:26 INFO  BlockManagerInfo:54 - Added broadcast_242_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:26 INFO  SparkContext:54 - Created broadcast 242 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[906] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:26 INFO  TaskSchedulerImpl:54 - Adding task set 120.0 with 2 tasks
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 120.0 (TID 720, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 1.0 in stage 120.0 (TID 721, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 0.0 in stage 120.0 (TID 720)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 1.0 in stage 120.0 (TID 721)
2020-05-19 05:26:26 INFO  KafkaSourceRDD:54 - Beginning offset 3261 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 1.0 in stage 120.0 (TID 721). 2074 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 1.0 in stage 120.0 (TID 721) in 10 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 0.0 in stage 120.0 (TID 720). 2203 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 120.0 (TID 720) in 24 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2020-05-19 05:26:26 INFO  DAGScheduler:54 - ShuffleMapStage 120 (start at NativeMethodAccessorImpl.java:0) finished in 0.030 s
2020-05-19 05:26:26 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:26 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:26 INFO  DAGScheduler:54 - waiting: Set(ResultStage 121)
2020-05-19 05:26:26 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Submitting ResultStage 121 (MapPartitionsRDD[912] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_243 stored as values in memory (estimated size 54.1 KB, free 364.3 MB)
2020-05-19 05:26:26 INFO  MemoryStore:54 - Block broadcast_243_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.3 MB)
2020-05-19 05:26:26 INFO  BlockManagerInfo:54 - Added broadcast_243_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:26 INFO  SparkContext:54 - Created broadcast 243 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:26 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 121 (MapPartitionsRDD[912] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:26 INFO  TaskSchedulerImpl:54 - Adding task set 121.0 with 10 tasks
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 121.0 (TID 722, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 1.0 in stage 121.0 (TID 723, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 0.0 in stage 121.0 (TID 722)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 1.0 in stage 121.0 (TID 723)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@635eb677
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7a8090
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c0f31db
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20e0f13b
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/61.delta
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 0.0 in stage 121.0 (TID 722). 34664 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 2.0 in stage 121.0 (TID 724, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:26 INFO  Executor:54 - Running task 2.0 in stage 121.0 (TID 724)
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 1.0 in stage 121.0 (TID 723). 33577 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 121.0 (TID 722) in 96 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 3.0 in stage 121.0 (TID 725, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 1.0 in stage 121.0 (TID 723) in 99 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 3.0 in stage 121.0 (TID 725)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1762f260
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e10c2cd
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8f7cd89
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@615b05ce
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 3.0 in stage 121.0 (TID 725). 36319 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 4.0 in stage 121.0 (TID 726, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 4.0 in stage 121.0 (TID 726)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 3.0 in stage 121.0 (TID 725) in 145 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eb373ff
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e3efa1
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 2.0 in stage 121.0 (TID 724). 35122 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 5.0 in stage 121.0 (TID 727, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 5.0 in stage 121.0 (TID 727)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 2.0 in stage 121.0 (TID 724) in 199 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28df33c6
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bfbe19e
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 4.0 in stage 121.0 (TID 726). 36041 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 6.0 in stage 121.0 (TID 728, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 6.0 in stage 121.0 (TID 728)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 4.0 in stage 121.0 (TID 726) in 187 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31c3fab9
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a8d1250
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 5.0 in stage 121.0 (TID 727). 38143 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 7.0 in stage 121.0 (TID 729, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 5.0 in stage 121.0 (TID 727) in 178 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 7.0 in stage 121.0 (TID 729)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad06d4b
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ab620b8
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 6.0 in stage 121.0 (TID 728). 38936 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 8.0 in stage 121.0 (TID 730, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 8.0 in stage 121.0 (TID 730)
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 6.0 in stage 121.0 (TID 728) in 210 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:26 INFO  Executor:54 - Finished task 7.0 in stage 121.0 (TID 729). 36410 bytes result sent to driver
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Starting task 9.0 in stage 121.0 (TID 731, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  TaskSetManager:54 - Finished task 7.0 in stage 121.0 (TID 729) in 188 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:26 INFO  Executor:54 - Running task 9.0 in stage 121.0 (TID 731)
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d203a11
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55bb46ee
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc67fc9
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:26 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:26 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:26 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54b4fbe7
2020-05-19 05:26:26 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 60 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/61.delta
2020-05-19 05:26:26 INFO  HDFSBackedStateStoreProvider:54 - Committed version 61 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/61.delta
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:26 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:27 INFO  Executor:54 - Finished task 8.0 in stage 121.0 (TID 730). 35352 bytes result sent to driver
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Finished task 8.0 in stage 121.0 (TID 730) in 223 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 61 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:27 INFO  Executor:54 - Finished task 9.0 in stage 121.0 (TID 731). 34904 bytes result sent to driver
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Finished task 9.0 in stage 121.0 (TID 731) in 231 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2020-05-19 05:26:27 INFO  DAGScheduler:54 - ResultStage 121 (start at NativeMethodAccessorImpl.java:0) finished in 0.886 s
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Job 120 finished: start at NativeMethodAccessorImpl.java:0, took 0.921861 s
2020-05-19 05:26:27 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@16f9f3da is committing.
-------------------------------------------
Batch: 60
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:27 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@16f9f3da committed.
2020-05-19 05:26:27 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Job 121 finished: start at NativeMethodAccessorImpl.java:0, took 0.000051 s
2020-05-19 05:26:27 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:25.814Z",
  "batchId" : 60,
  "numInputRows" : 1,
  "inputRowsPerSecond" : 0.78125,
  "processedRowsPerSecond" : 0.6042296072507553,
  "durationMs" : {
    "addBatch" : 1502,
    "getBatch" : 4,
    "getOffset" : 5,
    "queryPlanning" : 42,
    "triggerExecution" : 1655,
    "walCommit" : 101
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:38:00.000Z",
    "max" : "2018-12-28T16:38:00.000Z",
    "min" : "2018-12-28T16:38:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2846,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3261,
        "0" : 3164
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3261,
        "0" : 3165
      }
    },
    "numInputRows" : 1,
    "inputRowsPerSecond" : 0.78125,
    "processedRowsPerSecond" : 0.6042296072507553
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:27 INFO  MicroBatchExecution:54 - Committed offsets for batch 61. Metadata OffsetSeqMetadata(1546297020000,1589865987590,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:27 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3261,"0":3165}}), end = {"department.police.service.call":{"1":3263,"0":3165}}
2020-05-19 05:26:27 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:27 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3165,3165,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3261,3263,None)
2020-05-19 05:26:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:27 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_244 stored as values in memory (estimated size 281.8 KB, free 364.0 MB)
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_244_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.0 MB)
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Added broadcast_244_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  SparkContext:54 - Created broadcast 244 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_245 stored as values in memory (estimated size 281.8 KB, free 363.7 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5344
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5388
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5311
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5290
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5343
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5293
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5394
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5353
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5376
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5284
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5356
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5379
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5317
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5346
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5397
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5384
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5368
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5323
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5415
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5310
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5380
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5410
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5333
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_241_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5258
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5374
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5412
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5426
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5274
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5337
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5282
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5300
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5413
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5283
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5263
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5298
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5286
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5390
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_236_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5422
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5357
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5387
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5264
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5334
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5279
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5366
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5392
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5302
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5321
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5278
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5273
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5411
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5349
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_242_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5407
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5255
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5312
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5377
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5347
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5358
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5253
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5315
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5396
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5301
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5320
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5351
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5403
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5404
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5277
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5322
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5378
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned shuffle 59
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5423
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5281
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5314
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5418
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5288
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5371
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5327
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5340
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5270
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5305
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5259
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5261
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_245_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Added broadcast_245_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5391
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5345
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5355
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5352
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5375
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5382
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5256
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5421
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5272
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5332
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5429
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5359
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5287
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5269
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5318
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5331
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5364
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5425
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5268
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5367
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5260
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5267
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5299
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5381
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5319
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5373
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5416
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5338
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5408
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5295
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5265
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5335
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5313
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5324
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5276
2020-05-19 05:26:27 INFO  SparkContext:54 - Created broadcast 245 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:27 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2f1ac5dc. The input RDD has 10 partitions.
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_240_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_239_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5405
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5383
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5401
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5395
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5370
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5372
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5306
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5297
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5385
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5369
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5291
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5341
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5350
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5400
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5428
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5427
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5360
2020-05-19 05:26:27 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_237_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5363
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Registering RDD 921 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Got job 122 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Final stage: ResultStage 123 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 122)
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 122)
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 122 (MapPartitionsRDD[921] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_246 stored as values in memory (estimated size 39.1 KB, free 364.9 MB)
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_246_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.9 MB)
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Added broadcast_246_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:27 INFO  SparkContext:54 - Created broadcast 246 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[921] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:27 INFO  TaskSchedulerImpl:54 - Adding task set 122.0 with 2 tasks
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 122.0 (TID 732, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Starting task 1.0 in stage 122.0 (TID 733, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5430
2020-05-19 05:26:27 INFO  Executor:54 - Running task 1.0 in stage 122.0 (TID 733)
2020-05-19 05:26:27 INFO  KafkaSourceRDD:54 - Beginning offset 3165 is the same as ending offset skipping department.police.service.call 0
2020-05-19 05:26:27 INFO  Executor:54 - Running task 0.0 in stage 122.0 (TID 732)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5325
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5348
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5362
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5262
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5417
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Removed broadcast_243_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5328
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5386
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5330
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5432
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5257
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5289
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5365
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5389
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5303
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5280
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5336
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5406
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5419
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5307
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5354
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5402
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5398
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5342
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5294
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5266
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5292
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5296
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5361
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5399
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5409
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5424
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5316
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5308
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5329
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5285
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5271
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned shuffle 60
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5414
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5339
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5420
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5275
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5393
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5304
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5326
2020-05-19 05:26:27 INFO  ContextCleaner:54 - Cleaned accumulator 5309
2020-05-19 05:26:27 INFO  Executor:54 - Finished task 1.0 in stage 122.0 (TID 733). 2074 bytes result sent to driver
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Finished task 1.0 in stage 122.0 (TID 733) in 23 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:27 INFO  Executor:54 - Finished task 0.0 in stage 122.0 (TID 732). 2203 bytes result sent to driver
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 122.0 (TID 732) in 26 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2020-05-19 05:26:27 INFO  DAGScheduler:54 - ShuffleMapStage 122 (start at NativeMethodAccessorImpl.java:0) finished in 0.035 s
2020-05-19 05:26:27 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:27 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:27 INFO  DAGScheduler:54 - waiting: Set(ResultStage 123)
2020-05-19 05:26:27 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Submitting ResultStage 123 (MapPartitionsRDD[927] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_247 stored as values in memory (estimated size 54.1 KB, free 364.9 MB)
2020-05-19 05:26:27 INFO  MemoryStore:54 - Block broadcast_247_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.9 MB)
2020-05-19 05:26:27 INFO  BlockManagerInfo:54 - Added broadcast_247_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:27 INFO  SparkContext:54 - Created broadcast 247 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:27 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 123 (MapPartitionsRDD[927] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:27 INFO  TaskSchedulerImpl:54 - Adding task set 123.0 with 10 tasks
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 123.0 (TID 734, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:27 INFO  TaskSetManager:54 - Starting task 1.0 in stage 123.0 (TID 735, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:27 INFO  Executor:54 - Running task 1.0 in stage 123.0 (TID 735)
2020-05-19 05:26:27 INFO  Executor:54 - Running task 0.0 in stage 123.0 (TID 734)
2020-05-19 05:26:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc475dd
2020-05-19 05:26:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376cac1f
2020-05-19 05:26:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@140e757d
2020-05-19 05:26:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:27 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:27 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:27 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3096a5c2
2020-05-19 05:26:27 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:27 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/62.delta
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 1.0 in stage 123.0 (TID 735). 33577 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 2.0 in stage 123.0 (TID 736, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 2.0 in stage 123.0 (TID 736)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 123.0 (TID 735) in 105 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@616ac6dc
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@116325da
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 0.0 in stage 123.0 (TID 734). 34664 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 3.0 in stage 123.0 (TID 737, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 3.0 in stage 123.0 (TID 737)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@729fc1fe
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a1883c1
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 123.0 (TID 734) in 139 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 3.0 in stage 123.0 (TID 737). 36319 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 4.0 in stage 123.0 (TID 738, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 3.0 in stage 123.0 (TID 737) in 125 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 4.0 in stage 123.0 (TID 738)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5ed70b
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cc30e18
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 2.0 in stage 123.0 (TID 736). 35122 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 5.0 in stage 123.0 (TID 739, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 2.0 in stage 123.0 (TID 736) in 192 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 5.0 in stage 123.0 (TID 739)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@311c37c5
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64984027
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 4.0 in stage 123.0 (TID 738). 36142 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 6.0 in stage 123.0 (TID 740, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 6.0 in stage 123.0 (TID 740)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 4.0 in stage 123.0 (TID 738) in 137 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b3cc12
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19ca6573
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 5.0 in stage 123.0 (TID 739). 38143 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 7.0 in stage 123.0 (TID 741, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 5.0 in stage 123.0 (TID 739) in 145 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 7.0 in stage 123.0 (TID 741)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34cd3e96
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61f155a7
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 6.0 in stage 123.0 (TID 740). 38936 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 8.0 in stage 123.0 (TID 742, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 8.0 in stage 123.0 (TID 742)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 6.0 in stage 123.0 (TID 740) in 160 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@572e73f2
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c4be597
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 7.0 in stage 123.0 (TID 741). 36410 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Starting task 9.0 in stage 123.0 (TID 743, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:28 INFO  Executor:54 - Running task 9.0 in stage 123.0 (TID 743)
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 7.0 in stage 123.0 (TID 741) in 141 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19fdf3fa
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:28 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:28 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:28 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@449a20b3
2020-05-19 05:26:28 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 61 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/62.delta
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Committed version 62 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/62.delta
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:28 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 8.0 in stage 123.0 (TID 742). 35352 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 8.0 in stage 123.0 (TID 742) in 140 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:28 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 62 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:28 INFO  Executor:54 - Finished task 9.0 in stage 123.0 (TID 743). 34904 bytes result sent to driver
2020-05-19 05:26:28 INFO  TaskSetManager:54 - Finished task 9.0 in stage 123.0 (TID 743) in 120 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 123.0, whose tasks have all completed, from pool 
2020-05-19 05:26:28 INFO  DAGScheduler:54 - ResultStage 123 (start at NativeMethodAccessorImpl.java:0) finished in 0.702 s
2020-05-19 05:26:28 INFO  DAGScheduler:54 - Job 122 finished: start at NativeMethodAccessorImpl.java:0, took 0.742265 s
2020-05-19 05:26:28 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2f1ac5dc is committing.
-------------------------------------------
Batch: 61
-------------------------------------------
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:28 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@2f1ac5dc committed.
2020-05-19 05:26:28 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:28 INFO  DAGScheduler:54 - Job 123 finished: start at NativeMethodAccessorImpl.java:0, took 0.000040 s
2020-05-19 05:26:28 INFO  MicroBatchExecution:54 - Streaming query made progress: {
  "id" : "5bb46ce7-e507-4d4a-b04e-67d0babbd47c",
  "runId" : "aa5811b7-4964-4f8f-81cc-092a1da056a8",
  "name" : "aggregates",
  "timestamp" : "2020-05-19T05:26:27.584Z",
  "batchId" : 61,
  "numInputRows" : 2,
  "inputRowsPerSecond" : 1.1299435028248588,
  "processedRowsPerSecond" : 1.5772870662460567,
  "durationMs" : {
    "addBatch" : 1171,
    "getBatch" : 6,
    "getOffset" : 6,
    "queryPlanning" : 45,
    "triggerExecution" : 1268,
    "walCommit" : 39
  },
  "eventTime" : {
    "avg" : "2018-12-28T16:38:00.000Z",
    "max" : "2018-12-28T16:38:00.000Z",
    "min" : "2018-12-28T16:38:00.000Z",
    "watermark" : "2018-12-31T22:57:00.000Z"
  },
  "stateOperators" : [ {
    "numRowsTotal" : 2847,
    "numRowsUpdated" : 2,
    "memoryUsedBytes" : 709845
  } ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[department.police.service.call]]",
    "startOffset" : {
      "department.police.service.call" : {
        "1" : 3261,
        "0" : 3165
      }
    },
    "endOffset" : {
      "department.police.service.call" : {
        "1" : 3263,
        "0" : 3165
      }
    },
    "numInputRows" : 2,
    "inputRowsPerSecond" : 1.1299435028248588,
    "processedRowsPerSecond" : 1.5772870662460567
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@441197a0"
  }
}
2020-05-19 05:26:28 INFO  MicroBatchExecution:54 - Committed offsets for batch 62. Metadata OffsetSeqMetadata(1546297020000,1589865988899,Map(spark.sql.shuffle.partitions -> 10, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
2020-05-19 05:26:28 INFO  KafkaSource:54 - GetBatch called with start = Some({"department.police.service.call":{"1":3263,"0":3165}}), end = {"department.police.service.call":{"1":3263,"0":3166}}
2020-05-19 05:26:28 INFO  KafkaSource:54 - Partitions added: Map()
2020-05-19 05:26:28 INFO  KafkaSource:54 - GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(department.police.service.call-0,3165,3166,None), KafkaSourceRDDOffsetRange(department.police.service.call-1,3263,3263,None)
2020-05-19 05:26:29 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:29 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:29 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_248 stored as values in memory (estimated size 281.8 KB, free 364.7 MB)
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_248_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.6 MB)
2020-05-19 05:26:29 INFO  BlockManagerInfo:54 - Added broadcast_248_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:29 INFO  SparkContext:54 - Created broadcast 248 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_249 stored as values in memory (estimated size 281.8 KB, free 364.4 MB)
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_249_piece0 stored as bytes in memory (estimated size 24.1 KB, free 364.3 MB)
2020-05-19 05:26:29 INFO  BlockManagerInfo:54 - Added broadcast_249_piece0 in memory on 234cbc3ca30b:38543 (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:29 INFO  SparkContext:54 - Created broadcast 249 from start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:29 INFO  WriteToDataSourceV2Exec:54 - Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@63314932. The input RDD has 10 partitions.
2020-05-19 05:26:29 INFO  SparkContext:54 - Starting job: start at NativeMethodAccessorImpl.java:0
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Registering RDD 936 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Got job 124 (start at NativeMethodAccessorImpl.java:0) with 10 output partitions
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Final stage: ResultStage 125 (start at NativeMethodAccessorImpl.java:0)
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 124)
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 124)
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 124 (MapPartitionsRDD[936] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_250 stored as values in memory (estimated size 39.1 KB, free 364.3 MB)
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_250_piece0 stored as bytes in memory (estimated size 15.8 KB, free 364.3 MB)
2020-05-19 05:26:29 INFO  BlockManagerInfo:54 - Added broadcast_250_piece0 in memory on 234cbc3ca30b:38543 (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:29 INFO  SparkContext:54 - Created broadcast 250 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[936] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
2020-05-19 05:26:29 INFO  TaskSchedulerImpl:54 - Adding task set 124.0 with 2 tasks
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 124.0 (TID 744, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 124.0 (TID 745, localhost, executor driver, partition 1, PROCESS_LOCAL, 8042 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 1.0 in stage 124.0 (TID 745)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 0.0 in stage 124.0 (TID 744)
2020-05-19 05:26:29 INFO  KafkaSourceRDD:54 - Beginning offset 3263 is the same as ending offset skipping department.police.service.call 1
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 0.0 in stage 124.0 (TID 744). 2074 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 124.0 (TID 744) in 27 ms on localhost (executor driver) (1/2)
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 1.0 in stage 124.0 (TID 745). 2203 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 124.0 (TID 745) in 32 ms on localhost (executor driver) (2/2)
2020-05-19 05:26:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2020-05-19 05:26:29 INFO  DAGScheduler:54 - ShuffleMapStage 124 (start at NativeMethodAccessorImpl.java:0) finished in 0.036 s
2020-05-19 05:26:29 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-05-19 05:26:29 INFO  DAGScheduler:54 - running: Set()
2020-05-19 05:26:29 INFO  DAGScheduler:54 - waiting: Set(ResultStage 125)
2020-05-19 05:26:29 INFO  DAGScheduler:54 - failed: Set()
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Submitting ResultStage 125 (MapPartitionsRDD[942] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_251 stored as values in memory (estimated size 54.1 KB, free 364.2 MB)
2020-05-19 05:26:29 INFO  MemoryStore:54 - Block broadcast_251_piece0 stored as bytes in memory (estimated size 19.1 KB, free 364.2 MB)
2020-05-19 05:26:29 INFO  BlockManagerInfo:54 - Added broadcast_251_piece0 in memory on 234cbc3ca30b:38543 (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:29 INFO  SparkContext:54 - Created broadcast 251 from broadcast at DAGScheduler.scala:1039
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ResultStage 125 (MapPartitionsRDD[942] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2020-05-19 05:26:29 INFO  TaskSchedulerImpl:54 - Adding task set 125.0 with 10 tasks
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 125.0 (TID 746, localhost, executor driver, partition 0, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 125.0 (TID 747, localhost, executor driver, partition 1, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 0.0 in stage 125.0 (TID 746)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 1.0 in stage 125.0 (TID 747)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ba3308
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72bf9fa9
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,1,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d53668c
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c475a7a
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,0,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0/63.delta
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1/63.delta
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 0 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 0 committed.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 1 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 1 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/0]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 0.0 in stage 125.0 (TID 746). 34664 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 125.0 (TID 748, localhost, executor driver, partition 2, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 2.0 in stage 125.0 (TID 748)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 125.0 (TID 746) in 117 ms on localhost (executor driver) (1/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@85616f6
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a06b8c5
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,2,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/1]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 1.0 in stage 125.0 (TID 747). 33577 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 3.0 in stage 125.0 (TID 749, localhost, executor driver, partition 3, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 3.0 in stage 125.0 (TID 749)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 125.0 (TID 747) in 141 ms on localhost (executor driver) (2/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33fb10e0
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15167d07
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,3,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3/63.delta
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2/63.delta
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 2 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 2 committed.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 3 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 3 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/2]
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/3]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 2.0 in stage 125.0 (TID 748). 35122 bytes result sent to driver
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 3.0 in stage 125.0 (TID 749). 36319 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 4.0 in stage 125.0 (TID 750, localhost, executor driver, partition 4, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 5.0 in stage 125.0 (TID 751, localhost, executor driver, partition 5, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 5.0 in stage 125.0 (TID 751)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 3.0 in stage 125.0 (TID 749) in 135 ms on localhost (executor driver) (3/10)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 125.0 (TID 748) in 160 ms on localhost (executor driver) (4/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  Executor:54 - Running task 4.0 in stage 125.0 (TID 750)
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e23a9e2
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f9e8327
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,5,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f2ccb73
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3be3145c
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,4,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5/63.delta
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4/63.delta
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 4 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 4 committed.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 5 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 5 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/5]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 5.0 in stage 125.0 (TID 751). 38143 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 6.0 in stage 125.0 (TID 752, localhost, executor driver, partition 6, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 6.0 in stage 125.0 (TID 752)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 5.0 in stage 125.0 (TID 751) in 113 ms on localhost (executor driver) (5/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a733276
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a0525b
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,6,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/4]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 4.0 in stage 125.0 (TID 750). 36142 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 7.0 in stage 125.0 (TID 753, localhost, executor driver, partition 7, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 4.0 in stage 125.0 (TID 750) in 127 ms on localhost (executor driver) (6/10)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 7.0 in stage 125.0 (TID 753)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8b73f0
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@601973a
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,7,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6/63.delta
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7/63.delta
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 6 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 6 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/6]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 6.0 in stage 125.0 (TID 752). 38936 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 8.0 in stage 125.0 (TID 754, localhost, executor driver, partition 8, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 8.0 in stage 125.0 (TID 754)
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 7 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 7 committed.
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 6.0 in stage 125.0 (TID 752) in 116 ms on localhost (executor driver) (7/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7123e2ff
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8995d55
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,8,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/7]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 7.0 in stage 125.0 (TID 753). 36410 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Starting task 9.0 in stage 125.0 (TID 755, localhost, executor driver, partition 9, PROCESS_LOCAL, 7754 bytes)
2020-05-19 05:26:29 INFO  Executor:54 - Running task 9.0 in stage 125.0 (TID 755)
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8/63.delta
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 7.0 in stage 125.0 (TID 753) in 153 ms on localhost (executor driver) (8/10)
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d9307b2
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:29 INFO  StateStore:54 - Env is not null
2020-05-19 05:26:29 INFO  StateStore:54 - Getting StateStoreCoordinatorRef
2020-05-19 05:26:29 INFO  StateStore:54 - Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f00a34c
2020-05-19 05:26:29 INFO  StateStore:54 - Reported that the loaded instance StateStoreProviderId(StateStoreId(file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state,0,9,default),aa5811b7-4964-4f8f-81cc-092a1da056a8) is active
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Retrieved version 62 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] for update
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks out of 2 blocks
2020-05-19 05:26:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 8 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 8 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/8]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 8.0 in stage 125.0 (TID 754). 35352 bytes result sent to driver
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Committed version 63 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9] to file file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9/63.delta
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 8.0 in stage 125.0 (TID 754) in 100 ms on localhost (executor driver) (9/10)
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 9 is committing.
2020-05-19 05:26:29 INFO  DataWritingSparkTask:54 - Writer for partition 9 committed.
2020-05-19 05:26:29 INFO  HDFSBackedStateStoreProvider:54 - Aborted version 63 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b/state/0/9]
2020-05-19 05:26:29 INFO  Executor:54 - Finished task 9.0 in stage 125.0 (TID 755). 34904 bytes result sent to driver
2020-05-19 05:26:29 INFO  TaskSetManager:54 - Finished task 9.0 in stage 125.0 (TID 755) in 95 ms on localhost (executor driver) (10/10)
2020-05-19 05:26:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 125.0, whose tasks have all completed, from pool 
2020-05-19 05:26:29 INFO  DAGScheduler:54 - ResultStage 125 (start at NativeMethodAccessorImpl.java:0) finished in 0.649 s
2020-05-19 05:26:29 INFO  DAGScheduler:54 - Job 124 finished: start at NativeMethodAccessorImpl.java:0, took 0.689278 s
2020-05-19 05:26:29 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@63314932 is committing.
-------------------------------------------
Batch: 62
-------------------------------------------
Traceback (most recent call last):
  File "/home/workspace/data_stream.py", line 121, in <module>
    run_spark_job(spark)
  File "/home/workspace/data_stream.py", line 75, in run_spark_job
    query.awaitTermination()
  File "/opt/spark-2.3.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 106, in awaitTermination
  File "/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1255, in __call__
  File "/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 985, in send_command
  File "/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1152, in send_command
  File "/opt/conda/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/opt/spark-2.3.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/context.py", line 266, in signal_handler
KeyboardInterrupt
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5464
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5582
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5441
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5604
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5460
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5564
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5445
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5451
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5603
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5501
2020-05-19 05:26:30 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_250_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.1 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5446
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5561
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5498
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5559
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5504
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5492
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5454
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5462
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5496
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5562
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5595
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5513
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5487
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5449
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5471
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5468
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5570
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5431
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5477
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5515
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5473
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5470
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5573
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5583
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5467
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5497
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5463
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5510
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5585
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5444
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_245_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.1 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5438
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5493
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5502
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5578
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5472
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5503
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5575
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5577
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5506
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5447
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5474
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5434
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5484
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5593
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5514
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_251_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.1 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5452
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5499
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5439
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5435
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5591
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5521
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5436
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5476
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5459
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5600
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5558
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5495
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5517
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5486
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5601
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5489
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5574
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5565
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5586
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5598
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5605
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5483
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5437
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5465
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5490
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5494
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5581
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5488
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5572
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5505
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5588
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5566
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5443
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5433
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5456
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5511
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5557
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5569
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5480
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5599
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned shuffle 61
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5606
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5587
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5453
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5519
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5594
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5448
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5458
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5475
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5478
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5509
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5563
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5580
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5491
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5584
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_244_piece0 on 234cbc3ca30b:38543 in memory (size: 24.1 KB, free: 366.2 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5450
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5592
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5440
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5500
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5481
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5479
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5571
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5469
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5590
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5482
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5516
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5576
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5442
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5597
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5567
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5466
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5589
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5455
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_246_piece0 on 234cbc3ca30b:38543 in memory (size: 15.8 KB, free: 366.2 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5602
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5512
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5568
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5560
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5485
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5508
2020-05-19 05:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_247_piece0 on 234cbc3ca30b:38543 in memory (size: 19.1 KB, free: 366.2 MB)
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5518
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5507
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5579
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5461
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5457
2020-05-19 05:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 5596
2020-05-19 05:26:30 INFO  AbstractConnector:318 - Stopped Spark@4552eb46{HTTP/1.1,[http/1.1]}{0.0.0.0:3002}
2020-05-19 05:26:30 INFO  SparkUI:54 - Stopped Spark web UI at http://234cbc3ca30b:3002
+------------------------------------------+------------------------+-----+
|window                                    |original_crime_type_name|count|
+------------------------------------------+------------------------+-----+
|[2018-12-31 03:00:00, 2018-12-31 04:00:00]|Injury Veh Accident     |1    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Jo                      |1    |
|[2018-12-30 09:00:00, 2018-12-30 10:00:00]|Traf Violation Cite     |7    |
|[2018-12-29 19:00:00, 2018-12-29 20:00:00]|22500e                  |6    |
|[2018-12-30 11:00:00, 2018-12-30 12:00:00]|Noise Nuisance          |1    |
|[2018-12-29 01:00:00, 2018-12-29 02:00:00]|Traf Violation Cite     |3    |
|[2018-12-30 22:00:00, 2018-12-30 23:00:00]|7,2,25                  |1    |
|[2018-12-28 21:00:00, 2018-12-28 22:00:00]|7.2.27                  |2    |
|[2018-12-30 16:00:00, 2018-12-30 17:00:00]|Person Screaming        |1    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Passing Call            |16   |
|[2018-12-30 13:00:00, 2018-12-30 14:00:00]|H&r Injury Accident     |1    |
|[2018-12-31 18:00:00, 2018-12-31 19:00:00]|Burglary                |3    |
|[2018-12-28 18:00:00, 2018-12-28 19:00:00]|Fraud                   |1    |
|[2018-12-29 15:00:00, 2018-12-29 16:00:00]|Robbery                 |1    |
|[2018-12-30 21:00:00, 2018-12-30 22:00:00]|H&r Veh Accident        |1    |
|[2018-12-28 17:00:00, 2018-12-28 18:00:00]|Ret                     |1    |
|[2018-12-30 15:00:00, 2018-12-30 16:00:00]|22500e                  |2    |
|[2018-12-31 23:00:00, 2019-01-01 00:00:00]|Traf Violation Tow      |1    |
|[2018-12-29 17:00:00, 2018-12-29 18:00:00]|311                     |1    |
|[2018-12-31 15:00:00, 2018-12-31 16:00:00]|800                     |1    |
+------------------------------------------+------------------------+-----+
only showing top 20 rows

2020-05-19 05:26:30 INFO  WriteToDataSourceV2Exec:54 - Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@63314932 committed.
2020-05-19 05:26:30 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2020-05-19 05:26:30 ERROR MicroBatchExecution:91 - Query aggregates [id = 5bb46ce7-e507-4d4a-b04e-67d0babbd47c, runId = aa5811b7-4964-4f8f-81cc-092a1da056a8] terminated with error
java.lang.IllegalStateException: SparkContext has been shutdown
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2026)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3284)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2733)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2733)
	at org.apache.spark.sql.Dataset$$anonfun$51.apply(Dataset.scala:3265)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3264)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2733)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$3$$anonfun$apply$16.apply(MicroBatchExecution.scala:499)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$3.apply(MicroBatchExecution.scala:494)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:271)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:493)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:151)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:139)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:139)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:271)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:139)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:135)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:279)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
2020-05-19 05:26:30 INFO  MemoryStore:54 - MemoryStore cleared
2020-05-19 05:26:30 INFO  BlockManager:54 - BlockManager stopped
2020-05-19 05:26:30 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2020-05-19 05:26:30 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2020-05-19 05:26:30 INFO  SparkContext:54 - Successfully stopped SparkContext
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Deleting directory /tmp/temporary-b6e4289d-0be7-4a33-a9dc-e8abaa1d947b
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Deleting directory /tmp/temporaryReader-ea046204-b23a-4282-9957-cdc581245d18
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-5517b5bc-b92e-4569-816f-a8bd182b57df
2020-05-19 05:26:30 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7b31bd0d-f4a6-4dc7-b717-42dd86a0dbdb/pyspark-f2fb072c-c7e3-4c94-995f-d6a039d31ba9
